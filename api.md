# Project API Documentation
```mermaid
graph TD
    %% === 1. æ ¸å¿ƒç’°å¢ƒå€å¡Š ===
    subgraph Environment ["1. éŠæˆ²ç’°å¢ƒ (game.environment)"]
        direction TB
        GameEnv[("ğŸ—ï¸ GameEnv<br>(æ ¸å¿ƒé¡åˆ¥)")]
        
        %% åˆå§‹åŒ–åƒæ•¸
        subgraph Init ["âš™ï¸ åˆå§‹åŒ– (Init Settings)"]
            Params("seed (ç¨®å­)<br>max_steps (æœ€å¤§æ­¥æ•¸)<br>frame_skip (è·³å¹€æ•¸)")
        end
        
        %% ç‹€æ…‹èˆ‡å‹•ä½œ
        subgraph DataIO ["ğŸ“Š æ•¸æ“šè¼¸å…¥/è¼¸å‡º"]
            Obs["ğŸ‘ï¸ ç‹€æ…‹ç©ºé–“ (Observation)<br>[y, vy, x_obs, gap_top, gap_bottom]"]
            Act["ğŸ® å‹•ä½œç©ºé–“ (Action)<br>0: è‡ªç”±è½é«”<br>1: è·³èº"]
        end
        
        %% æ–¹æ³•
        subgraph EnvMethods ["ğŸ› ï¸ åŠŸèƒ½æ–¹æ³•"]
            Reset["reset() -> state"]
            Step["step(action) -> (state, reward, done, info)"]
            Diff["apply_difficulty_profile(config)"]
        end

        GameEnv --> Init
        GameEnv --> DataIO
        GameEnv --> EnvMethods
    end

    %% === 2. ä»£ç†äººå€å¡Š ===
    subgraph Agents ["2. ä»£ç†äºº (Agents)"]
        direction TB
        AgentInterface{{"ğŸ§  Agent å…±åŒä»‹é¢<br>act(state, explore)"}}
        
        PPO["PPOAgent<br>(è‡ªè£½ PPO è¨“ç·´ç”¨)"]
        SB3["SB3ReplayAgent<br>(è®€å–æ¨¡å‹é‡æ’­ç”¨)"]
        
        PPO -.-> AgentInterface
        SB3 -.-> AgentInterface
    end

    %% === 3. ç®¡ç†å™¨å€å¡Š ===
    subgraph Manager ["3. AI ç®¡ç†å™¨ (game.ai_manager)"]
        AlgoMgr["ğŸ’¼ AlgorithmManager"]
        MgrFuncs["register() è¨»å†Š<br>set_active() åˆ‡æ›<br>active_state() ç²å–ç‹€æ…‹"]
        
        AlgoMgr --> MgrFuncs
    end

    %% === 4. äº’å‹•é—œä¿‚ (Flow) ===
    AlgoMgr -- "1. ç®¡ç†èˆ‡åˆ‡æ›" --> AgentInterface
    
    %% éŠæˆ²è¿´åœˆ (Game Loop)
    AgentInterface -- "2. æ±ºå®šå‹•ä½œ action (0æˆ–1)" --> Step
    Step -- "3. å›å‚³ state, reward, done" --> AgentInterface
    Reset -- "åˆå§‹åŒ– state" --> AgentInterface

    %% æ¨£å¼è¨­å®š
    style GameEnv fill:#f9f,stroke:#333,stroke-width:4px
    style AgentInterface fill:#ff9,stroke:#f66,stroke-width:2px,stroke-dasharray: 5 5
    style AlgoMgr fill:#9cf,stroke:#333,stroke-width:2px
    style Obs fill:#e1f5fe
    style Act fill:#e1f5fe
```
## 1. éŠæˆ²ç’°å¢ƒ (Game Environment)

æ ¸å¿ƒç’°å¢ƒé¡åˆ¥ä½æ–¼ `game/environment.py`ï¼Œæ¨¡æ“¬ Flappy Bird çš„éŠæˆ²ç’°å¢ƒã€‚

### `game.environment.GameEnv`

#### åˆå§‹åŒ– (Initialization)
```python
env = GameEnv(seed=None, max_steps=None, frame_skip=4)
```
- **seed** (int, optional): éš¨æ©Ÿç¨®å­ï¼Œç”¨æ–¼é‡ç¾çµæœã€‚
- **max_steps** (int, optional): æ¯å€‹ Episode çš„æœ€å¤§æ­¥æ•¸é™åˆ¶ã€‚
- **frame_skip** (int, default=4): æ¯å€‹ `step` åŸ·è¡Œçš„ç‰©ç†å¹€æ•¸ (Action Repeat)ã€‚

#### ç‹€æ…‹ç©ºé–“ (Observation Space)
è¿”å›ä¸€å€‹åŒ…å« 5 å€‹æµ®é»æ•¸çš„ Numpy Array (æœªæ¨™æº–åŒ–)ï¼š
`[y, vy, x_obs, y_gap_top, y_gap_bottom]`

- **y**: ç©å®¶å‚ç›´ä½ç½®ã€‚
- **vy**: ç©å®¶å‚ç›´é€Ÿåº¦ã€‚
- **x_obs**: è·é›¢ä¸‹ä¸€å€‹éšœç¤™ç‰©çš„æ°´å¹³è·é›¢ã€‚
- **y_gap_top**: ä¸‹ä¸€å€‹éšœç¤™ç‰©ç¼ºå£çš„é ‚éƒ¨ Y åº§æ¨™ã€‚
- **y_gap_bottom**: ä¸‹ä¸€å€‹éšœç¤™ç‰©ç¼ºå£çš„åº•éƒ¨ Y åº§æ¨™ã€‚

> **æ³¨æ„**: å¯¦éš›è¿”å›çµ¦ Agent çš„æ•¸å€¼æœƒç¶“éæ¨™æº–åŒ–è™•ç† (é™¤ä»¥ `ScreenHeight` ç­‰å¸¸æ•¸)ã€‚

#### å‹•ä½œç©ºé–“ (Action Space)
é›¢æ•£ç©ºé–“ (Discrete Space)ï¼Œå¤§å°ç‚º 2ï¼š
- **0**: ä¸å‹•ä½œ (è‡ªç”±è½é«”)ã€‚
- **1**: è·³èº (æ–½åŠ å‘ä¸Šè¡é‡)ã€‚

#### æ–¹æ³• (Methods)

- **`reset() -> state`**
  é‡ç½®ç’°å¢ƒä¸¦è¿”å›åˆå§‹ç‹€æ…‹ã€‚

- **`step(action) -> (state, reward, done, info)`**
  åŸ·è¡Œä¸€å€‹å‹•ä½œä¸¦æ¨é€²ç’°å¢ƒã€‚
  - **state**: æ–°çš„ç‹€æ…‹ã€‚
  - **reward**: è©²æ­¥ç²å¾—çš„çå‹µ (æµ®é»æ•¸)ã€‚
  - **done**: æ˜¯å¦çµæŸ (True/False)ã€‚
  - **info**: é¡å¤–è³‡è¨Šå­—å…¸ (ä¾‹å¦‚ `{"win": True}`, `{"passed_count": 10}`).

- **`apply_difficulty_profile(profile: dict)`**
  å‹•æ…‹èª¿æ•´é›£åº¦åƒæ•¸ã€‚
  ```python
  profile = {
      "ScrollSpeed": 3.0,
      "ObstacleSpacing": 200.0
  }
  env.apply_difficulty_profile(profile)
  ```

---

## 2. ä»£ç†äºº (Agents)

ä»£ç†äººè² è²¬æ ¹æ“šç’°å¢ƒç‹€æ…‹åšå‡ºæ±ºç­–ã€‚

### `agents.ppo_agent.PPOAgent`
ä¸€å€‹è¼•é‡ç´šçš„ PPO (Proximal Policy Optimization) ä»£ç†äººå¯¦ç¾ã€‚

#### åˆå§‹åŒ–
```python
agent = PPOAgent(lr=3e-4, device=None)
```

#### æ–¹æ³•
- **`act(state, explore: bool = False) -> (action, logp, value)`**
  - **state**: ç’°å¢ƒç‹€æ…‹ã€‚
  - **explore**: æ˜¯å¦é€²è¡Œæ¢ç´¢ (True: éš¨æ©Ÿæ¡æ¨£, False: ç¢ºå®šæ€§å‹•ä½œ)ã€‚
  - **Returns**:
    - `action`: é¸æ“‡çš„å‹•ä½œ (0 æˆ– 1)ã€‚
    - `logp`: å‹•ä½œçš„ Log Probabilityã€‚
    - `value`: ç‹€æ…‹åƒ¹å€¼ä¼°è¨ˆ (Value Function)ã€‚

### `agents.sb3_replay_agent.SB3ReplayAgent`
ç”¨æ–¼åŠ è¼‰ä¸¦é‡æ’­ Stable-Baselines3 è¨“ç·´å¥½çš„æ¨¡å‹ã€‚

#### åˆå§‹åŒ–
```python
agent = SB3ReplayAgent(model_path="path/to/model.zip", device="cpu")
```

#### æ–¹æ³•
- **`act(state, explore: bool = False) -> (action, logp, value)`**
  ä»‹é¢èˆ‡ `PPOAgent` ä¿æŒä¸€è‡´ï¼Œæ–¹ä¾¿æ›¿æ›ã€‚

---

## 3. AI ç®¡ç†å™¨ (AI Manager)

`game/ai_manager.py` è² è²¬ç®¡ç†å¤šå€‹æ¼”ç®—æ³•çš„è¨»å†Šèˆ‡åˆ‡æ›ã€‚

### `game.ai_manager.AlgorithmManager`

#### ä¸»è¦æ–¹æ³•
- **`register(descriptor: AlgorithmDescriptor)`**
  è¨»å†Šä¸€å€‹æ–°çš„æ¼”ç®—æ³•ã€‚
- **`set_active(key: str)`**
  è¨­å®šç•¶å‰æ´»èºçš„æ¼”ç®—æ³•ã€‚
- **`active_state() -> AlgorithmState`**
  ç²å–ç•¶å‰æ¼”ç®—æ³•çš„ç‹€æ…‹ (åŒ…å« `agent`, `trainer` ç­‰)ã€‚

---

## 4. ä½¿ç”¨ç¯„ä¾‹ (Usage Examples)

### æ‰‹å‹•é‹è¡Œç’°å¢ƒ
```python
from game.environment import GameEnv

env = GameEnv(seed=42)
state = env.reset()
done = False

while not done:
    action = 1 # ç¸½æ˜¯è·³èº
    state, reward, done, info = env.step(action)
    print(f"Reward: {reward}, Info: {info}")
```

### åŠ è¼‰è¨“ç·´å¥½çš„æ¨¡å‹ä¸¦é‹è¡Œ
```python
from game.environment import GameEnv
from agents.sb3_replay_agent import SB3ReplayAgent

# åˆå§‹åŒ–ç’°å¢ƒèˆ‡ä»£ç†äºº
env = GameEnv()
agent = SB3ReplayAgent(model_path="best_model/ppo_game2048_6666_final.zip")

state = env.reset()
done = False

while not done:
    # Agent æ±ºå®šå‹•ä½œ (explore=False ä»£è¡¨ä½¿ç”¨è¨“ç·´å¥½çš„æœ€ä½³ç­–ç•¥)
    action, _, _ = agent.act(state, explore=False)
    
    state, reward, done, info = env.step(action)
    
    if done:
        print("Game Over")
        print(f"Final Score: {info.get('passed_count', 0)}")
```

