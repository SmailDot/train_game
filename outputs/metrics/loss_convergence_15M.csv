tag,step,wall_time,value
env/win_rate(通關率),32768,1767850555.705423,0.0
env/win_rate(通關率),65536,1767850559.228526,0.0
env/win_rate(通關率),98304,1767850562.996143,0.0
env/win_rate(通關率),131072,1767850566.719327,0.0
env/win_rate(通關率),163840,1767850570.4483514,0.0
env/win_rate(通關率),196608,1767850574.1534498,0.0
env/win_rate(通關率),229376,1767850577.8905578,0.0
env/win_rate(通關率),262144,1767850581.583047,0.0
env/win_rate(通關率),294912,1767850585.2030509,0.0
env/win_rate(通關率),327680,1767850588.9230797,0.0
env/win_rate(通關率),360448,1767850592.6420286,0.0
env/win_rate(通關率),393216,1767850596.5343516,0.0
env/win_rate(通關率),425984,1767850600.2572355,0.0
env/win_rate(通關率),458752,1767850604.004208,0.0
env/win_rate(通關率),491520,1767850607.7767951,0.0
env/win_rate(通關率),524288,1767850611.5745854,0.0
env/win_rate(通關率),557056,1767850615.2046947,0.0
env/win_rate(通關率),589824,1767850618.933322,0.0
env/win_rate(通關率),622592,1767850622.619367,0.0
env/win_rate(通關率),655360,1767850626.3165457,0.0
env/win_rate(通關率),688128,1767850629.9219232,0.0
env/win_rate(通關率),720896,1767850633.6161911,0.0
env/win_rate(通關率),753664,1767850637.1983774,0.0
env/win_rate(通關率),786432,1767850640.8717477,0.0
env/win_rate(通關率),819200,1767850644.4654818,0.0
env/win_rate(通關率),851968,1767850648.1052475,0.0
env/win_rate(通關率),884736,1767850651.703579,0.0
env/win_rate(通關率),917504,1767850655.3435278,0.0
env/win_rate(通關率),950272,1767850659.0710485,0.0
env/win_rate(通關率),983040,1767850662.7455473,0.0
env/win_rate(通關率),1015808,1767850666.481074,0.0
env/win_rate(通關率),1048576,1767850670.1074698,0.0
env/win_rate(通關率),1081344,1767850673.8068314,0.0
env/win_rate(通關率),1114112,1767850677.3988,0.0
env/win_rate(通關率),1146880,1767850681.0832002,0.0
env/win_rate(通關率),1179648,1767850684.683882,0.0
env/win_rate(通關率),1212416,1767850688.3471098,0.0
env/win_rate(通關率),1245184,1767850692.0412767,0.0
env/win_rate(通關率),1277952,1767850695.7100718,0.0
env/win_rate(通關率),1310720,1767850699.3796778,0.0
env/win_rate(通關率),1343488,1767850703.1060586,0.0
env/win_rate(通關率),1376256,1767850706.7275863,0.009999999776482582
env/win_rate(通關率),1409024,1767850710.4058769,0.009999999776482582
env/win_rate(通關率),1441792,1767850713.9961836,0.009999999776482582
env/win_rate(通關率),1474560,1767850717.6598337,0.029999999329447746
env/win_rate(通關率),1507328,1767850721.2686496,0.029999999329447746
env/win_rate(通關率),1540096,1767850724.905224,0.05999999865889549
env/win_rate(通關率),1572864,1767850728.5152638,0.05999999865889549
env/win_rate(通關率),1600000,1767850737.0012846,0.07000000029802322
env/win_rate(通關率),1605632,1767850737.711769,0.07999999821186066
env/win_rate(通關率),1638400,1767850741.4428859,0.11999999731779099
env/win_rate(通關率),1671168,1767850745.071232,0.12999999523162842
env/win_rate(通關率),1703936,1767850748.701232,0.1599999964237213
env/win_rate(通關率),1736704,1767850752.3870256,0.17000000178813934
env/win_rate(通關率),1769472,1767850755.9522567,0.17000000178813934
env/win_rate(通關率),1802240,1767850759.612867,0.17000000178813934
env/win_rate(通關率),1835008,1767850763.1786482,0.1899999976158142
env/win_rate(通關率),1867776,1767850766.8146942,0.20000000298023224
env/win_rate(通關率),1900544,1767850770.3717258,0.20000000298023224
env/win_rate(通關率),1933312,1767850774.0567575,0.2199999988079071
env/win_rate(通關率),1966080,1767850777.6604764,0.20999999344348907
env/win_rate(通關率),1998848,1767850781.2761362,0.25
env/win_rate(通關率),2031616,1767850784.883305,0.25
env/win_rate(通關率),2064384,1767850788.4913623,0.25999999046325684
env/win_rate(通關率),2097152,1767850792.2032356,0.25
env/win_rate(通關率),2129920,1767850795.866282,0.20999999344348907
env/win_rate(通關率),2162688,1767850799.5272243,0.20000000298023224
env/win_rate(通關率),2195456,1767850803.2312806,0.18000000715255737
env/win_rate(通關率),2228224,1767850806.8434565,0.1599999964237213
env/win_rate(通關率),2260992,1767850810.455892,0.1599999964237213
env/win_rate(通關率),2293760,1767850814.0776038,0.18000000715255737
env/win_rate(通關率),2326528,1767850817.7324646,0.1899999976158142
env/win_rate(通關率),2359296,1767850821.3082688,0.1899999976158142
env/win_rate(通關率),2392064,1767850824.9743595,0.2199999988079071
env/win_rate(通關率),2424832,1767850828.55592,0.23000000417232513
env/win_rate(通關率),2457600,1767850832.2084389,0.25999999046325684
env/win_rate(通關率),2490368,1767850835.7887897,0.25999999046325684
env/win_rate(通關率),2523136,1767850839.410689,0.27000001072883606
env/win_rate(通關率),2555904,1767850842.9688787,0.27000001072883606
env/win_rate(通關率),2588672,1767850846.6125402,0.27000001072883606
env/win_rate(通關率),2621440,1767850850.1919608,0.23999999463558197
env/win_rate(通關率),2654208,1767850853.8263726,0.25
env/win_rate(通關率),2686976,1767850857.4195008,0.27000001072883606
env/win_rate(通關率),2719744,1767850861.3290613,0.2800000011920929
env/win_rate(通關率),2752512,1767850865.0908148,0.2800000011920929
env/win_rate(通關率),2785280,1767850869.031745,0.3100000023841858
env/win_rate(通關率),2818048,1767850872.8489573,0.3199999928474426
env/win_rate(通關率),2850816,1767850876.7107396,0.3799999952316284
env/win_rate(通關率),2883584,1767850880.4894252,0.4000000059604645
env/win_rate(通關率),2916352,1767850884.3961153,0.4300000071525574
env/win_rate(通關率),2949120,1767850888.1782212,0.4399999976158142
env/win_rate(通關率),2981888,1767850891.9776053,0.4699999988079071
env/win_rate(通關率),3014656,1767850895.7577431,0.46000000834465027
env/win_rate(通關率),3047424,1767850899.5806687,0.49000000953674316
env/win_rate(通關率),3080192,1767850903.3661573,0.5199999809265137
env/win_rate(通關率),3112960,1767850907.1832235,0.5
env/win_rate(通關率),3145728,1767850911.2433429,0.5199999809265137
env/win_rate(通關率),3178496,1767850915.1832602,0.4699999988079071
env/win_rate(通關率),3200000,1767850924.5230672,0.49000000953674316
env/win_rate(通關率),3211264,1767850925.8636262,0.47999998927116394
env/win_rate(通關率),3244032,1767850929.708885,0.47999998927116394
env/win_rate(通關率),3276800,1767850933.5472097,0.49000000953674316
env/win_rate(通關率),3309568,1767850937.467982,0.49000000953674316
env/win_rate(通關率),3342336,1767850941.3087542,0.5699999928474426
env/win_rate(通關率),3375104,1767850945.2962406,0.550000011920929
env/win_rate(通關率),3407872,1767850949.2080567,0.5799999833106995
env/win_rate(通關率),3440640,1767850952.9483771,0.5600000023841858
env/win_rate(通關率),3473408,1767850957.3175955,0.550000011920929
env/win_rate(通關率),3506176,1767850961.4267182,0.6100000143051147
env/win_rate(通關率),3538944,1767850965.30745,0.6200000047683716
env/win_rate(通關率),3571712,1767850969.296191,0.6100000143051147
env/win_rate(通關率),3604480,1767850972.9610317,0.6000000238418579
env/win_rate(通關率),3637248,1767850976.7373757,0.5899999737739563
env/win_rate(通關率),3670016,1767850980.5669193,0.6299999952316284
env/win_rate(通關率),3702784,1767850984.6186466,0.6399999856948853
env/win_rate(通關率),3735552,1767850988.6584132,0.6100000143051147
env/win_rate(通關率),3768320,1767850992.5548205,0.6100000143051147
env/win_rate(通關率),3801088,1767850996.5146782,0.550000011920929
env/win_rate(通關率),3833856,1767851000.422122,0.5299999713897705
env/win_rate(通關率),3866624,1767851004.6852853,0.5600000023841858
env/win_rate(通關率),3899392,1767851008.561874,0.550000011920929
env/win_rate(通關率),3932160,1767851012.599403,0.550000011920929
env/win_rate(通關率),3964928,1767851016.6966462,0.550000011920929
env/win_rate(通關率),3997696,1767851020.5565472,0.5400000214576721
env/win_rate(通關率),4030464,1767851024.2745268,0.5099999904632568
env/win_rate(通關率),4063232,1767851027.931706,0.550000011920929
env/win_rate(通關率),4096000,1767851031.6902683,0.5699999928474426
env/win_rate(通關率),4128768,1767851035.552128,0.5799999833106995
env/win_rate(通關率),4161536,1767851039.3616033,0.5199999809265137
env/win_rate(通關率),4194304,1767851043.1991954,0.5
env/win_rate(通關率),4227072,1767851047.1003935,0.5
env/win_rate(通關率),4259840,1767851050.8482265,0.44999998807907104
env/win_rate(通關率),4292608,1767851054.8405092,0.44999998807907104
env/win_rate(通關率),4325376,1767851058.8245432,0.46000000834465027
env/win_rate(通關率),4358144,1767851062.640887,0.44999998807907104
env/win_rate(通關率),4390912,1767851066.511372,0.46000000834465027
env/win_rate(通關率),4423680,1767851070.3151045,0.46000000834465027
env/win_rate(通關率),4456448,1767851074.1013825,0.47999998927116394
env/win_rate(通關率),4489216,1767851077.8736207,0.5
env/win_rate(通關率),4521984,1767851081.7243874,0.5400000214576721
env/win_rate(通關率),4554752,1767851085.5352962,0.5600000023841858
env/win_rate(通關率),4587520,1767851089.4027958,0.5600000023841858
env/win_rate(通關率),4620288,1767851093.227601,0.550000011920929
env/win_rate(通關率),4653056,1767851097.0151076,0.550000011920929
env/win_rate(通關率),4685824,1767851100.8662007,0.6100000143051147
env/win_rate(通關率),4718592,1767851104.6115327,0.5799999833106995
env/win_rate(通關率),4751360,1767851108.3256793,0.6100000143051147
env/win_rate(通關率),4784128,1767851112.1232119,0.6299999952316284
env/win_rate(通關率),4800000,1767851120.069484,0.6200000047683716
env/win_rate(通關率),4816896,1767851122.0869133,0.5899999737739563
env/win_rate(通關率),4849664,1767851125.9408178,0.5299999713897705
env/win_rate(通關率),4882432,1767851129.6968298,0.5
env/win_rate(通關率),4915200,1767851133.48323,0.49000000953674316
env/win_rate(通關率),4947968,1767851137.2527626,0.41999998688697815
env/win_rate(通關率),4980736,1767851141.0984478,0.36000001430511475
env/win_rate(通關率),5013504,1767851144.8310637,0.33000001311302185
env/win_rate(通關率),5046272,1767851148.5421064,0.3499999940395355
env/win_rate(通關率),5079040,1767851152.4135032,0.4000000059604645
env/win_rate(通關率),5111808,1767851156.2059376,0.4000000059604645
env/win_rate(通關率),5144576,1767851159.8980644,0.4300000071525574
env/win_rate(通關率),5177344,1767851163.7191901,0.41999998688697815
env/win_rate(通關率),5210112,1767851167.4530969,0.4399999976158142
env/win_rate(通關率),5242880,1767851171.206861,0.44999998807907104
env/win_rate(通關率),5275648,1767851174.9225078,0.49000000953674316
env/win_rate(通關率),5308416,1767851178.7835948,0.47999998927116394
env/win_rate(通關率),5341184,1767851182.6305401,0.38999998569488525
env/win_rate(通關率),5373952,1767851186.3842208,0.3499999940395355
env/win_rate(通關率),5406720,1767851190.255159,0.33000001311302185
env/win_rate(通關率),5439488,1767851194.0659354,0.33000001311302185
env/win_rate(通關率),5472256,1767851197.8260283,0.30000001192092896
env/win_rate(通關率),5505024,1767851201.6629026,0.30000001192092896
env/win_rate(通關率),5537792,1767851205.4095185,0.33000001311302185
env/win_rate(通關率),5570560,1767851209.1642163,0.33000001311302185
env/win_rate(通關率),5603328,1767851212.9930987,0.3499999940395355
env/win_rate(通關率),5636096,1767851216.7795317,0.4099999964237213
env/win_rate(通關率),5668864,1767851220.50399,0.41999998688697815
env/win_rate(通關率),5701632,1767851224.3482041,0.4699999988079071
env/win_rate(通關率),5734400,1767851228.1825051,0.49000000953674316
env/win_rate(通關率),5767168,1767851231.940569,0.5
env/win_rate(通關率),5799936,1767851235.8235393,0.5199999809265137
env/win_rate(通關率),5832704,1767851239.639634,0.49000000953674316
env/win_rate(通關率),5865472,1767851243.3867345,0.5199999809265137
env/win_rate(通關率),5898240,1767851247.2597299,0.49000000953674316
env/win_rate(通關率),5931008,1767851251.0267448,0.4699999988079071
env/win_rate(通關率),5963776,1767851254.8078127,0.44999998807907104
env/win_rate(通關率),5996544,1767851258.8188546,0.4099999964237213
env/win_rate(通關率),6029312,1767851262.7803826,0.4099999964237213
env/win_rate(通關率),6062080,1767851266.7045023,0.4300000071525574
env/win_rate(通關率),6094848,1767851270.5552242,0.4399999976158142
env/win_rate(通關率),6127616,1767851274.4984272,0.4699999988079071
env/win_rate(通關率),6160384,1767851278.5352979,0.46000000834465027
env/win_rate(通關率),6193152,1767851282.496792,0.49000000953674316
env/win_rate(通關率),6225920,1767851286.371077,0.5099999904632568
env/win_rate(通關率),6258688,1767851290.2993336,0.5600000023841858
env/win_rate(通關率),6291456,1767851294.1221151,0.5600000023841858
env/win_rate(通關率),6324224,1767851298.0558202,0.6100000143051147
env/win_rate(通關率),6356992,1767851301.9332805,0.550000011920929
env/win_rate(通關率),6389760,1767851305.9010336,0.550000011920929
env/win_rate(通關率),6400000,1767851311.462924,0.5299999713897705
env/win_rate(通關率),6422528,1767851314.32162,0.5400000214576721
env/win_rate(通關率),6455296,1767851318.2926252,0.550000011920929
env/win_rate(通關率),6488064,1767851322.189184,0.5799999833106995
env/win_rate(通關率),6520832,1767851326.0816662,0.5600000023841858
env/win_rate(通關率),6553600,1767851329.9729526,0.550000011920929
env/win_rate(通關率),6586368,1767851333.914084,0.550000011920929
env/win_rate(通關率),6619136,1767851337.7628021,0.49000000953674316
env/win_rate(通關率),6651904,1767851341.701503,0.5299999713897705
env/win_rate(通關率),6684672,1767851345.6731632,0.5799999833106995
env/win_rate(通關率),6717440,1767851349.560387,0.550000011920929
env/win_rate(通關率),6750208,1767851353.5039809,0.5400000214576721
env/win_rate(通關率),6782976,1767851357.4343462,0.5400000214576721
env/win_rate(通關率),6815744,1767851361.2815995,0.5199999809265137
env/win_rate(通關率),6848512,1767851365.1255405,0.47999998927116394
env/win_rate(通關率),6881280,1767851369.1308281,0.5
env/win_rate(通關率),6914048,1767851373.0831103,0.4699999988079071
env/win_rate(通關率),6946816,1767851376.9331527,0.4699999988079071
env/win_rate(通關率),6979584,1767851380.8888044,0.49000000953674316
env/win_rate(通關率),7012352,1767851384.8043604,0.5
env/win_rate(通關率),7045120,1767851388.6258478,0.5099999904632568
env/win_rate(通關率),7077888,1767851392.4364486,0.5299999713897705
env/win_rate(通關率),7110656,1767851396.205339,0.5600000023841858
env/win_rate(通關率),7143424,1767851400.0019038,0.5600000023841858
env/win_rate(通關率),7176192,1767851403.8091478,0.6000000238418579
env/win_rate(通關率),7208960,1767851407.556572,0.5899999737739563
env/win_rate(通關率),7241728,1767851411.3092682,0.6299999952316284
env/win_rate(通關率),7274496,1767851415.177134,0.6200000047683716
env/win_rate(通關率),7307264,1767851418.9848976,0.6499999761581421
env/win_rate(通關率),7340032,1767851422.7503793,0.6499999761581421
env/win_rate(通關率),7372800,1767851426.6533804,0.6399999856948853
env/win_rate(通關率),7405568,1767851430.4099774,0.6299999952316284
env/win_rate(通關率),7438336,1767851434.2522728,0.6100000143051147
env/win_rate(通關率),7471104,1767851438.0266423,0.6299999952316284
env/win_rate(通關率),7503872,1767851441.8613071,0.6200000047683716
env/win_rate(通關率),7536640,1767851445.6970434,0.6100000143051147
env/win_rate(通關率),7569408,1767851449.6036465,0.6299999952316284
env/win_rate(通關率),7602176,1767851453.3829386,0.6299999952316284
env/win_rate(通關率),7634944,1767851457.202003,0.6100000143051147
env/win_rate(通關率),7667712,1767851461.0313587,0.6000000238418579
env/win_rate(通關率),7700480,1767851464.834783,0.6000000238418579
env/win_rate(通關率),7733248,1767851468.6625133,0.6299999952316284
env/win_rate(通關率),7766016,1767851472.5622845,0.5799999833106995
env/win_rate(通關率),7798784,1767851476.4400105,0.5699999928474426
env/win_rate(通關率),7831552,1767851480.220457,0.5299999713897705
env/win_rate(通關率),7864320,1767851484.0781865,0.5
env/win_rate(通關率),7897088,1767851487.9261947,0.5
env/win_rate(通關率),7929856,1767851491.717675,0.5099999904632568
env/win_rate(通關率),7962624,1767851495.5764532,0.5
env/win_rate(通關率),7995392,1767851499.3429677,0.5
env/win_rate(通關率),8000000,1767851506.12033,0.49000000953674316
env/win_rate(通關率),8028160,1767851509.486613,0.49000000953674316
env/win_rate(通關率),8060928,1767851513.3896632,0.5
env/win_rate(通關率),8093696,1767851517.216103,0.5099999904632568
env/win_rate(通關率),8126464,1767851521.0065434,0.5299999713897705
env/win_rate(通關率),8159232,1767851524.8318646,0.5299999713897705
env/win_rate(通關率),8192000,1767851528.6107416,0.5299999713897705
env/win_rate(通關率),8224768,1767851532.4548416,0.5199999809265137
env/win_rate(通關率),8257536,1767851536.3604865,0.5299999713897705
env/win_rate(通關率),8290304,1767851540.1405644,0.5299999713897705
env/win_rate(通關率),8323072,1767851543.9752173,0.49000000953674316
env/win_rate(通關率),8355840,1767851547.7974606,0.46000000834465027
env/win_rate(通關率),8388608,1767851551.5882347,0.44999998807907104
env/win_rate(通關率),8421376,1767851555.4249458,0.46000000834465027
env/win_rate(通關率),8454144,1767851559.163552,0.49000000953674316
env/win_rate(通關率),8486912,1767851562.9092748,0.47999998927116394
env/win_rate(通關率),8519680,1767851566.6495507,0.4699999988079071
env/win_rate(通關率),8552448,1767851570.5102527,0.44999998807907104
env/win_rate(通關率),8585216,1767851574.3190894,0.46000000834465027
env/win_rate(通關率),8617984,1767851578.10446,0.4699999988079071
env/win_rate(通關率),8650752,1767851581.9328792,0.46000000834465027
env/win_rate(通關率),8683520,1767851585.6849768,0.4399999976158142
env/win_rate(通關率),8716288,1767851589.452577,0.38999998569488525
env/win_rate(通關率),8749056,1767851593.3209686,0.38999998569488525
env/win_rate(通關率),8781824,1767851597.117463,0.4399999976158142
env/win_rate(通關率),8814592,1767851600.8884895,0.3799999952316284
env/win_rate(通關率),8847360,1767851604.7922852,0.36000001430511475
env/win_rate(通關率),8880128,1767851608.6254165,0.3400000035762787
env/win_rate(通關率),8912896,1767851612.5267959,0.36000001430511475
env/win_rate(通關率),8945664,1767851616.3148751,0.4000000059604645
env/win_rate(通關率),8978432,1767851620.060589,0.38999998569488525
env/win_rate(通關率),9011200,1767851623.9150236,0.38999998569488525
env/win_rate(通關率),9043968,1767851627.6861043,0.3700000047683716
env/win_rate(通關率),9076736,1767851631.4564013,0.41999998688697815
env/win_rate(通關率),9109504,1767851635.3077714,0.46000000834465027
env/win_rate(通關率),9142272,1767851639.1065817,0.49000000953674316
env/win_rate(通關率),9175040,1767851642.8536239,0.5
env/win_rate(通關率),9207808,1767851646.7242799,0.49000000953674316
env/win_rate(通關率),9240576,1767851650.5223844,0.5
env/win_rate(通關率),9273344,1767851654.3266377,0.5
env/win_rate(通關率),9306112,1767851658.1292422,0.5099999904632568
env/win_rate(通關率),9338880,1767851661.9003403,0.5099999904632568
env/win_rate(通關率),9371648,1767851665.6797972,0.47999998927116394
env/win_rate(通關率),9404416,1767851669.5427177,0.46000000834465027
env/win_rate(通關率),9437184,1767851673.3655446,0.41999998688697815
env/win_rate(通關率),9469952,1767851677.180017,0.4099999964237213
env/win_rate(通關率),9502720,1767851680.9703443,0.4000000059604645
env/win_rate(通關率),9535488,1767851684.754203,0.41999998688697815
env/win_rate(通關率),9568256,1767851688.5870562,0.4399999976158142
env/win_rate(通關率),9600000,1767851698.600738,0.46000000834465027
env/win_rate(通關率),9601024,1767851698.7403507,0.46000000834465027
env/win_rate(通關率),9633792,1767851702.5447552,0.5
env/win_rate(通關率),9666560,1767851706.3297298,0.5299999713897705
env/win_rate(通關率),9699328,1767851710.1771321,0.5199999809265137
env/win_rate(通關率),9732096,1767851713.9104607,0.5400000214576721
env/win_rate(通關率),9764864,1767851717.6755009,0.5600000023841858
env/win_rate(通關率),9797632,1767851721.4707024,0.550000011920929
env/win_rate(通關率),9830400,1767851725.2913725,0.550000011920929
env/win_rate(通關率),9863168,1767851729.1063426,0.5
env/win_rate(通關率),9895936,1767851732.8964748,0.5099999904632568
env/win_rate(通關率),9928704,1767851736.723532,0.5099999904632568
env/win_rate(通關率),9961472,1767851740.5198991,0.49000000953674316
env/win_rate(通關率),9994240,1767851744.2771597,0.46000000834465027
env/win_rate(通關率),10027008,1767851748.0839155,0.44999998807907104
env/win_rate(通關率),10059776,1767851751.8725479,0.4699999988079071
env/win_rate(通關率),10092544,1767851755.6664157,0.49000000953674316
env/win_rate(通關率),10125312,1767851759.5029423,0.49000000953674316
env/win_rate(通關率),10158080,1767851763.2659757,0.49000000953674316
env/win_rate(通關率),10190848,1767851767.0469668,0.49000000953674316
env/win_rate(通關率),10223616,1767851770.8760586,0.49000000953674316
env/win_rate(通關率),10256384,1767851774.7005332,0.5199999809265137
env/win_rate(通關率),10289152,1767851778.5006182,0.5
env/win_rate(通關率),10321920,1767851782.3109753,0.46000000834465027
env/win_rate(通關率),10354688,1767851786.103872,0.4099999964237213
env/win_rate(通關率),10387456,1767851789.889282,0.38999998569488525
env/win_rate(通關率),10420224,1767851793.661537,0.3700000047683716
env/win_rate(通關率),10452992,1767851797.5050159,0.3799999952316284
env/win_rate(通關率),10485760,1767851801.2503831,0.3799999952316284
env/win_rate(通關率),10518528,1767851805.0712113,0.36000001430511475
env/win_rate(通關率),10551296,1767851808.8688548,0.36000001430511475
env/win_rate(通關率),10584064,1767851812.6389425,0.3700000047683716
env/win_rate(通關率),10616832,1767851816.490222,0.3799999952316284
env/win_rate(通關率),10649600,1767851820.25121,0.41999998688697815
env/win_rate(通關率),10682368,1767851824.0040731,0.4099999964237213
env/win_rate(通關率),10715136,1767851827.861113,0.4000000059604645
env/win_rate(通關率),10747904,1767851831.6708193,0.3799999952316284
env/win_rate(通關率),10780672,1767851835.4792118,0.4099999964237213
env/win_rate(通關率),10813440,1767851839.280336,0.4099999964237213
env/win_rate(通關率),10846208,1767851843.065974,0.44999998807907104
env/win_rate(通關率),10878976,1767851846.8648553,0.4699999988079071
env/win_rate(通關率),10911744,1767851850.6482563,0.44999998807907104
env/win_rate(通關率),10944512,1767851854.4339461,0.4399999976158142
env/win_rate(通關率),10977280,1767851858.2310927,0.44999998807907104
env/win_rate(通關率),11010048,1767851862.1134384,0.4699999988079071
env/win_rate(通關率),11042816,1767851865.956484,0.4699999988079071
env/win_rate(通關率),11075584,1767851869.897537,0.44999998807907104
env/win_rate(通關率),11108352,1767851873.7397423,0.4099999964237213
env/win_rate(通關率),11141120,1767851877.6540227,0.3799999952316284
env/win_rate(通關率),11173888,1767851881.5055263,0.38999998569488525
env/win_rate(通關率),11200000,1767851890.859954,0.3799999952316284
env/win_rate(通關率),11206656,1767851891.719144,0.3799999952316284
env/win_rate(通關率),11239424,1767851895.6584544,0.36000001430511475
env/win_rate(通關率),11272192,1767851899.437363,0.3700000047683716
env/win_rate(通關率),11304960,1767851903.2367744,0.3799999952316284
env/win_rate(通關率),11337728,1767851907.0456638,0.3700000047683716
env/win_rate(通關率),11370496,1767851910.8145862,0.4000000059604645
env/win_rate(通關率),11403264,1767851914.5965257,0.3799999952316284
env/win_rate(通關率),11436032,1767851918.434133,0.3799999952316284
env/win_rate(通關率),11468800,1767851922.2353313,0.3400000035762787
env/win_rate(通關率),11501568,1767851926.0057366,0.30000001192092896
env/win_rate(通關率),11534336,1767851929.8337362,0.28999999165534973
env/win_rate(通關率),11567104,1767851933.6304746,0.30000001192092896
env/win_rate(通關率),11599872,1767851937.4094367,0.30000001192092896
env/win_rate(通關率),11632640,1767851941.2539635,0.27000001072883606
env/win_rate(通關率),11665408,1767851945.0449657,0.27000001072883606
env/win_rate(通關率),11698176,1767851948.827807,0.2800000011920929
env/win_rate(通關率),11730944,1767851952.6740668,0.23999999463558197
env/win_rate(通關率),11763712,1767851956.4674273,0.23999999463558197
env/win_rate(通關率),11796480,1767851960.358683,0.25
env/win_rate(通關率),11829248,1767851964.2478104,0.25999999046325684
env/win_rate(通關率),11862016,1767851968.0738328,0.33000001311302185
env/win_rate(通關率),11894784,1767851971.9493694,0.3199999928474426
env/win_rate(通關率),11927552,1767851975.8429923,0.3499999940395355
env/win_rate(通關率),11960320,1767851979.655874,0.3499999940395355
env/win_rate(通關率),11993088,1767851983.4819186,0.36000001430511475
env/win_rate(通關率),12025856,1767851987.3343585,0.3400000035762787
env/win_rate(通關率),12058624,1767851991.2070632,0.27000001072883606
env/win_rate(通關率),12091392,1767851995.0093503,0.25999999046325684
env/win_rate(通關率),12124160,1767851998.8575733,0.2800000011920929
env/win_rate(通關率),12156928,1767852002.723118,0.30000001192092896
env/win_rate(通關率),12189696,1767852006.6192544,0.3199999928474426
env/win_rate(通關率),12222464,1767852010.4443982,0.33000001311302185
env/win_rate(通關率),12255232,1767852014.2415743,0.33000001311302185
env/win_rate(通關率),12288000,1767852018.0783741,0.3400000035762787
env/win_rate(通關率),12320768,1767852021.9408715,0.36000001430511475
env/win_rate(通關率),12353536,1767852025.8486497,0.3700000047683716
env/win_rate(通關率),12386304,1767852029.716671,0.3499999940395355
env/win_rate(通關率),12419072,1767852033.6132348,0.3400000035762787
env/win_rate(通關率),12451840,1767852037.411729,0.3400000035762787
env/win_rate(通關率),12484608,1767852041.2448833,0.38999998569488525
env/win_rate(通關率),12517376,1767852045.0343423,0.38999998569488525
env/win_rate(通關率),12550144,1767852048.8760827,0.33000001311302185
env/win_rate(通關率),12582912,1767852052.7375727,0.30000001192092896
env/win_rate(通關率),12615680,1767852056.60109,0.3199999928474426
env/win_rate(通關率),12648448,1767852060.4723964,0.28999999165534973
env/win_rate(通關率),12681216,1767852064.3369222,0.23000000417232513
env/win_rate(通關率),12713984,1767852068.303477,0.20999999344348907
env/win_rate(通關率),12746752,1767852072.1466877,0.2199999988079071
env/win_rate(通關率),12779520,1767852076.0867941,0.20000000298023224
env/win_rate(通關率),12800000,1767852083.843321,0.17000000178813934
env/win_rate(通關率),12812288,1767852085.342652,0.18000000715255737
env/win_rate(通關率),12845056,1767852089.3506994,0.17000000178813934
env/win_rate(通關率),12877824,1767852093.240537,0.20000000298023224
env/win_rate(通關率),12910592,1767852097.047181,0.20999999344348907
env/win_rate(通關率),12943360,1767852100.8524952,0.23000000417232513
env/win_rate(通關率),12976128,1767852104.6656787,0.2199999988079071
env/win_rate(通關率),13008896,1767852108.5615203,0.23999999463558197
env/win_rate(通關率),13041664,1767852112.3818095,0.2199999988079071
env/win_rate(通關率),13074432,1767852116.144301,0.23000000417232513
env/win_rate(通關率),13107200,1767852119.9847195,0.20000000298023224
env/win_rate(通關率),13139968,1767852123.7673254,0.20000000298023224
env/win_rate(通關率),13172736,1767852127.555611,0.20999999344348907
env/win_rate(通關率),13205504,1767852131.4294608,0.25999999046325684
env/win_rate(通關率),13238272,1767852135.2610745,0.25
env/win_rate(通關率),13271040,1767852139.1296704,0.3199999928474426
env/win_rate(通關率),13303808,1767852142.939284,0.3499999940395355
env/win_rate(通關率),13336576,1767852146.6933453,0.36000001430511475
env/win_rate(通關率),13369344,1767852150.5655675,0.38999998569488525
env/win_rate(通關率),13402112,1767852154.337042,0.4099999964237213
env/win_rate(通關率),13434880,1767852158.1100445,0.41999998688697815
env/win_rate(通關率),13467648,1767852161.9528158,0.41999998688697815
env/win_rate(通關率),13500416,1767852165.7732508,0.46000000834465027
env/win_rate(通關率),13533184,1767852169.5396895,0.4699999988079071
env/win_rate(通關率),13565952,1767852173.3529642,0.4699999988079071
env/win_rate(通關率),13598720,1767852177.1586583,0.47999998927116394
env/win_rate(通關率),13631488,1767852180.9323645,0.49000000953674316
env/win_rate(通關率),13664256,1767852184.7686446,0.47999998927116394
env/win_rate(通關率),13697024,1767852188.5371807,0.5099999904632568
env/win_rate(通關率),13729792,1767852192.3260584,0.5299999713897705
env/win_rate(通關率),13762560,1767852196.1565945,0.5299999713897705
env/win_rate(通關率),13795328,1767852199.9392993,0.5199999809265137
env/win_rate(通關率),13828096,1767852203.7457683,0.5
env/win_rate(通關率),13860864,1767852207.5603771,0.47999998927116394
env/win_rate(通關率),13893632,1767852211.3222716,0.46000000834465027
env/win_rate(通關率),13926400,1767852215.117207,0.4399999976158142
env/win_rate(通關率),13959168,1767852218.9593084,0.38999998569488525
env/win_rate(通關率),13991936,1767852222.7497587,0.3799999952316284
env/win_rate(通關率),14024704,1767852226.5376217,0.3400000035762787
env/win_rate(通關率),14057472,1767852230.341306,0.3400000035762787
env/win_rate(通關率),14090240,1767852234.1532724,0.3700000047683716
env/win_rate(通關率),14123008,1767852237.9555166,0.36000001430511475
env/win_rate(通關率),14155776,1767852241.7709186,0.33000001311302185
env/win_rate(通關率),14188544,1767852245.580831,0.36000001430511475
env/win_rate(通關率),14221312,1767852249.4112377,0.3799999952316284
env/win_rate(通關率),14254080,1767852253.1772535,0.4099999964237213
env/win_rate(通關率),14286848,1767852256.9677918,0.41999998688697815
env/win_rate(通關率),14319616,1767852260.8131015,0.41999998688697815
env/win_rate(通關率),14352384,1767852264.6120255,0.4000000059604645
env/win_rate(通關率),14385152,1767852268.473499,0.4399999976158142
env/win_rate(通關率),14400000,1767852276.521322,0.4399999976158142
env/win_rate(通關率),14417920,1767852278.6587572,0.4699999988079071
env/win_rate(通關率),14450688,1767852282.5740464,0.47999998927116394
env/win_rate(通關率),14483456,1767852286.3921025,0.44999998807907104
env/win_rate(通關率),14516224,1767852290.2720983,0.4699999988079071
env/win_rate(通關率),14548992,1767852294.1244688,0.49000000953674316
env/win_rate(通關率),14581760,1767852297.9144642,0.46000000834465027
env/win_rate(通關率),14614528,1767852301.7823184,0.4699999988079071
env/win_rate(通關率),14647296,1767852305.590244,0.4399999976158142
env/win_rate(通關率),14680064,1767852309.4423165,0.38999998569488525
env/win_rate(通關率),14712832,1767852313.3254573,0.38999998569488525
env/win_rate(通關率),14745600,1767852317.128722,0.38999998569488525
env/win_rate(通關率),14778368,1767852320.9527233,0.4000000059604645
env/win_rate(通關率),14811136,1767852324.7873342,0.38999998569488525
env/win_rate(通關率),14843904,1767852328.6576471,0.4099999964237213
env/win_rate(通關率),14876672,1767852332.519666,0.4300000071525574
env/win_rate(通關率),14909440,1767852336.2900808,0.46000000834465027
env/win_rate(通關率),14942208,1767852340.1513834,0.4699999988079071
env/win_rate(通關率),14974976,1767852343.9663556,0.49000000953674316
env/win_rate(通關率),15007744,1767852347.8196182,0.49000000953674316
rollout/ep_rew_mean(平均回合獎勵),32768,1767850555.705423,-2.3606395721435547
rollout/ep_rew_mean(平均回合獎勵),65536,1767850559.228526,-2.416320323944092
rollout/ep_rew_mean(平均回合獎勵),98304,1767850562.996143,1.588672161102295
rollout/ep_rew_mean(平均回合獎勵),131072,1767850566.719327,2.680746078491211
rollout/ep_rew_mean(平均回合獎勵),163840,1767850570.4483514,7.924005031585693
rollout/ep_rew_mean(平均回合獎勵),196608,1767850574.1534498,13.55927848815918
rollout/ep_rew_mean(平均回合獎勵),229376,1767850577.8905578,26.690101623535156
rollout/ep_rew_mean(平均回合獎勵),262144,1767850581.583047,59.48430252075195
rollout/ep_rew_mean(平均回合獎勵),294912,1767850585.2030509,101.22660827636719
rollout/ep_rew_mean(平均回合獎勵),327680,1767850588.9230797,121.54461669921875
rollout/ep_rew_mean(平均回合獎勵),360448,1767850592.6420286,134.73403930664062
rollout/ep_rew_mean(平均回合獎勵),393216,1767850596.5343516,168.8619384765625
rollout/ep_rew_mean(平均回合獎勵),425984,1767850600.2572355,204.99652099609375
rollout/ep_rew_mean(平均回合獎勵),458752,1767850604.004208,268.491943359375
rollout/ep_rew_mean(平均回合獎勵),491520,1767850607.7767951,295.8313903808594
rollout/ep_rew_mean(平均回合獎勵),524288,1767850611.5745854,383.02947998046875
rollout/ep_rew_mean(平均回合獎勵),557056,1767850615.2046947,385.59246826171875
rollout/ep_rew_mean(平均回合獎勵),589824,1767850618.933322,448.8443298339844
rollout/ep_rew_mean(平均回合獎勵),622592,1767850622.619367,584.61376953125
rollout/ep_rew_mean(平均回合獎勵),655360,1767850626.3165457,648.7349853515625
rollout/ep_rew_mean(平均回合獎勵),688128,1767850629.9219232,749.5711669921875
rollout/ep_rew_mean(平均回合獎勵),720896,1767850633.6161911,808.1408081054688
rollout/ep_rew_mean(平均回合獎勵),753664,1767850637.1983774,830.7431030273438
rollout/ep_rew_mean(平均回合獎勵),786432,1767850640.8717477,891.3158569335938
rollout/ep_rew_mean(平均回合獎勵),819200,1767850644.4654818,956.9095458984375
rollout/ep_rew_mean(平均回合獎勵),851968,1767850648.1052475,1045.1190185546875
rollout/ep_rew_mean(平均回合獎勵),884736,1767850651.703579,1122.0350341796875
rollout/ep_rew_mean(平均回合獎勵),917504,1767850655.3435278,1190.1702880859375
rollout/ep_rew_mean(平均回合獎勵),950272,1767850659.0710485,1371.770263671875
rollout/ep_rew_mean(平均回合獎勵),983040,1767850662.7455473,1392.3370361328125
rollout/ep_rew_mean(平均回合獎勵),1015808,1767850666.481074,1463.986083984375
rollout/ep_rew_mean(平均回合獎勵),1048576,1767850670.1074698,1412.8011474609375
rollout/ep_rew_mean(平均回合獎勵),1081344,1767850673.8068314,1510.1343994140625
rollout/ep_rew_mean(平均回合獎勵),1114112,1767850677.3988,1618.1368408203125
rollout/ep_rew_mean(平均回合獎勵),1146880,1767850681.0832002,1686.522216796875
rollout/ep_rew_mean(平均回合獎勵),1179648,1767850684.683882,1764.3690185546875
rollout/ep_rew_mean(平均回合獎勵),1212416,1767850688.3471098,1802.1639404296875
rollout/ep_rew_mean(平均回合獎勵),1245184,1767850692.0412767,1796.0068359375
rollout/ep_rew_mean(平均回合獎勵),1277952,1767850695.7100718,1972.1541748046875
rollout/ep_rew_mean(平均回合獎勵),1310720,1767850699.3796778,2106.549072265625
rollout/ep_rew_mean(平均回合獎勵),1343488,1767850703.1060586,2150.46240234375
rollout/ep_rew_mean(平均回合獎勵),1376256,1767850706.7275863,2284.111328125
rollout/ep_rew_mean(平均回合獎勵),1409024,1767850710.4058769,2261.262451171875
rollout/ep_rew_mean(平均回合獎勵),1441792,1767850713.9961836,2259.272705078125
rollout/ep_rew_mean(平均回合獎勵),1474560,1767850717.6608357,2496.8447265625
rollout/ep_rew_mean(平均回合獎勵),1507328,1767850721.2686496,2580.877685546875
rollout/ep_rew_mean(平均回合獎勵),1540096,1767850724.905224,2841.4814453125
rollout/ep_rew_mean(平均回合獎勵),1572864,1767850728.5152638,2898.089599609375
rollout/ep_rew_mean(平均回合獎勵),1605632,1767850737.711769,3017.6142578125
rollout/ep_rew_mean(平均回合獎勵),1638400,1767850741.4428859,3228.177734375
rollout/ep_rew_mean(平均回合獎勵),1671168,1767850745.0722322,3444.7197265625
rollout/ep_rew_mean(平均回合獎勵),1703936,1767850748.701232,3594.777587890625
rollout/ep_rew_mean(平均回合獎勵),1736704,1767850752.3870256,3697.094482421875
rollout/ep_rew_mean(平均回合獎勵),1769472,1767850755.9522567,3765.2685546875
rollout/ep_rew_mean(平均回合獎勵),1802240,1767850759.612867,3828.490966796875
rollout/ep_rew_mean(平均回合獎勵),1835008,1767850763.1786482,4029.5302734375
rollout/ep_rew_mean(平均回合獎勵),1867776,1767850766.815694,4103.486328125
rollout/ep_rew_mean(平均回合獎勵),1900544,1767850770.3717258,4061.64990234375
rollout/ep_rew_mean(平均回合獎勵),1933312,1767850774.0567575,4048.406982421875
rollout/ep_rew_mean(平均回合獎勵),1966080,1767850777.6604764,4054.289306640625
rollout/ep_rew_mean(平均回合獎勵),1998848,1767850781.2761362,4217.15771484375
rollout/ep_rew_mean(平均回合獎勵),2031616,1767850784.883305,4138.15673828125
rollout/ep_rew_mean(平均回合獎勵),2064384,1767850788.4913623,4172.0
rollout/ep_rew_mean(平均回合獎勵),2097152,1767850792.2032356,4217.955078125
rollout/ep_rew_mean(平均回合獎勵),2129920,1767850795.866282,3968.21728515625
rollout/ep_rew_mean(平均回合獎勵),2162688,1767850799.5272243,3924.317138671875
rollout/ep_rew_mean(平均回合獎勵),2195456,1767850803.2312806,3789.113037109375
rollout/ep_rew_mean(平均回合獎勵),2228224,1767850806.8434565,3701.939453125
rollout/ep_rew_mean(平均回合獎勵),2260992,1767850810.455892,3681.1240234375
rollout/ep_rew_mean(平均回合獎勵),2293760,1767850814.0776038,3695.890869140625
rollout/ep_rew_mean(平均回合獎勵),2326528,1767850817.7324646,3711.588134765625
rollout/ep_rew_mean(平均回合獎勵),2359296,1767850821.3082688,3815.468994140625
rollout/ep_rew_mean(平均回合獎勵),2392064,1767850824.9743595,4015.36474609375
rollout/ep_rew_mean(平均回合獎勵),2424832,1767850828.55592,4110.5966796875
rollout/ep_rew_mean(平均回合獎勵),2457600,1767850832.2084389,4235.76611328125
rollout/ep_rew_mean(平均回合獎勵),2490368,1767850835.7887897,4278.00927734375
rollout/ep_rew_mean(平均回合獎勵),2523136,1767850839.410689,4329.6455078125
rollout/ep_rew_mean(平均回合獎勵),2555904,1767850842.9688787,4284.24365234375
rollout/ep_rew_mean(平均回合獎勵),2588672,1767850846.6125402,4137.45947265625
rollout/ep_rew_mean(平均回合獎勵),2621440,1767850850.1919608,4034.771484375
rollout/ep_rew_mean(平均回合獎勵),2654208,1767850853.8263726,3984.26416015625
rollout/ep_rew_mean(平均回合獎勵),2686976,1767850857.4195008,3975.468505859375
rollout/ep_rew_mean(平均回合獎勵),2719744,1767850861.3290613,4022.609619140625
rollout/ep_rew_mean(平均回合獎勵),2752512,1767850865.0908148,4062.396484375
rollout/ep_rew_mean(平均回合獎勵),2785280,1767850869.031745,4292.931640625
rollout/ep_rew_mean(平均回合獎勵),2818048,1767850872.8489573,4310.5185546875
rollout/ep_rew_mean(平均回合獎勵),2850816,1767850876.7107396,4685.392578125
rollout/ep_rew_mean(平均回合獎勵),2883584,1767850880.4894252,4841.52978515625
rollout/ep_rew_mean(平均回合獎勵),2916352,1767850884.3961153,5023.99658203125
rollout/ep_rew_mean(平均回合獎勵),2949120,1767850888.1782212,5133.73046875
rollout/ep_rew_mean(平均回合獎勵),2981888,1767850891.9776053,5315.92431640625
rollout/ep_rew_mean(平均回合獎勵),3014656,1767850895.7577431,5310.3974609375
rollout/ep_rew_mean(平均回合獎勵),3047424,1767850899.5806687,5324.73828125
rollout/ep_rew_mean(平均回合獎勵),3080192,1767850903.3661573,5477.8017578125
rollout/ep_rew_mean(平均回合獎勵),3112960,1767850907.1832235,5395.17822265625
rollout/ep_rew_mean(平均回合獎勵),3145728,1767850911.2433429,5575.7373046875
rollout/ep_rew_mean(平均回合獎勵),3178496,1767850915.1832602,5394.3779296875
rollout/ep_rew_mean(平均回合獎勵),3211264,1767850925.8636262,5454.69482421875
rollout/ep_rew_mean(平均回合獎勵),3244032,1767850929.708885,5444.2919921875
rollout/ep_rew_mean(平均回合獎勵),3276800,1767850933.5472097,5474.8486328125
rollout/ep_rew_mean(平均回合獎勵),3309568,1767850937.467982,5538.14794921875
rollout/ep_rew_mean(平均回合獎勵),3342336,1767850941.3087542,5796.560546875
rollout/ep_rew_mean(平均回合獎勵),3375104,1767850945.2962406,5776.62646484375
rollout/ep_rew_mean(平均回合獎勵),3407872,1767850949.2080567,5905.51953125
rollout/ep_rew_mean(平均回合獎勵),3440640,1767850952.9483771,5692.54833984375
rollout/ep_rew_mean(平均回合獎勵),3473408,1767850957.3175955,5532.2138671875
rollout/ep_rew_mean(平均回合獎勵),3506176,1767850961.4267182,5735.25439453125
rollout/ep_rew_mean(平均回合獎勵),3538944,1767850965.30745,5701.8994140625
rollout/ep_rew_mean(平均回合獎勵),3571712,1767850969.296191,5547.06494140625
rollout/ep_rew_mean(平均回合獎勵),3604480,1767850972.9610317,5418.24755859375
rollout/ep_rew_mean(平均回合獎勵),3637248,1767850976.7373757,5437.541015625
rollout/ep_rew_mean(平均回合獎勵),3670016,1767850980.5669193,5645.0537109375
rollout/ep_rew_mean(平均回合獎勵),3702784,1767850984.6186466,5770.96923828125
rollout/ep_rew_mean(平均回合獎勵),3735552,1767850988.6584132,5602.9814453125
rollout/ep_rew_mean(平均回合獎勵),3768320,1767850992.5548205,5585.599609375
rollout/ep_rew_mean(平均回合獎勵),3801088,1767850996.5146782,5272.5888671875
rollout/ep_rew_mean(平均回合獎勵),3833856,1767851000.422122,5233.43798828125
rollout/ep_rew_mean(平均回合獎勵),3866624,1767851004.6852853,5465.091796875
rollout/ep_rew_mean(平均回合獎勵),3899392,1767851008.561874,5492.18798828125
rollout/ep_rew_mean(平均回合獎勵),3932160,1767851012.599403,5432.984375
rollout/ep_rew_mean(平均回合獎勵),3964928,1767851016.6966462,5459.1650390625
rollout/ep_rew_mean(平均回合獎勵),3997696,1767851020.5565472,5369.12353515625
rollout/ep_rew_mean(平均回合獎勵),4030464,1767851024.2745268,5237.59912109375
rollout/ep_rew_mean(平均回合獎勵),4063232,1767851027.931706,5495.42041015625
rollout/ep_rew_mean(平均回合獎勵),4096000,1767851031.6902683,5615.41259765625
rollout/ep_rew_mean(平均回合獎勵),4128768,1767851035.552128,5630.345703125
rollout/ep_rew_mean(平均回合獎勵),4161536,1767851039.3616033,5132.76171875
rollout/ep_rew_mean(平均回合獎勵),4194304,1767851043.1991954,4982.970703125
rollout/ep_rew_mean(平均回合獎勵),4227072,1767851047.1003935,5082.6591796875
rollout/ep_rew_mean(平均回合獎勵),4259840,1767851050.8482265,4773.17041015625
rollout/ep_rew_mean(平均回合獎勵),4292608,1767851054.8405092,4847.74658203125
rollout/ep_rew_mean(平均回合獎勵),4325376,1767851058.8245432,4912.49072265625
rollout/ep_rew_mean(平均回合獎勵),4358144,1767851062.640887,4841.57958984375
rollout/ep_rew_mean(平均回合獎勵),4390912,1767851066.511372,4952.13134765625
rollout/ep_rew_mean(平均回合獎勵),4423680,1767851070.3151045,5021.462890625
rollout/ep_rew_mean(平均回合獎勵),4456448,1767851074.1013825,5306.72021484375
rollout/ep_rew_mean(平均回合獎勵),4489216,1767851077.8736207,5412.3017578125
rollout/ep_rew_mean(平均回合獎勵),4521984,1767851081.7243874,5662.810546875
rollout/ep_rew_mean(平均回合獎勵),4554752,1767851085.5352962,5692.318359375
rollout/ep_rew_mean(平均回合獎勵),4587520,1767851089.4027958,5692.12548828125
rollout/ep_rew_mean(平均回合獎勵),4620288,1767851093.227601,5582.296875
rollout/ep_rew_mean(平均回合獎勵),4653056,1767851097.0151076,5582.427734375
rollout/ep_rew_mean(平均回合獎勵),4685824,1767851100.8662007,5879.833984375
rollout/ep_rew_mean(平均回合獎勵),4718592,1767851104.6115327,5762.54638671875
rollout/ep_rew_mean(平均回合獎勵),4751360,1767851108.3256793,5917.33203125
rollout/ep_rew_mean(平均回合獎勵),4784128,1767851112.1232119,5937.73681640625
rollout/ep_rew_mean(平均回合獎勵),4816896,1767851122.0869133,5604.91064453125
rollout/ep_rew_mean(平均回合獎勵),4849664,1767851125.9408178,5272.673828125
rollout/ep_rew_mean(平均回合獎勵),4882432,1767851129.6968298,5077.22021484375
rollout/ep_rew_mean(平均回合獎勵),4915200,1767851133.48323,5039.52392578125
rollout/ep_rew_mean(平均回合獎勵),4947968,1767851137.2527626,4683.8671875
rollout/ep_rew_mean(平均回合獎勵),4980736,1767851141.0984478,4249.2783203125
rollout/ep_rew_mean(平均回合獎勵),5013504,1767851144.8310637,4010.896240234375
rollout/ep_rew_mean(平均回合獎勵),5046272,1767851148.5421064,4100.634765625
rollout/ep_rew_mean(平均回合獎勵),5079040,1767851152.4145024,4352.62890625
rollout/ep_rew_mean(平均回合獎勵),5111808,1767851156.2059376,4415.744140625
rollout/ep_rew_mean(平均回合獎勵),5144576,1767851159.8980644,4627.396484375
rollout/ep_rew_mean(平均回合獎勵),5177344,1767851163.7191901,4585.82080078125
rollout/ep_rew_mean(平均回合獎勵),5210112,1767851167.4530969,4631.65576171875
rollout/ep_rew_mean(平均回合獎勵),5242880,1767851171.206861,4775.8125
rollout/ep_rew_mean(平均回合獎勵),5275648,1767851174.9225078,5102.8720703125
rollout/ep_rew_mean(平均回合獎勵),5308416,1767851178.7835948,5191.39453125
rollout/ep_rew_mean(平均回合獎勵),5341184,1767851182.6305401,4781.08203125
rollout/ep_rew_mean(平均回合獎勵),5373952,1767851186.3842208,4834.81591796875
rollout/ep_rew_mean(平均回合獎勵),5406720,1767851190.255159,4714.27392578125
rollout/ep_rew_mean(平均回合獎勵),5439488,1767851194.0659354,4507.10205078125
rollout/ep_rew_mean(平均回合獎勵),5472256,1767851197.8260283,4411.4970703125
rollout/ep_rew_mean(平均回合獎勵),5505024,1767851201.6629026,4321.3544921875
rollout/ep_rew_mean(平均回合獎勵),5537792,1767851205.4095185,4435.7470703125
rollout/ep_rew_mean(平均回合獎勵),5570560,1767851209.164723,4303.6298828125
rollout/ep_rew_mean(平均回合獎勵),5603328,1767851212.9930987,4413.78662109375
rollout/ep_rew_mean(平均回合獎勵),5636096,1767851216.7795317,4555.35205078125
rollout/ep_rew_mean(平均回合獎勵),5668864,1767851220.50399,4476.84765625
rollout/ep_rew_mean(平均回合獎勵),5701632,1767851224.3482041,4767.45947265625
rollout/ep_rew_mean(平均回合獎勵),5734400,1767851228.1825051,5044.8447265625
rollout/ep_rew_mean(平均回合獎勵),5767168,1767851231.940569,5051.06103515625
rollout/ep_rew_mean(平均回合獎勵),5799936,1767851235.8235393,5218.3037109375
rollout/ep_rew_mean(平均回合獎勵),5832704,1767851239.639634,5056.3232421875
rollout/ep_rew_mean(平均回合獎勵),5865472,1767851243.3867345,5211.732421875
rollout/ep_rew_mean(平均回合獎勵),5898240,1767851247.2597299,4940.06005859375
rollout/ep_rew_mean(平均回合獎勵),5931008,1767851251.0267448,4860.37939453125
rollout/ep_rew_mean(平均回合獎勵),5963776,1767851254.8078127,4779.43017578125
rollout/ep_rew_mean(平均回合獎勵),5996544,1767851258.8188546,4546.24609375
rollout/ep_rew_mean(平均回合獎勵),6029312,1767851262.7803826,4569.37548828125
rollout/ep_rew_mean(平均回合獎勵),6062080,1767851266.7045023,4637.48046875
rollout/ep_rew_mean(平均回合獎勵),6094848,1767851270.5552242,4693.357421875
rollout/ep_rew_mean(平均回合獎勵),6127616,1767851274.4984272,4963.716796875
rollout/ep_rew_mean(平均回合獎勵),6160384,1767851278.5352979,4900.79052734375
rollout/ep_rew_mean(平均回合獎勵),6193152,1767851282.496792,5093.72021484375
rollout/ep_rew_mean(平均回合獎勵),6225920,1767851286.371077,5198.8486328125
rollout/ep_rew_mean(平均回合獎勵),6258688,1767851290.2993336,5455.0419921875
rollout/ep_rew_mean(平均回合獎勵),6291456,1767851294.1221151,5368.69384765625
rollout/ep_rew_mean(平均回合獎勵),6324224,1767851298.0558202,5669.4580078125
rollout/ep_rew_mean(平均回合獎勵),6356992,1767851301.9332805,5367.00048828125
rollout/ep_rew_mean(平均回合獎勵),6389760,1767851305.9010336,5396.05810546875
rollout/ep_rew_mean(平均回合獎勵),6422528,1767851314.32162,5293.0263671875
rollout/ep_rew_mean(平均回合獎勵),6455296,1767851318.2926252,5342.57568359375
rollout/ep_rew_mean(平均回合獎勵),6488064,1767851322.189184,5541.68505859375
rollout/ep_rew_mean(平均回合獎勵),6520832,1767851326.0816662,5490.57568359375
rollout/ep_rew_mean(平均回合獎勵),6553600,1767851329.9729526,5421.5068359375
rollout/ep_rew_mean(平均回合獎勵),6586368,1767851333.914084,5483.5732421875
rollout/ep_rew_mean(平均回合獎勵),6619136,1767851337.7628021,5117.18603515625
rollout/ep_rew_mean(平均回合獎勵),6651904,1767851341.701503,5231.685546875
rollout/ep_rew_mean(平均回合獎勵),6684672,1767851345.6731632,5515.115234375
rollout/ep_rew_mean(平均回合獎勵),6717440,1767851349.560387,5298.53759765625
rollout/ep_rew_mean(平均回合獎勵),6750208,1767851353.5039809,5169.34228515625
rollout/ep_rew_mean(平均回合獎勵),6782976,1767851357.4343462,5201.66015625
rollout/ep_rew_mean(平均回合獎勵),6815744,1767851361.2815995,5030.8115234375
rollout/ep_rew_mean(平均回合獎勵),6848512,1767851365.1255405,4784.95703125
rollout/ep_rew_mean(平均回合獎勵),6881280,1767851369.1308281,4800.30322265625
rollout/ep_rew_mean(平均回合獎勵),6914048,1767851373.0831103,4686.109375
rollout/ep_rew_mean(平均回合獎勵),6946816,1767851376.9331527,4728.95703125
rollout/ep_rew_mean(平均回合獎勵),6979584,1767851380.8888044,4964.29736328125
rollout/ep_rew_mean(平均回合獎勵),7012352,1767851384.8043604,4981.67578125
rollout/ep_rew_mean(平均回合獎勵),7045120,1767851388.6258478,5037.94287109375
rollout/ep_rew_mean(平均回合獎勵),7077888,1767851392.4364486,5110.65869140625
rollout/ep_rew_mean(平均回合獎勵),7110656,1767851396.205339,5295.66015625
rollout/ep_rew_mean(平均回合獎勵),7143424,1767851400.0019038,5250.28759765625
rollout/ep_rew_mean(平均回合獎勵),7176192,1767851403.8091478,5514.701171875
rollout/ep_rew_mean(平均回合獎勵),7208960,1767851407.556572,5389.072265625
rollout/ep_rew_mean(平均回合獎勵),7241728,1767851411.3092682,5629.873046875
rollout/ep_rew_mean(平均回合獎勵),7274496,1767851415.177134,5433.07373046875
rollout/ep_rew_mean(平均回合獎勵),7307264,1767851418.9848976,5520.95947265625
rollout/ep_rew_mean(平均回合獎勵),7340032,1767851422.7503793,5508.54296875
rollout/ep_rew_mean(平均回合獎勵),7372800,1767851426.6533804,5402.27197265625
rollout/ep_rew_mean(平均回合獎勵),7405568,1767851430.4099774,5343.59423828125
rollout/ep_rew_mean(平均回合獎勵),7438336,1767851434.2522728,5263.51171875
rollout/ep_rew_mean(平均回合獎勵),7471104,1767851438.0266423,5367.56103515625
rollout/ep_rew_mean(平均回合獎勵),7503872,1767851441.8613071,5334.10546875
rollout/ep_rew_mean(平均回合獎勵),7536640,1767851445.6970434,5274.93994140625
rollout/ep_rew_mean(平均回合獎勵),7569408,1767851449.6036465,5395.58642578125
rollout/ep_rew_mean(平均回合獎勵),7602176,1767851453.3829386,5422.9404296875
rollout/ep_rew_mean(平均回合獎勵),7634944,1767851457.202003,5359.65478515625
rollout/ep_rew_mean(平均回合獎勵),7667712,1767851461.0313587,5352.30859375
rollout/ep_rew_mean(平均回合獎勵),7700480,1767851464.834783,5301.2001953125
rollout/ep_rew_mean(平均回合獎勵),7733248,1767851468.6625133,5478.2880859375
rollout/ep_rew_mean(平均回合獎勵),7766016,1767851472.5628033,5130.3212890625
rollout/ep_rew_mean(平均回合獎勵),7798784,1767851476.4400105,5028.04541015625
rollout/ep_rew_mean(平均回合獎勵),7831552,1767851480.220457,4812.45654296875
rollout/ep_rew_mean(平均回合獎勵),7864320,1767851484.0781865,4574.107421875
rollout/ep_rew_mean(平均回合獎勵),7897088,1767851487.9261947,4614.546875
rollout/ep_rew_mean(平均回合獎勵),7929856,1767851491.717675,4815.92138671875
rollout/ep_rew_mean(平均回合獎勵),7962624,1767851495.5764532,4760.267578125
rollout/ep_rew_mean(平均回合獎勵),7995392,1767851499.3429677,4876.95703125
rollout/ep_rew_mean(平均回合獎勵),8028160,1767851509.486613,4850.8408203125
rollout/ep_rew_mean(平均回合獎勵),8060928,1767851513.3896632,4958.783203125
rollout/ep_rew_mean(平均回合獎勵),8093696,1767851517.216103,5069.38427734375
rollout/ep_rew_mean(平均回合獎勵),8126464,1767851521.0065434,5205.6435546875
rollout/ep_rew_mean(平均回合獎勵),8159232,1767851524.8318646,5263.89013671875
rollout/ep_rew_mean(平均回合獎勵),8192000,1767851528.6107416,5347.13818359375
rollout/ep_rew_mean(平均回合獎勵),8224768,1767851532.4548416,5047.8583984375
rollout/ep_rew_mean(平均回合獎勵),8257536,1767851536.3604865,5201.599609375
rollout/ep_rew_mean(平均回合獎勵),8290304,1767851540.1405644,5020.091796875
rollout/ep_rew_mean(平均回合獎勵),8323072,1767851543.9752173,4771.130859375
rollout/ep_rew_mean(平均回合獎勵),8355840,1767851547.7974606,4723.76171875
rollout/ep_rew_mean(平均回合獎勵),8388608,1767851551.5882347,4654.15234375
rollout/ep_rew_mean(平均回合獎勵),8421376,1767851555.4249458,4694.83203125
rollout/ep_rew_mean(平均回合獎勵),8454144,1767851559.1645546,4807.8076171875
rollout/ep_rew_mean(平均回合獎勵),8486912,1767851562.9092748,4720.33349609375
rollout/ep_rew_mean(平均回合獎勵),8519680,1767851566.6495507,4698.33740234375
rollout/ep_rew_mean(平均回合獎勵),8552448,1767851570.5102527,4642.2236328125
rollout/ep_rew_mean(平均回合獎勵),8585216,1767851574.3190894,4685.70703125
rollout/ep_rew_mean(平均回合獎勵),8617984,1767851578.10446,4734.9560546875
rollout/ep_rew_mean(平均回合獎勵),8650752,1767851581.9328792,4531.30419921875
rollout/ep_rew_mean(平均回合獎勵),8683520,1767851585.6849768,4384.85205078125
rollout/ep_rew_mean(平均回合獎勵),8716288,1767851589.452577,4260.32958984375
rollout/ep_rew_mean(平均回合獎勵),8749056,1767851593.3209686,4338.0595703125
rollout/ep_rew_mean(平均回合獎勵),8781824,1767851597.117463,4562.802734375
rollout/ep_rew_mean(平均回合獎勵),8814592,1767851600.8884895,4322.86279296875
rollout/ep_rew_mean(平均回合獎勵),8847360,1767851604.7922852,4301.3173828125
rollout/ep_rew_mean(平均回合獎勵),8880128,1767851608.6254165,4136.5986328125
rollout/ep_rew_mean(平均回合獎勵),8912896,1767851612.5267959,4340.0947265625
rollout/ep_rew_mean(平均回合獎勵),8945664,1767851616.3148751,4459.8388671875
rollout/ep_rew_mean(平均回合獎勵),8978432,1767851620.060589,4286.3603515625
rollout/ep_rew_mean(平均回合獎勵),9011200,1767851623.9150236,4271.810546875
rollout/ep_rew_mean(平均回合獎勵),9043968,1767851627.6861043,4165.70166015625
rollout/ep_rew_mean(平均回合獎勵),9076736,1767851631.4564013,4428.9169921875
rollout/ep_rew_mean(平均回合獎勵),9109504,1767851635.3077714,4623.685546875
rollout/ep_rew_mean(平均回合獎勵),9142272,1767851639.1065817,4739.95068359375
rollout/ep_rew_mean(平均回合獎勵),9175040,1767851642.8536239,4867.3203125
rollout/ep_rew_mean(平均回合獎勵),9207808,1767851646.7242799,4714.44140625
rollout/ep_rew_mean(平均回合獎勵),9240576,1767851650.5223844,4920.33447265625
rollout/ep_rew_mean(平均回合獎勵),9273344,1767851654.3266377,4936.916015625
rollout/ep_rew_mean(平均回合獎勵),9306112,1767851658.1292422,4987.70703125
rollout/ep_rew_mean(平均回合獎勵),9338880,1767851661.9003403,4898.10986328125
rollout/ep_rew_mean(平均回合獎勵),9371648,1767851665.6797972,4723.79150390625
rollout/ep_rew_mean(平均回合獎勵),9404416,1767851669.5427177,4617.64013671875
rollout/ep_rew_mean(平均回合獎勵),9437184,1767851673.3655446,4367.8642578125
rollout/ep_rew_mean(平均回合獎勵),9469952,1767851677.180017,4442.67578125
rollout/ep_rew_mean(平均回合獎勵),9502720,1767851680.9703443,4346.81298828125
rollout/ep_rew_mean(平均回合獎勵),9535488,1767851684.7552023,4494.09423828125
rollout/ep_rew_mean(平均回合獎勵),9568256,1767851688.5870562,4632.78173828125
rollout/ep_rew_mean(平均回合獎勵),9601024,1767851698.7403507,4731.33740234375
rollout/ep_rew_mean(平均回合獎勵),9633792,1767851702.5447552,4947.47509765625
rollout/ep_rew_mean(平均回合獎勵),9666560,1767851706.3297298,5178.99853515625
rollout/ep_rew_mean(平均回合獎勵),9699328,1767851710.1771321,5037.78955078125
rollout/ep_rew_mean(平均回合獎勵),9732096,1767851713.9104607,5182.21630859375
rollout/ep_rew_mean(平均回合獎勵),9764864,1767851717.6755009,5202.27294921875
rollout/ep_rew_mean(平均回合獎勵),9797632,1767851721.4707024,5070.267578125
rollout/ep_rew_mean(平均回合獎勵),9830400,1767851725.2913725,5155.11572265625
rollout/ep_rew_mean(平均回合獎勵),9863168,1767851729.1073449,4861.3671875
rollout/ep_rew_mean(平均回合獎勵),9895936,1767851732.8964748,4901.47314453125
rollout/ep_rew_mean(平均回合獎勵),9928704,1767851736.723532,4965.84521484375
rollout/ep_rew_mean(平均回合獎勵),9961472,1767851740.5198991,4907.82861328125
rollout/ep_rew_mean(平均回合獎勵),9994240,1767851744.2771597,4636.1123046875
rollout/ep_rew_mean(平均回合獎勵),10027008,1767851748.0839155,4494.41650390625
rollout/ep_rew_mean(平均回合獎勵),10059776,1767851751.8725479,4698.27197265625
rollout/ep_rew_mean(平均回合獎勵),10092544,1767851755.6664157,4708.80419921875
rollout/ep_rew_mean(平均回合獎勵),10125312,1767851759.5029423,4683.341796875
rollout/ep_rew_mean(平均回合獎勵),10158080,1767851763.2659757,4756.0458984375
rollout/ep_rew_mean(平均回合獎勵),10190848,1767851767.0469668,4747.3994140625
rollout/ep_rew_mean(平均回合獎勵),10223616,1767851770.8760586,4654.73095703125
rollout/ep_rew_mean(平均回合獎勵),10256384,1767851774.7005332,4847.70947265625
rollout/ep_rew_mean(平均回合獎勵),10289152,1767851778.5006182,4780.7841796875
rollout/ep_rew_mean(平均回合獎勵),10321920,1767851782.3109753,4642.4873046875
rollout/ep_rew_mean(平均回合獎勵),10354688,1767851786.103872,4409.9140625
rollout/ep_rew_mean(平均回合獎勵),10387456,1767851789.889282,4250.640625
rollout/ep_rew_mean(平均回合獎勵),10420224,1767851793.661537,4059.5849609375
rollout/ep_rew_mean(平均回合獎勵),10452992,1767851797.5050159,4185.197265625
rollout/ep_rew_mean(平均回合獎勵),10485760,1767851801.2503831,4139.28369140625
rollout/ep_rew_mean(平均回合獎勵),10518528,1767851805.0712113,4103.4443359375
rollout/ep_rew_mean(平均回合獎勵),10551296,1767851808.8688548,4036.265869140625
rollout/ep_rew_mean(平均回合獎勵),10584064,1767851812.6389425,4156.80615234375
rollout/ep_rew_mean(平均回合獎勵),10616832,1767851816.490222,4238.1689453125
rollout/ep_rew_mean(平均回合獎勵),10649600,1767851820.25121,4557.32177734375
rollout/ep_rew_mean(平均回合獎勵),10682368,1767851824.0040731,4559.96240234375
rollout/ep_rew_mean(平均回合獎勵),10715136,1767851827.861113,4495.10546875
rollout/ep_rew_mean(平均回合獎勵),10747904,1767851831.6708193,4419.001953125
rollout/ep_rew_mean(平均回合獎勵),10780672,1767851835.4792118,4588.30078125
rollout/ep_rew_mean(平均回合獎勵),10813440,1767851839.280336,4657.107421875
rollout/ep_rew_mean(平均回合獎勵),10846208,1767851843.065974,4831.0927734375
rollout/ep_rew_mean(平均回合獎勵),10878976,1767851846.8648553,5027.1337890625
rollout/ep_rew_mean(平均回合獎勵),10911744,1767851850.6482563,4847.81201171875
rollout/ep_rew_mean(平均回合獎勵),10944512,1767851854.4339461,4778.00634765625
rollout/ep_rew_mean(平均回合獎勵),10977280,1767851858.2310927,4796.830078125
rollout/ep_rew_mean(平均回合獎勵),11010048,1767851862.1134384,4875.998046875
rollout/ep_rew_mean(平均回合獎勵),11042816,1767851865.956484,5009.5517578125
rollout/ep_rew_mean(平均回合獎勵),11075584,1767851869.897537,4706.71240234375
rollout/ep_rew_mean(平均回合獎勵),11108352,1767851873.7397423,4321.5439453125
rollout/ep_rew_mean(平均回合獎勵),11141120,1767851877.6540227,4019.04248046875
rollout/ep_rew_mean(平均回合獎勵),11173888,1767851881.5055263,4217.44384765625
rollout/ep_rew_mean(平均回合獎勵),11206656,1767851891.719144,4283.603515625
rollout/ep_rew_mean(平均回合獎勵),11239424,1767851895.6584544,4178.38671875
rollout/ep_rew_mean(平均回合獎勵),11272192,1767851899.437363,4257.0517578125
rollout/ep_rew_mean(平均回合獎勵),11304960,1767851903.2367744,4357.12939453125
rollout/ep_rew_mean(平均回合獎勵),11337728,1767851907.0456638,4304.609375
rollout/ep_rew_mean(平均回合獎勵),11370496,1767851910.8145862,4484.17333984375
rollout/ep_rew_mean(平均回合獎勵),11403264,1767851914.5965257,4432.90234375
rollout/ep_rew_mean(平均回合獎勵),11436032,1767851918.434133,4253.92626953125
rollout/ep_rew_mean(平均回合獎勵),11468800,1767851922.2353313,3996.3154296875
rollout/ep_rew_mean(平均回合獎勵),11501568,1767851926.0057366,3731.068359375
rollout/ep_rew_mean(平均回合獎勵),11534336,1767851929.8337362,3716.597412109375
rollout/ep_rew_mean(平均回合獎勵),11567104,1767851933.6304746,3761.037841796875
rollout/ep_rew_mean(平均回合獎勵),11599872,1767851937.4094367,3751.3583984375
rollout/ep_rew_mean(平均回合獎勵),11632640,1767851941.2539635,3717.12646484375
rollout/ep_rew_mean(平均回合獎勵),11665408,1767851945.0449657,3720.721923828125
rollout/ep_rew_mean(平均回合獎勵),11698176,1767851948.827807,3537.564697265625
rollout/ep_rew_mean(平均回合獎勵),11730944,1767851952.6740668,3107.341796875
rollout/ep_rew_mean(平均回合獎勵),11763712,1767851956.4674273,3152.033447265625
rollout/ep_rew_mean(平均回合獎勵),11796480,1767851960.358683,3242.278076171875
rollout/ep_rew_mean(平均回合獎勵),11829248,1767851964.2478104,3286.35595703125
rollout/ep_rew_mean(平均回合獎勵),11862016,1767851968.0738328,3572.033447265625
rollout/ep_rew_mean(平均回合獎勵),11894784,1767851971.9493694,3545.9208984375
rollout/ep_rew_mean(平均回合獎勵),11927552,1767851975.8429923,3708.50537109375
rollout/ep_rew_mean(平均回合獎勵),11960320,1767851979.655874,3961.47900390625
rollout/ep_rew_mean(平均回合獎勵),11993088,1767851983.4819186,4040.71533203125
rollout/ep_rew_mean(平均回合獎勵),12025856,1767851987.3343585,3934.422607421875
rollout/ep_rew_mean(平均回合獎勵),12058624,1767851991.2070632,3429.19677734375
rollout/ep_rew_mean(平均回合獎勵),12091392,1767851995.0093503,3424.4638671875
rollout/ep_rew_mean(平均回合獎勵),12124160,1767851998.8575733,3639.543701171875
rollout/ep_rew_mean(平均回合獎勵),12156928,1767852002.723118,3832.6943359375
rollout/ep_rew_mean(平均回合獎勵),12189696,1767852006.6192544,3820.42822265625
rollout/ep_rew_mean(平均回合獎勵),12222464,1767852010.4443982,3822.041015625
rollout/ep_rew_mean(平均回合獎勵),12255232,1767852014.2415743,3791.69091796875
rollout/ep_rew_mean(平均回合獎勵),12288000,1767852018.0783741,3961.905517578125
rollout/ep_rew_mean(平均回合獎勵),12320768,1767852021.9408715,4034.19677734375
rollout/ep_rew_mean(平均回合獎勵),12353536,1767852025.8486497,3999.720947265625
rollout/ep_rew_mean(平均回合獎勵),12386304,1767852029.716671,3924.288330078125
rollout/ep_rew_mean(平均回合獎勵),12419072,1767852033.6132348,3851.4853515625
rollout/ep_rew_mean(平均回合獎勵),12451840,1767852037.411729,3841.4052734375
rollout/ep_rew_mean(平均回合獎勵),12484608,1767852041.2448833,4168.2001953125
rollout/ep_rew_mean(平均回合獎勵),12517376,1767852045.0343423,4107.271484375
rollout/ep_rew_mean(平均回合獎勵),12550144,1767852048.8760827,3870.1787109375
rollout/ep_rew_mean(平均回合獎勵),12582912,1767852052.7375727,3718.858642578125
rollout/ep_rew_mean(平均回合獎勵),12615680,1767852056.60109,3884.533203125
rollout/ep_rew_mean(平均回合獎勵),12648448,1767852060.4723964,3748.3037109375
rollout/ep_rew_mean(平均回合獎勵),12681216,1767852064.3369222,3368.566162109375
rollout/ep_rew_mean(平均回合獎勵),12713984,1767852068.303477,3126.100341796875
rollout/ep_rew_mean(平均回合獎勵),12746752,1767852072.1466877,3239.6064453125
rollout/ep_rew_mean(平均回合獎勵),12779520,1767852076.0867941,2901.145263671875
rollout/ep_rew_mean(平均回合獎勵),12812288,1767852085.342652,2708.216552734375
rollout/ep_rew_mean(平均回合獎勵),12845056,1767852089.3506994,2697.090087890625
rollout/ep_rew_mean(平均回合獎勵),12877824,1767852093.240537,2921.687255859375
rollout/ep_rew_mean(平均回合獎勵),12910592,1767852097.047181,3120.465087890625
rollout/ep_rew_mean(平均回合獎勵),12943360,1767852100.8524952,3227.299072265625
rollout/ep_rew_mean(平均回合獎勵),12976128,1767852104.6656787,3286.434326171875
rollout/ep_rew_mean(平均回合獎勵),13008896,1767852108.5615203,3416.72509765625
rollout/ep_rew_mean(平均回合獎勵),13041664,1767852112.3818095,3343.27685546875
rollout/ep_rew_mean(平均回合獎勵),13074432,1767852116.144301,3478.947509765625
rollout/ep_rew_mean(平均回合獎勵),13107200,1767852119.9847195,3235.413330078125
rollout/ep_rew_mean(平均回合獎勵),13139968,1767852123.7673254,3312.54541015625
rollout/ep_rew_mean(平均回合獎勵),13172736,1767852127.555611,3334.383056640625
rollout/ep_rew_mean(平均回合獎勵),13205504,1767852131.4294608,3547.6318359375
rollout/ep_rew_mean(平均回合獎勵),13238272,1767852135.2610745,3597.31396484375
rollout/ep_rew_mean(平均回合獎勵),13271040,1767852139.1296704,4098.90283203125
rollout/ep_rew_mean(平均回合獎勵),13303808,1767852142.939284,4163.92919921875
rollout/ep_rew_mean(平均回合獎勵),13336576,1767852146.6933453,4239.017578125
rollout/ep_rew_mean(平均回合獎勵),13369344,1767852150.5655675,4314.19775390625
rollout/ep_rew_mean(平均回合獎勵),13402112,1767852154.337042,4235.107421875
rollout/ep_rew_mean(平均回合獎勵),13434880,1767852158.1100445,4400.25146484375
rollout/ep_rew_mean(平均回合獎勵),13467648,1767852161.9528158,4358.53466796875
rollout/ep_rew_mean(平均回合獎勵),13500416,1767852165.7732508,4504.65625
rollout/ep_rew_mean(平均回合獎勵),13533184,1767852169.5396895,4491.71484375
rollout/ep_rew_mean(平均回合獎勵),13565952,1767852173.3529642,4450.89697265625
rollout/ep_rew_mean(平均回合獎勵),13598720,1767852177.1586583,4450.380859375
rollout/ep_rew_mean(平均回合獎勵),13631488,1767852180.9323645,4537.01513671875
rollout/ep_rew_mean(平均回合獎勵),13664256,1767852184.7686446,4629.076171875
rollout/ep_rew_mean(平均回合獎勵),13697024,1767852188.5371807,4878.6630859375
rollout/ep_rew_mean(平均回合獎勵),13729792,1767852192.3260584,5032.06689453125
rollout/ep_rew_mean(平均回合獎勵),13762560,1767852196.1565945,5082.287109375
rollout/ep_rew_mean(平均回合獎勵),13795328,1767852199.9392993,5120.02490234375
rollout/ep_rew_mean(平均回合獎勵),13828096,1767852203.7457683,5094.84130859375
rollout/ep_rew_mean(平均回合獎勵),13860864,1767852207.5603771,4991.974609375
rollout/ep_rew_mean(平均回合獎勵),13893632,1767852211.3222716,4831.10205078125
rollout/ep_rew_mean(平均回合獎勵),13926400,1767852215.117207,4579.8896484375
rollout/ep_rew_mean(平均回合獎勵),13959168,1767852218.9593084,4245.828125
rollout/ep_rew_mean(平均回合獎勵),13991936,1767852222.7497587,4133.720703125
rollout/ep_rew_mean(平均回合獎勵),14024704,1767852226.5376217,3777.383544921875
rollout/ep_rew_mean(平均回合獎勵),14057472,1767852230.341306,3701.18994140625
rollout/ep_rew_mean(平均回合獎勵),14090240,1767852234.1532724,3935.40185546875
rollout/ep_rew_mean(平均回合獎勵),14123008,1767852237.9555166,3871.601318359375
rollout/ep_rew_mean(平均回合獎勵),14155776,1767852241.7709186,3798.82666015625
rollout/ep_rew_mean(平均回合獎勵),14188544,1767852245.580831,3942.668701171875
rollout/ep_rew_mean(平均回合獎勵),14221312,1767852249.4112377,3986.6650390625
rollout/ep_rew_mean(平均回合獎勵),14254080,1767852253.1772535,4256.07666015625
rollout/ep_rew_mean(平均回合獎勵),14286848,1767852256.9677918,4377.341796875
rollout/ep_rew_mean(平均回合獎勵),14319616,1767852260.8131015,4460.3681640625
rollout/ep_rew_mean(平均回合獎勵),14352384,1767852264.6120255,4375.48291015625
rollout/ep_rew_mean(平均回合獎勵),14385152,1767852268.473499,4702.4794921875
rollout/ep_rew_mean(平均回合獎勵),14417920,1767852278.6587572,4910.61962890625
rollout/ep_rew_mean(平均回合獎勵),14450688,1767852282.5740464,4970.765625
rollout/ep_rew_mean(平均回合獎勵),14483456,1767852286.3921025,4808.833984375
rollout/ep_rew_mean(平均回合獎勵),14516224,1767852290.2720983,5005.20849609375
rollout/ep_rew_mean(平均回合獎勵),14548992,1767852294.1244688,4988.9013671875
rollout/ep_rew_mean(平均回合獎勵),14581760,1767852297.9144642,4757.81591796875
rollout/ep_rew_mean(平均回合獎勵),14614528,1767852301.7823184,4702.0693359375
rollout/ep_rew_mean(平均回合獎勵),14647296,1767852305.590244,4483.544921875
rollout/ep_rew_mean(平均回合獎勵),14680064,1767852309.4423165,4169.88134765625
rollout/ep_rew_mean(平均回合獎勵),14712832,1767852313.3254573,4088.65087890625
rollout/ep_rew_mean(平均回合獎勵),14745600,1767852317.128722,4000.548828125
rollout/ep_rew_mean(平均回合獎勵),14778368,1767852320.9527233,4056.043212890625
rollout/ep_rew_mean(平均回合獎勵),14811136,1767852324.7873342,4017.253173828125
rollout/ep_rew_mean(平均回合獎勵),14843904,1767852328.6576471,4174.59716796875
rollout/ep_rew_mean(平均回合獎勵),14876672,1767852332.519666,4318.6494140625
rollout/ep_rew_mean(平均回合獎勵),14909440,1767852336.2900808,4476.11083984375
rollout/ep_rew_mean(平均回合獎勵),14942208,1767852340.1513834,4519.2998046875
rollout/ep_rew_mean(平均回合獎勵),14974976,1767852343.9663556,4709.2607421875
rollout/ep_rew_mean(平均回合獎勵),15007744,1767852347.8196182,4724.35791015625
train/approx_kl(近似KL散度),65536,1767850559.228526,0.0033541573211550713
train/approx_kl(近似KL散度),98304,1767850562.996143,0.004000835120677948
train/approx_kl(近似KL散度),131072,1767850566.719327,0.004144897684454918
train/approx_kl(近似KL散度),163840,1767850570.4483514,0.004413156770169735
train/approx_kl(近似KL散度),196608,1767850574.1534498,0.004991503898054361
train/approx_kl(近似KL散度),229376,1767850577.8905578,0.00563386594876647
train/approx_kl(近似KL散度),262144,1767850581.583047,0.006785557139664888
train/approx_kl(近似KL散度),294912,1767850585.2030509,0.005548875778913498
train/approx_kl(近似KL散度),327680,1767850588.9230797,0.004313366487622261
train/approx_kl(近似KL散度),360448,1767850592.6420286,0.0022250129841268063
train/approx_kl(近似KL散度),393216,1767850596.5343516,0.0020991936326026917
train/approx_kl(近似KL散度),425984,1767850600.2572355,0.0017961612902581692
train/approx_kl(近似KL散度),458752,1767850604.004208,0.0014878390356898308
train/approx_kl(近似KL散度),491520,1767850607.7767951,0.0014623047318309546
train/approx_kl(近似KL散度),524288,1767850611.5745854,0.00143330916762352
train/approx_kl(近似KL散度),557056,1767850615.2046947,0.0011311625130474567
train/approx_kl(近似KL散度),589824,1767850618.933322,0.0012956648133695126
train/approx_kl(近似KL散度),622592,1767850622.619367,0.0009348209132440388
train/approx_kl(近似KL散度),655360,1767850626.3165457,0.0010507188271731138
train/approx_kl(近似KL散度),688128,1767850629.9219232,0.0009189611300826073
train/approx_kl(近似KL散度),720896,1767850633.6161911,0.0008259176975116134
train/approx_kl(近似KL散度),753664,1767850637.1983774,0.001312545035034418
train/approx_kl(近似KL散度),786432,1767850640.8717477,0.0007211352931335568
train/approx_kl(近似KL散度),819200,1767850644.4654818,0.0008695782744325697
train/approx_kl(近似KL散度),851968,1767850648.1052475,0.0009445000905543566
train/approx_kl(近似KL散度),884736,1767850651.703579,0.0006790435872972012
train/approx_kl(近似KL散度),917504,1767850655.3435278,0.000769160920754075
train/approx_kl(近似KL散度),950272,1767850659.0710485,0.0007290764478966594
train/approx_kl(近似KL散度),983040,1767850662.7455473,0.0008213688852265477
train/approx_kl(近似KL散度),1015808,1767850666.481074,0.0009830576600506902
train/approx_kl(近似KL散度),1048576,1767850670.1074698,0.000879703788086772
train/approx_kl(近似KL散度),1081344,1767850673.8068314,0.0008555552340112627
train/approx_kl(近似KL散度),1114112,1767850677.3988,0.0007655704393982887
train/approx_kl(近似KL散度),1146880,1767850681.0832002,0.001036602770909667
train/approx_kl(近似KL散度),1179648,1767850684.683882,0.0008371928706765175
train/approx_kl(近似KL散度),1212416,1767850688.3471098,0.0008411137969233096
train/approx_kl(近似KL散度),1245184,1767850692.0412767,0.0007470164564438164
train/approx_kl(近似KL散度),1277952,1767850695.7100718,0.0007330841617658734
train/approx_kl(近似KL散度),1310720,1767850699.3796778,0.0008114014053717256
train/approx_kl(近似KL散度),1343488,1767850703.1060586,0.0009174987208098173
train/approx_kl(近似KL散度),1376256,1767850706.7275863,0.0008640696760267019
train/approx_kl(近似KL散度),1409024,1767850710.4058769,0.0007020465563982725
train/approx_kl(近似KL散度),1441792,1767850713.9961836,0.0006965319626033306
train/approx_kl(近似KL散度),1474560,1767850717.6608357,0.0014971413183957338
train/approx_kl(近似KL散度),1507328,1767850721.2686496,0.0007759422296658158
train/approx_kl(近似KL散度),1540096,1767850724.905224,0.000686998013406992
train/approx_kl(近似KL散度),1572864,1767850728.5152638,0.0013367213541641831
train/approx_kl(近似KL散度),1600000,1767850737.0012846,0.0007524045067839324
train/approx_kl(近似KL散度),1638400,1767850741.4428859,0.0008750893175601959
train/approx_kl(近似KL散度),1671168,1767850745.0722322,0.0010373862460255623
train/approx_kl(近似KL散度),1703936,1767850748.701232,0.0008132653892971575
train/approx_kl(近似KL散度),1736704,1767850752.3870256,0.0008019679225981236
train/approx_kl(近似KL散度),1769472,1767850755.9522567,0.0006082307081669569
train/approx_kl(近似KL散度),1802240,1767850759.612867,0.0006032901583239436
train/approx_kl(近似KL散度),1835008,1767850763.1786482,0.0008180474396795034
train/approx_kl(近似KL散度),1867776,1767850766.815694,0.0007879333570599556
train/approx_kl(近似KL散度),1900544,1767850770.3717258,0.0008103352156467736
train/approx_kl(近似KL散度),1933312,1767850774.0567575,0.0006381953717209399
train/approx_kl(近似KL散度),1966080,1767850777.6604764,0.0012751566246151924
train/approx_kl(近似KL散度),1998848,1767850781.2761362,0.0006310329772531986
train/approx_kl(近似KL散度),2031616,1767850784.883305,0.0011561076389625669
train/approx_kl(近似KL散度),2064384,1767850788.4923668,0.0009209985146299005
train/approx_kl(近似KL散度),2097152,1767850792.2032356,0.0011993988882750273
train/approx_kl(近似KL散度),2129920,1767850795.866282,0.0007024477235972881
train/approx_kl(近似KL散度),2162688,1767850799.5272243,0.0009142373455688357
train/approx_kl(近似KL散度),2195456,1767850803.2312806,0.001258413540199399
train/approx_kl(近似KL散度),2228224,1767850806.8434565,0.0008081241394393146
train/approx_kl(近似KL散度),2260992,1767850810.455892,0.0010250718332827091
train/approx_kl(近似KL散度),2293760,1767850814.0776038,0.0009358104434795678
train/approx_kl(近似KL散度),2326528,1767850817.7324646,0.0005686524673365057
train/approx_kl(近似KL散度),2359296,1767850821.3082688,0.0005838848883286119
train/approx_kl(近似KL散度),2392064,1767850824.9743595,0.0011432480532675982
train/approx_kl(近似KL散度),2424832,1767850828.55592,0.0008201542077586055
train/approx_kl(近似KL散度),2457600,1767850832.2084389,0.0006951122195459902
train/approx_kl(近似KL散度),2490368,1767850835.7887897,0.0010254576336592436
train/approx_kl(近似KL散度),2523136,1767850839.410689,0.001131874043494463
train/approx_kl(近似KL散度),2555904,1767850842.9688787,0.0006417793338187039
train/approx_kl(近似KL散度),2588672,1767850846.6125402,0.0008901632390916348
train/approx_kl(近似KL散度),2621440,1767850850.1919608,0.0012709142174571753
train/approx_kl(近似KL散度),2654208,1767850853.8263726,0.0025512659922242165
train/approx_kl(近似KL散度),2686976,1767850857.4195008,0.0008730540284886956
train/approx_kl(近似KL散度),2719744,1767850861.3290613,0.0009885169565677643
train/approx_kl(近似KL散度),2752512,1767850865.0908148,0.000958287448156625
train/approx_kl(近似KL散度),2785280,1767850869.031745,0.0007750263321213424
train/approx_kl(近似KL散度),2818048,1767850872.8489573,0.0009547709487378597
train/approx_kl(近似KL散度),2850816,1767850876.7107396,0.001022009993903339
train/approx_kl(近似KL散度),2883584,1767850880.4894252,0.0008344815578311682
train/approx_kl(近似KL散度),2916352,1767850884.3961153,0.0008674937416799366
train/approx_kl(近似KL散度),2949120,1767850888.1782212,0.0006645346293225884
train/approx_kl(近似KL散度),2981888,1767850891.9776053,0.0007838746532797813
train/approx_kl(近似KL散度),3014656,1767850895.7577431,0.0007756312843412161
train/approx_kl(近似KL散度),3047424,1767850899.5806687,0.0008759212214499712
train/approx_kl(近似KL散度),3080192,1767850903.3661573,0.0009426657343283296
train/approx_kl(近似KL散度),3112960,1767850907.1832235,0.001030600513331592
train/approx_kl(近似KL散度),3145728,1767850911.2433429,0.0013084530364722013
train/approx_kl(近似KL散度),3178496,1767850915.1832602,0.0008224716875702143
train/approx_kl(近似KL散度),3200000,1767850924.5230672,0.000985435675829649
train/approx_kl(近似KL散度),3244032,1767850929.708885,0.001119390013627708
train/approx_kl(近似KL散度),3276800,1767850933.5472097,0.001082925358787179
train/approx_kl(近似KL散度),3309568,1767850937.467982,0.001022026757709682
train/approx_kl(近似KL散度),3342336,1767850941.3087542,0.0006581477937288582
train/approx_kl(近似KL散度),3375104,1767850945.2962406,0.001172359799966216
train/approx_kl(近似KL散度),3407872,1767850949.2090595,0.001118071493692696
train/approx_kl(近似KL散度),3440640,1767850952.9483771,0.0007542890962213278
train/approx_kl(近似KL散度),3473408,1767850957.3175955,0.0009631061693653464
train/approx_kl(近似KL散度),3506176,1767850961.4267182,0.0011470187455415726
train/approx_kl(近似KL散度),3538944,1767850965.30745,0.0009054692927747965
train/approx_kl(近似KL散度),3571712,1767850969.296191,0.0010047198738902807
train/approx_kl(近似KL散度),3604480,1767850972.9610317,0.0007421904010698199
train/approx_kl(近似KL散度),3637248,1767850976.7373757,0.0015983919147402048
train/approx_kl(近似KL散度),3670016,1767850980.5669193,0.0006736888317391276
train/approx_kl(近似KL散度),3702784,1767850984.6186466,0.0009625648963265121
train/approx_kl(近似KL散度),3735552,1767850988.6584132,0.0008091494673863053
train/approx_kl(近似KL散度),3768320,1767850992.5548205,0.0005873585469089448
train/approx_kl(近似KL散度),3801088,1767850996.5146782,0.0006546737859025598
train/approx_kl(近似KL散度),3833856,1767851000.422122,0.0010877699824050069
train/approx_kl(近似KL散度),3866624,1767851004.6852853,0.0008485702564939857
train/approx_kl(近似KL散度),3899392,1767851008.561874,0.0007158034713938832
train/approx_kl(近似KL散度),3932160,1767851012.599403,0.0009164342191070318
train/approx_kl(近似KL散度),3964928,1767851016.6966462,0.0008349107811227441
train/approx_kl(近似KL散度),3997696,1767851020.5565472,0.0021345268469303846
train/approx_kl(近似KL散度),4030464,1767851024.2745268,0.0010226230369880795
train/approx_kl(近似KL散度),4063232,1767851027.931706,0.0006537347799167037
train/approx_kl(近似KL散度),4096000,1767851031.6902683,0.0008066212176345289
train/approx_kl(近似KL散度),4128768,1767851035.552128,0.0005931254127062857
train/approx_kl(近似KL散度),4161536,1767851039.3616033,0.0008689431706443429
train/approx_kl(近似KL散度),4194304,1767851043.1991954,0.000798236345872283
train/approx_kl(近似KL散度),4227072,1767851047.1003935,0.0008365462417714298
train/approx_kl(近似KL散度),4259840,1767851050.8482265,0.001215606927871704
train/approx_kl(近似KL散度),4292608,1767851054.8405092,0.001075885258615017
train/approx_kl(近似KL散度),4325376,1767851058.8245432,0.000729117076843977
train/approx_kl(近似KL散度),4358144,1767851062.640887,0.000900753540918231
train/approx_kl(近似KL散度),4390912,1767851066.511372,0.0007566844578832388
train/approx_kl(近似KL散度),4423680,1767851070.3151045,0.0011436984641477466
train/approx_kl(近似KL散度),4456448,1767851074.1013825,0.0009290248854085803
train/approx_kl(近似KL散度),4489216,1767851077.8736207,0.000719682255294174
train/approx_kl(近似KL散度),4521984,1767851081.7243874,0.0006064363988116384
train/approx_kl(近似KL散度),4554752,1767851085.5352962,0.0007704675663262606
train/approx_kl(近似KL散度),4587520,1767851089.4027958,0.0006463184836320579
train/approx_kl(近似KL散度),4620288,1767851093.227601,0.000707981176674366
train/approx_kl(近似KL散度),4653056,1767851097.0151076,0.0010306898038834333
train/approx_kl(近似KL散度),4685824,1767851100.8662007,0.0007906786631792784
train/approx_kl(近似KL散度),4718592,1767851104.6115327,0.0009318717056885362
train/approx_kl(近似KL散度),4751360,1767851108.3256793,0.0008555103559046984
train/approx_kl(近似KL散度),4784128,1767851112.1232119,0.0009600144112482667
train/approx_kl(近似KL散度),4800000,1767851120.069484,0.000700382050126791
train/approx_kl(近似KL散度),4849664,1767851125.9408178,0.001429676078259945
train/approx_kl(近似KL散度),4882432,1767851129.6968298,0.0009172265999950469
train/approx_kl(近似KL散度),4915200,1767851133.48323,0.0006992478738538921
train/approx_kl(近似KL散度),4947968,1767851137.2527626,0.000960824778303504
train/approx_kl(近似KL散度),4980736,1767851141.0984478,0.0008640385931357741
train/approx_kl(近似KL散度),5013504,1767851144.8310637,0.0013306601904332638
train/approx_kl(近似KL散度),5046272,1767851148.5421064,0.0008651736425235868
train/approx_kl(近似KL散度),5079040,1767851152.4145024,0.0008744655642658472
train/approx_kl(近似KL散度),5111808,1767851156.2059376,0.0007783080800436437
train/approx_kl(近似KL散度),5144576,1767851159.8980644,0.0006634291494265199
train/approx_kl(近似KL散度),5177344,1767851163.7191901,0.0008218300063163042
train/approx_kl(近似KL散度),5210112,1767851167.4530969,0.0008268464589491487
train/approx_kl(近似KL散度),5242880,1767851171.206861,0.0009034620597958565
train/approx_kl(近似KL散度),5275648,1767851174.9225078,0.0008805237011983991
train/approx_kl(近似KL散度),5308416,1767851178.7835948,0.0007083315867930651
train/approx_kl(近似KL散度),5341184,1767851182.6305401,0.0009417316759936512
train/approx_kl(近似KL散度),5373952,1767851186.3842208,0.0008166518528014421
train/approx_kl(近似KL散度),5406720,1767851190.255159,0.0012789529282599688
train/approx_kl(近似KL散度),5439488,1767851194.0659354,0.0008074436336755753
train/approx_kl(近似KL散度),5472256,1767851197.8260283,0.0014673399273306131
train/approx_kl(近似KL散度),5505024,1767851201.6629026,0.0007590509485453367
train/approx_kl(近似KL散度),5537792,1767851205.4095185,0.0010618879459798336
train/approx_kl(近似KL散度),5570560,1767851209.164723,0.0009406143799424171
train/approx_kl(近似KL散度),5603328,1767851212.9930987,0.0008130031637847424
train/approx_kl(近似KL散度),5636096,1767851216.7795317,0.0010651594493538141
train/approx_kl(近似KL散度),5668864,1767851220.50399,0.0006814493099227548
train/approx_kl(近似KL散度),5701632,1767851224.3482041,0.0007202316774055362
train/approx_kl(近似KL散度),5734400,1767851228.1825051,0.0006832289509475231
train/approx_kl(近似KL散度),5767168,1767851231.940569,0.0008114195661619306
train/approx_kl(近似KL散度),5799936,1767851235.8235393,0.0011997504625469446
train/approx_kl(近似KL散度),5832704,1767851239.639634,0.0008512954809702933
train/approx_kl(近似KL散度),5865472,1767851243.3867345,0.0009491672972217202
train/approx_kl(近似KL散度),5898240,1767851247.2597299,0.0006169109838083386
train/approx_kl(近似KL散度),5931008,1767851251.0267448,0.0009772207122296095
train/approx_kl(近似KL散度),5963776,1767851254.8078127,0.0009270719019696116
train/approx_kl(近似KL散度),5996544,1767851258.8188546,0.00113935605622828
train/approx_kl(近似KL散度),6029312,1767851262.7803826,0.0007234682561829686
train/approx_kl(近似KL散度),6062080,1767851266.7045023,0.0009637153125368059
train/approx_kl(近似KL散度),6094848,1767851270.5552242,0.0011650912929326296
train/approx_kl(近似KL散度),6127616,1767851274.4984272,0.0005965628079138696
train/approx_kl(近似KL散度),6160384,1767851278.5352979,0.0008914918871596456
train/approx_kl(近似KL散度),6193152,1767851282.497792,0.0006014906102791429
train/approx_kl(近似KL散度),6225920,1767851286.371077,0.0006954692653380334
train/approx_kl(近似KL散度),6258688,1767851290.2993336,0.0010882308706641197
train/approx_kl(近似KL散度),6291456,1767851294.1221151,0.0011409677099436522
train/approx_kl(近似KL散度),6324224,1767851298.0558202,0.0007268015760928392
train/approx_kl(近似KL散度),6356992,1767851301.9332805,0.000890701194293797
train/approx_kl(近似KL散度),6389760,1767851305.9010336,0.0007147289579734206
train/approx_kl(近似KL散度),6400000,1767851311.462924,0.0005528498440980911
train/approx_kl(近似KL散度),6455296,1767851318.2926252,0.0010914169251918793
train/approx_kl(近似KL散度),6488064,1767851322.189184,0.0008334002341143787
train/approx_kl(近似KL散度),6520832,1767851326.0816662,0.0006883658934384584
train/approx_kl(近似KL散度),6553600,1767851329.9729526,0.0006917000282555819
train/approx_kl(近似KL散度),6586368,1767851333.914084,0.0007908953120931983
train/approx_kl(近似KL散度),6619136,1767851337.7628021,0.000765270902775228
train/approx_kl(近似KL散度),6651904,1767851341.701503,0.0009890797082334757
train/approx_kl(近似KL散度),6684672,1767851345.6731632,0.0007953608874231577
train/approx_kl(近似KL散度),6717440,1767851349.560387,0.0009911907836794853
train/approx_kl(近似KL散度),6750208,1767851353.5039809,0.0004767104401253164
train/approx_kl(近似KL散度),6782976,1767851357.4343462,0.0007335235131904483
train/approx_kl(近似KL散度),6815744,1767851361.2815995,0.0007943330565467477
train/approx_kl(近似KL散度),6848512,1767851365.1255405,0.0008010384044609964
train/approx_kl(近似KL散度),6881280,1767851369.1308281,0.001017486210912466
train/approx_kl(近似KL散度),6914048,1767851373.0831103,0.001357188681140542
train/approx_kl(近似KL散度),6946816,1767851376.9331527,0.0006835617241449654
train/approx_kl(近似KL散度),6979584,1767851380.8888044,0.0011318554170429707
train/approx_kl(近似KL散度),7012352,1767851384.8043604,0.0007395759457722306
train/approx_kl(近似KL散度),7045120,1767851388.6258478,0.0008970817434601486
train/approx_kl(近似KL散度),7077888,1767851392.4364486,0.0009216615580953658
train/approx_kl(近似KL散度),7110656,1767851396.205339,0.0007265062886290252
train/approx_kl(近似KL散度),7143424,1767851400.0019038,0.0011540092527866364
train/approx_kl(近似KL散度),7176192,1767851403.8091478,0.0008924663998186588
train/approx_kl(近似KL散度),7208960,1767851407.556572,0.000616086705122143
train/approx_kl(近似KL散度),7241728,1767851411.3092682,0.0007981989765539765
train/approx_kl(近似KL散度),7274496,1767851415.177134,0.0007944842800498009
train/approx_kl(近似KL散度),7307264,1767851418.9848976,0.0009337299270555377
train/approx_kl(近似KL散度),7340032,1767851422.7503793,0.0005911544431000948
train/approx_kl(近似KL散度),7372800,1767851426.6533804,0.0015010791830718517
train/approx_kl(近似KL散度),7405568,1767851430.4099774,0.0006827777251601219
train/approx_kl(近似KL散度),7438336,1767851434.2532735,0.0008408772991970181
train/approx_kl(近似KL散度),7471104,1767851438.0266423,0.0008278205059468746
train/approx_kl(近似KL散度),7503872,1767851441.8613071,0.0033645490184426308
train/approx_kl(近似KL散度),7536640,1767851445.6970434,0.0008719824254512787
train/approx_kl(近似KL散度),7569408,1767851449.6036465,0.0007117569912225008
train/approx_kl(近似KL散度),7602176,1767851453.3829386,0.0010341870365664363
train/approx_kl(近似KL散度),7634944,1767851457.202003,0.0006389155751094222
train/approx_kl(近似KL散度),7667712,1767851461.0313587,0.0005312119610607624
train/approx_kl(近似KL散度),7700480,1767851464.834783,0.0010344788897782564
train/approx_kl(近似KL散度),7733248,1767851468.6625133,0.000688447616994381
train/approx_kl(近似KL散度),7766016,1767851472.5628033,0.0008734810398891568
train/approx_kl(近似KL散度),7798784,1767851476.4400105,0.001064451178535819
train/approx_kl(近似KL散度),7831552,1767851480.220457,0.0016043439973145723
train/approx_kl(近似KL散度),7864320,1767851484.0781865,0.0007822891930118203
train/approx_kl(近似KL散度),7897088,1767851487.9261947,0.0006390197668224573
train/approx_kl(近似KL散度),7929856,1767851491.717675,0.0014297801535576582
train/approx_kl(近似KL散度),7962624,1767851495.5764532,0.0006174135487526655
train/approx_kl(近似KL散度),7995392,1767851499.3429677,0.0014729938702657819
train/approx_kl(近似KL散度),8000000,1767851506.12033,0.0005686237127520144
train/approx_kl(近似KL散度),8060928,1767851513.3896632,0.0006547284428961575
train/approx_kl(近似KL散度),8093696,1767851517.216103,0.0005701404297724366
train/approx_kl(近似KL散度),8126464,1767851521.0065434,0.0010110283037647605
train/approx_kl(近似KL散度),8159232,1767851524.8318646,0.0006017693085595965
train/approx_kl(近似KL散度),8192000,1767851528.6107416,0.0008292984566651285
train/approx_kl(近似KL散度),8224768,1767851532.4548416,0.0006951368413865566
train/approx_kl(近似KL散度),8257536,1767851536.3604865,0.001008838415145874
train/approx_kl(近似KL散度),8290304,1767851540.1405644,0.0009997400920838118
train/approx_kl(近似KL散度),8323072,1767851543.9752173,0.0009149423567578197
train/approx_kl(近似KL散度),8355840,1767851547.7974606,0.0005947845056653023
train/approx_kl(近似KL散度),8388608,1767851551.5882347,0.0010912842117249966
train/approx_kl(近似KL散度),8421376,1767851555.4249458,0.0008282307535409927
train/approx_kl(近似KL散度),8454144,1767851559.1645546,0.0015116790309548378
train/approx_kl(近似KL散度),8486912,1767851562.9092748,0.0007882215431891382
train/approx_kl(近似KL散度),8519680,1767851566.6495507,0.000683315796777606
train/approx_kl(近似KL散度),8552448,1767851570.5102527,0.0006117672892287374
train/approx_kl(近似KL散度),8585216,1767851574.3190894,0.0008193860994651914
train/approx_kl(近似KL散度),8617984,1767851578.10446,0.0006060516461730003
train/approx_kl(近似KL散度),8650752,1767851581.9328792,0.0006391992792487144
train/approx_kl(近似KL散度),8683520,1767851585.6849768,0.0006419675191864371
train/approx_kl(近似KL散度),8716288,1767851589.452577,0.0011148890480399132
train/approx_kl(近似KL散度),8749056,1767851593.3209686,0.0008144858293235302
train/approx_kl(近似KL散度),8781824,1767851597.117463,0.0005641158786602318
train/approx_kl(近似KL散度),8814592,1767851600.8884895,0.0008514594519510865
train/approx_kl(近似KL散度),8847360,1767851604.7922852,0.0008809349383227527
train/approx_kl(近似KL散度),8880128,1767851608.6254165,0.0008569001220166683
train/approx_kl(近似KL散度),8912896,1767851612.5267959,0.0009229613351635635
train/approx_kl(近似KL散度),8945664,1767851616.3148751,0.0006029219948686659
train/approx_kl(近似KL散度),8978432,1767851620.060589,0.0006124685169197619
train/approx_kl(近似KL散度),9011200,1767851623.9150236,0.000698683550581336
train/approx_kl(近似KL散度),9043968,1767851627.6861043,0.0009304165141656995
train/approx_kl(近似KL散度),9076736,1767851631.4564013,0.000522972084581852
train/approx_kl(近似KL散度),9109504,1767851635.3077714,0.00043657602509483695
train/approx_kl(近似KL散度),9142272,1767851639.1065817,0.000763661868404597
train/approx_kl(近似KL散度),9175040,1767851642.8536239,0.0008709809044376016
train/approx_kl(近似KL散度),9207808,1767851646.7242799,0.0006526943179778755
train/approx_kl(近似KL散度),9240576,1767851650.5223844,0.0005403920076787472
train/approx_kl(近似KL散度),9273344,1767851654.3266377,0.0008036148501560092
train/approx_kl(近似KL散度),9306112,1767851658.1292422,0.0009915211703628302
train/approx_kl(近似KL散度),9338880,1767851661.9003403,0.0009181412751786411
train/approx_kl(近似KL散度),9371648,1767851665.6797972,0.0008558938861824572
train/approx_kl(近似KL散度),9404416,1767851669.5427177,0.0018329510930925608
train/approx_kl(近似KL散度),9437184,1767851673.3655446,0.0007662124698981643
train/approx_kl(近似KL散度),9469952,1767851677.180017,0.00075780029874295
train/approx_kl(近似KL散度),9502720,1767851680.9703443,0.0006702962564304471
train/approx_kl(近似KL散度),9535488,1767851684.7552023,0.0009015475516207516
train/approx_kl(近似KL散度),9568256,1767851688.5870562,0.0006620674394071102
train/approx_kl(近似KL散度),9600000,1767851698.600738,0.0013191115576773882
train/approx_kl(近似KL散度),9633792,1767851702.5447552,0.000719939824193716
train/approx_kl(近似KL散度),9666560,1767851706.3297298,0.0007264206651598215
train/approx_kl(近似KL散度),9699328,1767851710.178134,0.0006670746952295303
train/approx_kl(近似KL散度),9732096,1767851713.9104607,0.0005762124201282859
train/approx_kl(近似KL散度),9764864,1767851717.6755009,0.0006890616496093571
train/approx_kl(近似KL散度),9797632,1767851721.4707024,0.0007369138184003532
train/approx_kl(近似KL散度),9830400,1767851725.2913725,0.0006141721969470382
train/approx_kl(近似KL散度),9863168,1767851729.1073449,0.0006118982564657927
train/approx_kl(近似KL散度),9895936,1767851732.8964748,0.0005521620623767376
train/approx_kl(近似KL散度),9928704,1767851736.723532,0.0005470038740895689
train/approx_kl(近似KL散度),9961472,1767851740.5198991,0.0008134228410199285
train/approx_kl(近似KL散度),9994240,1767851744.2771597,0.0005512599018402398
train/approx_kl(近似KL散度),10027008,1767851748.0839155,0.0008979967096820474
train/approx_kl(近似KL散度),10059776,1767851751.8725479,0.0004030098207294941
train/approx_kl(近似KL散度),10092544,1767851755.6664157,0.0009209728450514376
train/approx_kl(近似KL散度),10125312,1767851759.5029423,0.0006947935908101499
train/approx_kl(近似KL散度),10158080,1767851763.2659757,0.0007300867000594735
train/approx_kl(近似KL散度),10190848,1767851767.0469668,0.0008183654281310737
train/approx_kl(近似KL散度),10223616,1767851770.8760586,0.0008743978105485439
train/approx_kl(近似KL散度),10256384,1767851774.7005332,0.0009516948484815657
train/approx_kl(近似KL散度),10289152,1767851778.5006182,0.000995667651295662
train/approx_kl(近似KL散度),10321920,1767851782.3109753,0.0005314743611961603
train/approx_kl(近似KL散度),10354688,1767851786.103872,0.0007378740701824427
train/approx_kl(近似KL散度),10387456,1767851789.889282,0.0006617170292884111
train/approx_kl(近似KL散度),10420224,1767851793.661537,0.0007844110950827599
train/approx_kl(近似KL散度),10452992,1767851797.5050159,0.0005520861013792455
train/approx_kl(近似KL散度),10485760,1767851801.2503831,0.0006257101194933057
train/approx_kl(近似KL散度),10518528,1767851805.0712113,0.0006235137116163969
train/approx_kl(近似KL散度),10551296,1767851808.8688548,0.0008781448123045266
train/approx_kl(近似KL散度),10584064,1767851812.6389425,0.0006773447385057807
train/approx_kl(近似KL散度),10616832,1767851816.490222,0.0009888518834486604
train/approx_kl(近似KL散度),10649600,1767851820.25121,0.0005889400490559638
train/approx_kl(近似KL散度),10682368,1767851824.0040731,0.0007641628617420793
train/approx_kl(近似KL散度),10715136,1767851827.861113,0.0008038349915295839
train/approx_kl(近似KL散度),10747904,1767851831.6708193,0.0009389414335601032
train/approx_kl(近似KL散度),10780672,1767851835.4792118,0.0009320664685219526
train/approx_kl(近似KL散度),10813440,1767851839.280336,0.0008342337678186595
train/approx_kl(近似KL散度),10846208,1767851843.065974,0.0006185204838402569
train/approx_kl(近似KL散度),10878976,1767851846.8648553,0.0005881960387341678
train/approx_kl(近似KL散度),10911744,1767851850.6482563,0.0006337262457236648
train/approx_kl(近似KL散度),10944512,1767851854.4339461,0.0005350496503524482
train/approx_kl(近似KL散度),10977280,1767851858.2310927,0.0006592066492885351
train/approx_kl(近似KL散度),11010048,1767851862.1134384,0.0007576631614938378
train/approx_kl(近似KL散度),11042816,1767851865.956484,0.0009183947113342583
train/approx_kl(近似KL散度),11075584,1767851869.897537,0.0006151997949928045
train/approx_kl(近似KL散度),11108352,1767851873.7397423,0.0007303731981664896
train/approx_kl(近似KL散度),11141120,1767851877.6540227,0.0006951681571081281
train/approx_kl(近似KL散度),11173888,1767851881.5055263,0.0008581521105952561
train/approx_kl(近似KL散度),11200000,1767851890.859954,0.0005912448978051543
train/approx_kl(近似KL散度),11239424,1767851895.6584544,0.0006523265037685633
train/approx_kl(近似KL散度),11272192,1767851899.437363,0.0004782640025950968
train/approx_kl(近似KL散度),11304960,1767851903.2367744,0.0008265318465419114
train/approx_kl(近似KL散度),11337728,1767851907.0456638,0.0005770844873040915
train/approx_kl(近似KL散度),11370496,1767851910.8145862,0.0007740381988696754
train/approx_kl(近似KL散度),11403264,1767851914.5965257,0.0009222354274243116
train/approx_kl(近似KL散度),11436032,1767851918.434133,0.0006450372166000307
train/approx_kl(近似KL散度),11468800,1767851922.2353313,0.0007531840819865465
train/approx_kl(近似KL散度),11501568,1767851926.0057366,0.0004021399945486337
train/approx_kl(近似KL散度),11534336,1767851929.8337362,0.000981205957941711
train/approx_kl(近似KL散度),11567104,1767851933.6304746,0.0005942009156569839
train/approx_kl(近似KL散度),11599872,1767851937.4094367,0.0005306914681568742
train/approx_kl(近似KL散度),11632640,1767851941.2539635,0.0005578364944085479
train/approx_kl(近似KL散度),11665408,1767851945.0449657,0.000550838652998209
train/approx_kl(近似KL散度),11698176,1767851948.827807,0.0005865979474037886
train/approx_kl(近似KL散度),11730944,1767851952.6740668,0.0005630418309010565
train/approx_kl(近似KL散度),11763712,1767851956.4674273,0.0005162974121049047
train/approx_kl(近似KL散度),11796480,1767851960.358683,0.0009577836026437581
train/approx_kl(近似KL散度),11829248,1767851964.2478104,0.0007084713433869183
train/approx_kl(近似KL散度),11862016,1767851968.0738328,0.0005427582655102015
train/approx_kl(近似KL散度),11894784,1767851971.9493694,0.0006191342254169285
train/approx_kl(近似KL散度),11927552,1767851975.8429923,0.0006890848744660616
train/approx_kl(近似KL散度),11960320,1767851979.655874,0.0005935839144513011
train/approx_kl(近似KL散度),11993088,1767851983.4819186,0.0005121805006638169
train/approx_kl(近似KL散度),12025856,1767851987.3343585,0.0005336825852282345
train/approx_kl(近似KL散度),12058624,1767851991.2070632,0.0007567218272015452
train/approx_kl(近似KL散度),12091392,1767851995.0093503,0.0007191732292994857
train/approx_kl(近似KL散度),12124160,1767851998.8575733,0.001041908166371286
train/approx_kl(近似KL散度),12156928,1767852002.723118,0.0005926772719249129
train/approx_kl(近似KL散度),12189696,1767852006.6192544,0.0006950832903385162
train/approx_kl(近似KL散度),12222464,1767852010.4443982,0.00044439357588998973
train/approx_kl(近似KL散度),12255232,1767852014.2415743,0.0008206890779547393
train/approx_kl(近似KL散度),12288000,1767852018.0783741,0.0005549147026613355
train/approx_kl(近似KL散度),12320768,1767852021.9408715,0.0006069974624551833
train/approx_kl(近似KL散度),12353536,1767852025.8486497,0.0006282326648943126
train/approx_kl(近似KL散度),12386304,1767852029.716671,0.0006051715463399887
train/approx_kl(近似KL散度),12419072,1767852033.6132348,0.00047408591490238905
train/approx_kl(近似KL散度),12451840,1767852037.411729,0.0005288415122777224
train/approx_kl(近似KL散度),12484608,1767852041.2448833,0.000565436203032732
train/approx_kl(近似KL散度),12517376,1767852045.0343423,0.000702733057551086
train/approx_kl(近似KL散度),12550144,1767852048.8760827,0.0006671161390841007
train/approx_kl(近似KL散度),12582912,1767852052.7375727,0.0006942945765331388
train/approx_kl(近似KL散度),12615680,1767852056.60109,0.0005268578534014523
train/approx_kl(近似KL散度),12648448,1767852060.4723964,0.000596341211348772
train/approx_kl(近似KL散度),12681216,1767852064.3369222,0.0008171420195139945
train/approx_kl(近似KL散度),12713984,1767852068.303477,0.0005553191294893622
train/approx_kl(近似KL散度),12746752,1767852072.1466877,0.0006153724389150739
train/approx_kl(近似KL散度),12779520,1767852076.0867941,0.0005097555695101619
train/approx_kl(近似KL散度),12800000,1767852083.843321,0.0007541801314800978
train/approx_kl(近似KL散度),12845056,1767852089.3506994,0.0006402017315849662
train/approx_kl(近似KL散度),12877824,1767852093.240537,0.00046731592738069594
train/approx_kl(近似KL散度),12910592,1767852097.047181,0.0006610225536860526
train/approx_kl(近似KL散度),12943360,1767852100.8524952,0.0006658688653260469
train/approx_kl(近似KL散度),12976128,1767852104.6656787,0.0006705262931063771
train/approx_kl(近似KL散度),13008896,1767852108.5615203,0.0008047206792980433
train/approx_kl(近似KL散度),13041664,1767852112.3818095,0.0006428685737773776
train/approx_kl(近似KL散度),13074432,1767852116.144301,0.0006256460910663009
train/approx_kl(近似KL散度),13107200,1767852119.9847195,0.00042349821887910366
train/approx_kl(近似KL散度),13139968,1767852123.7673254,0.0004226241144351661
train/approx_kl(近似KL散度),13172736,1767852127.555611,0.0006479372968897223
train/approx_kl(近似KL散度),13205504,1767852131.4294608,0.0004816390573978424
train/approx_kl(近似KL散度),13238272,1767852135.2610745,0.0006239480571821332
train/approx_kl(近似KL散度),13271040,1767852139.1296704,0.00041781566687859595
train/approx_kl(近似KL散度),13303808,1767852142.939284,0.0006349646719172597
train/approx_kl(近似KL散度),13336576,1767852146.6933453,0.0005860071396455169
train/approx_kl(近似KL散度),13369344,1767852150.5655675,0.0007280691061168909
train/approx_kl(近似KL散度),13402112,1767852154.337042,0.0007743140449747443
train/approx_kl(近似KL散度),13434880,1767852158.1100445,0.00039296518662013113
train/approx_kl(近似KL散度),13467648,1767852161.9528158,0.0004007683019153774
train/approx_kl(近似KL散度),13500416,1767852165.7732508,0.000420743745053187
train/approx_kl(近似KL散度),13533184,1767852169.5396895,0.0005418277578428388
train/approx_kl(近似KL散度),13565952,1767852173.3529642,0.0004969386500306427
train/approx_kl(近似KL散度),13598720,1767852177.1586583,0.0004892520373687148
train/approx_kl(近似KL散度),13631488,1767852180.9323645,0.0006431445945054293
train/approx_kl(近似KL散度),13664256,1767852184.7686446,0.0006738814408890903
train/approx_kl(近似KL散度),13697024,1767852188.5371807,0.0007064698729664087
train/approx_kl(近似KL散度),13729792,1767852192.3260584,0.0003268567961640656
train/approx_kl(近似KL散度),13762560,1767852196.1565945,0.0005317647592164576
train/approx_kl(近似KL散度),13795328,1767852199.9392993,0.0005827328423038125
train/approx_kl(近似KL散度),13828096,1767852203.7457683,0.00040512793930247426
train/approx_kl(近似KL散度),13860864,1767852207.5603771,0.00047546482528559864
train/approx_kl(近似KL散度),13893632,1767852211.3222716,0.0004604719579219818
train/approx_kl(近似KL散度),13926400,1767852215.117207,0.0006231165607459843
train/approx_kl(近似KL散度),13959168,1767852218.9593084,0.0007156873471103609
train/approx_kl(近似KL散度),13991936,1767852222.7497587,0.0006389731424860656
train/approx_kl(近似KL散度),14024704,1767852226.5376217,0.0005630048690363765
train/approx_kl(近似KL散度),14057472,1767852230.341306,0.0006822607829235494
train/approx_kl(近似KL散度),14090240,1767852234.1532724,0.000534656981471926
train/approx_kl(近似KL散度),14123008,1767852237.9555166,0.0008564606541767716
train/approx_kl(近似KL散度),14155776,1767852241.7709186,0.0006850342033430934
train/approx_kl(近似KL散度),14188544,1767852245.580831,0.0005844633560627699
train/approx_kl(近似KL散度),14221312,1767852249.4112377,0.0004399494791869074
train/approx_kl(近似KL散度),14254080,1767852253.1772535,0.0006012634839862585
train/approx_kl(近似KL散度),14286848,1767852256.9677918,0.000525589392054826
train/approx_kl(近似KL散度),14319616,1767852260.8131015,0.00041223468724638224
train/approx_kl(近似KL散度),14352384,1767852264.6120255,0.0005281755002215505
train/approx_kl(近似KL散度),14385152,1767852268.473499,0.0004596261715050787
train/approx_kl(近似KL散度),14400000,1767852276.521322,0.0007027609972283244
train/approx_kl(近似KL散度),14450688,1767852282.5740464,0.0005803117528557777
train/approx_kl(近似KL散度),14483456,1767852286.3921025,0.0006958459853194654
train/approx_kl(近似KL散度),14516224,1767852290.2720983,0.00046892481623217463
train/approx_kl(近似KL散度),14548992,1767852294.1244688,0.0005232690018601716
train/approx_kl(近似KL散度),14581760,1767852297.9144642,0.0003079583984799683
train/approx_kl(近似KL散度),14614528,1767852301.7823184,0.00038378615863621235
train/approx_kl(近似KL散度),14647296,1767852305.590244,0.0007512046722695231
train/approx_kl(近似KL散度),14680064,1767852309.4423165,0.00041971926111727953
train/approx_kl(近似KL散度),14712832,1767852313.3254573,0.0005309148691594601
train/approx_kl(近似KL散度),14745600,1767852317.128722,0.0006114303832873702
train/approx_kl(近似KL散度),14778368,1767852320.9527233,0.0003169969713781029
train/approx_kl(近似KL散度),14811136,1767852324.7873342,0.0006069695809856057
train/approx_kl(近似KL散度),14843904,1767852328.6576471,0.0005717897438444197
train/approx_kl(近似KL散度),14876672,1767852332.5206673,0.0007239280384965241
train/approx_kl(近似KL散度),14909440,1767852336.2900808,0.0006445231847465038
train/approx_kl(近似KL散度),14942208,1767852340.1513834,0.00043077318696305156
train/approx_kl(近似KL散度),14974976,1767852343.9663556,0.00047410960542038083
train/approx_kl(近似KL散度),15007744,1767852347.8196182,0.000519275781698525
train/entropy_loss(熵損失),65536,1767850559.228526,-0.6903741359710693
train/entropy_loss(熵損失),98304,1767850562.996143,-0.6796344518661499
train/entropy_loss(熵損失),131072,1767850566.719327,-0.6612873077392578
train/entropy_loss(熵損失),163840,1767850570.4483514,-0.6354351043701172
train/entropy_loss(熵損失),196608,1767850574.1534498,-0.6058256030082703
train/entropy_loss(熵損失),229376,1767850577.8905578,-0.5765578150749207
train/entropy_loss(熵損失),262144,1767850581.583047,-0.538158655166626
train/entropy_loss(熵損失),294912,1767850585.2030509,-0.5118275880813599
train/entropy_loss(熵損失),327680,1767850588.9230797,-0.49919676780700684
train/entropy_loss(熵損失),360448,1767850592.6420286,-0.49756962060928345
train/entropy_loss(熵損失),393216,1767850596.5343516,-0.49430185556411743
train/entropy_loss(熵損失),425984,1767850600.2572355,-0.48719117045402527
train/entropy_loss(熵損失),458752,1767850604.004208,-0.4720344543457031
train/entropy_loss(熵損失),491520,1767850607.7767951,-0.4691275358200073
train/entropy_loss(熵損失),524288,1767850611.5745854,-0.46383434534072876
train/entropy_loss(熵損失),557056,1767850615.2046947,-0.45321744680404663
train/entropy_loss(熵損失),589824,1767850618.933322,-0.44807350635528564
train/entropy_loss(熵損失),622592,1767850622.619367,-0.44278010725975037
train/entropy_loss(熵損失),655360,1767850626.3165457,-0.4349498152732849
train/entropy_loss(熵損失),688128,1767850629.9219232,-0.427996963262558
train/entropy_loss(熵損失),720896,1767850633.6161911,-0.42811912298202515
train/entropy_loss(熵損失),753664,1767850637.1983774,-0.4176258146762848
train/entropy_loss(熵損失),786432,1767850640.8717477,-0.4153605103492737
train/entropy_loss(熵損失),819200,1767850644.4654818,-0.40437793731689453
train/entropy_loss(熵損失),851968,1767850648.1052475,-0.404305100440979
train/entropy_loss(熵損失),884736,1767850651.703579,-0.40003278851509094
train/entropy_loss(熵損失),917504,1767850655.3435278,-0.39038363099098206
train/entropy_loss(熵損失),950272,1767850659.0710485,-0.3863833546638489
train/entropy_loss(熵損失),983040,1767850662.7455473,-0.3855116665363312
train/entropy_loss(熵損失),1015808,1767850666.481074,-0.38252681493759155
train/entropy_loss(熵損失),1048576,1767850670.1074698,-0.3810669183731079
train/entropy_loss(熵損失),1081344,1767850673.8068314,-0.3735504746437073
train/entropy_loss(熵損失),1114112,1767850677.3988,-0.3757430911064148
train/entropy_loss(熵損失),1146880,1767850681.0832002,-0.36465513706207275
train/entropy_loss(熵損失),1179648,1767850684.683882,-0.36986789107322693
train/entropy_loss(熵損失),1212416,1767850688.3471098,-0.35858839750289917
train/entropy_loss(熵損失),1245184,1767850692.0412767,-0.36257079243659973
train/entropy_loss(熵損失),1277952,1767850695.7100718,-0.3547164499759674
train/entropy_loss(熵損失),1310720,1767850699.3796778,-0.3530133366584778
train/entropy_loss(熵損失),1343488,1767850703.1060586,-0.34838035702705383
train/entropy_loss(熵損失),1376256,1767850706.7275863,-0.3508034646511078
train/entropy_loss(熵損失),1409024,1767850710.4058769,-0.3442510664463043
train/entropy_loss(熵損失),1441792,1767850713.9961836,-0.34065037965774536
train/entropy_loss(熵損失),1474560,1767850717.6608357,-0.33949652314186096
train/entropy_loss(熵損失),1507328,1767850721.2686496,-0.33097895979881287
train/entropy_loss(熵損失),1540096,1767850724.905224,-0.331045538187027
train/entropy_loss(熵損失),1572864,1767850728.5152638,-0.32418158650398254
train/entropy_loss(熵損失),1600000,1767850737.0012846,-0.32549330592155457
train/entropy_loss(熵損失),1638400,1767850741.4428859,-0.3198132812976837
train/entropy_loss(熵損失),1671168,1767850745.0722322,-0.31545692682266235
train/entropy_loss(熵損失),1703936,1767850748.701232,-0.3125298321247101
train/entropy_loss(熵損失),1736704,1767850752.3870256,-0.31833523511886597
train/entropy_loss(熵損失),1769472,1767850755.9522567,-0.31023168563842773
train/entropy_loss(熵損失),1802240,1767850759.612867,-0.3003900945186615
train/entropy_loss(熵損失),1835008,1767850763.1786482,-0.3051380515098572
train/entropy_loss(熵損失),1867776,1767850766.815694,-0.29736652970314026
train/entropy_loss(熵損失),1900544,1767850770.3717258,-0.3066147565841675
train/entropy_loss(熵損失),1933312,1767850774.0567575,-0.29328155517578125
train/entropy_loss(熵損失),1966080,1767850777.6604764,-0.3089864253997803
train/entropy_loss(熵損失),1998848,1767850781.2761362,-0.2990780770778656
train/entropy_loss(熵損失),2031616,1767850784.883305,-0.2993713915348053
train/entropy_loss(熵損失),2064384,1767850788.492404,-0.30102619528770447
train/entropy_loss(熵損失),2097152,1767850792.2032356,-0.3020665645599365
train/entropy_loss(熵損失),2129920,1767850795.866282,-0.3032818138599396
train/entropy_loss(熵損失),2162688,1767850799.5272243,-0.3018588721752167
train/entropy_loss(熵損失),2195456,1767850803.2312806,-0.2905210852622986
train/entropy_loss(熵損失),2228224,1767850806.8434565,-0.2955816090106964
train/entropy_loss(熵損失),2260992,1767850810.455892,-0.2956348657608032
train/entropy_loss(熵損失),2293760,1767850814.0776038,-0.2791185677051544
train/entropy_loss(熵損失),2326528,1767850817.7324646,-0.29444295167922974
train/entropy_loss(熵損失),2359296,1767850821.3082688,-0.28613364696502686
train/entropy_loss(熵損失),2392064,1767850824.9743595,-0.2839909791946411
train/entropy_loss(熵損失),2424832,1767850828.55592,-0.2896362543106079
train/entropy_loss(熵損失),2457600,1767850832.2084389,-0.277962327003479
train/entropy_loss(熵損失),2490368,1767850835.7887897,-0.3004764914512634
train/entropy_loss(熵損失),2523136,1767850839.410689,-0.28635868430137634
train/entropy_loss(熵損失),2555904,1767850842.9688787,-0.28654640913009644
train/entropy_loss(熵損失),2588672,1767850846.6125402,-0.2861328721046448
train/entropy_loss(熵損失),2621440,1767850850.1919608,-0.29163995385169983
train/entropy_loss(熵損失),2654208,1767850853.8273733,-0.27834048867225647
train/entropy_loss(熵損失),2686976,1767850857.4195008,-0.2834187150001526
train/entropy_loss(熵損失),2719744,1767850861.3290613,-0.2753540873527527
train/entropy_loss(熵損失),2752512,1767850865.0908148,-0.27922412753105164
train/entropy_loss(熵損失),2785280,1767850869.031745,-0.25974583625793457
train/entropy_loss(熵損失),2818048,1767850872.8489573,-0.26820772886276245
train/entropy_loss(熵損失),2850816,1767850876.7107396,-0.25939005613327026
train/entropy_loss(熵損失),2883584,1767850880.4894252,-0.2754828929901123
train/entropy_loss(熵損失),2916352,1767850884.3961153,-0.2545723617076874
train/entropy_loss(熵損失),2949120,1767850888.1782212,-0.26920080184936523
train/entropy_loss(熵損失),2981888,1767850891.9776053,-0.2577824592590332
train/entropy_loss(熵損失),3014656,1767850895.7577431,-0.26966118812561035
train/entropy_loss(熵損失),3047424,1767850899.581668,-0.2646036148071289
train/entropy_loss(熵損失),3080192,1767850903.3661573,-0.2512407898902893
train/entropy_loss(熵損失),3112960,1767850907.1832235,-0.2604595124721527
train/entropy_loss(熵損失),3145728,1767850911.2433429,-0.24827173352241516
train/entropy_loss(熵損失),3178496,1767850915.1832602,-0.2639792859554291
train/entropy_loss(熵損失),3200000,1767850924.5230672,-0.2545093595981598
train/entropy_loss(熵損失),3244032,1767850929.708885,-0.254509299993515
train/entropy_loss(熵損失),3276800,1767850933.5472097,-0.2444724589586258
train/entropy_loss(熵損失),3309568,1767850937.467982,-0.262850284576416
train/entropy_loss(熵損失),3342336,1767850941.3087542,-0.24151454865932465
train/entropy_loss(熵損失),3375104,1767850945.2962406,-0.2521294355392456
train/entropy_loss(熵損失),3407872,1767850949.2090595,-0.24488702416419983
train/entropy_loss(熵損失),3440640,1767850952.9483771,-0.2375022917985916
train/entropy_loss(熵損失),3473408,1767850957.3175955,-0.24889831244945526
train/entropy_loss(熵損失),3506176,1767850961.4267182,-0.24445413053035736
train/entropy_loss(熵損失),3538944,1767850965.30745,-0.23900124430656433
train/entropy_loss(熵損失),3571712,1767850969.296191,-0.24838709831237793
train/entropy_loss(熵損失),3604480,1767850972.9610317,-0.24408288300037384
train/entropy_loss(熵損失),3637248,1767850976.7373757,-0.2510291337966919
train/entropy_loss(熵損失),3670016,1767850980.5669193,-0.23411701619625092
train/entropy_loss(熵損失),3702784,1767850984.6186466,-0.23770824074745178
train/entropy_loss(熵損失),3735552,1767850988.6584132,-0.2367497831583023
train/entropy_loss(熵損失),3768320,1767850992.5548205,-0.24713434278964996
train/entropy_loss(熵損失),3801088,1767850996.5146782,-0.2426317185163498
train/entropy_loss(熵損失),3833856,1767851000.422122,-0.2588566839694977
train/entropy_loss(熵損失),3866624,1767851004.6852853,-0.22428371012210846
train/entropy_loss(熵損失),3899392,1767851008.561874,-0.23664505779743195
train/entropy_loss(熵損失),3932160,1767851012.599403,-0.23114079236984253
train/entropy_loss(熵損失),3964928,1767851016.6966462,-0.2499150037765503
train/entropy_loss(熵損失),3997696,1767851020.5565472,-0.22168758511543274
train/entropy_loss(熵損失),4030464,1767851024.2745268,-0.2451888620853424
train/entropy_loss(熵損失),4063232,1767851027.931706,-0.23658870160579681
train/entropy_loss(熵損失),4096000,1767851031.6902683,-0.2358010858297348
train/entropy_loss(熵損失),4128768,1767851035.552128,-0.24712511897087097
train/entropy_loss(熵損失),4161536,1767851039.3616033,-0.23928214609622955
train/entropy_loss(熵損失),4194304,1767851043.1991954,-0.2565135657787323
train/entropy_loss(熵損失),4227072,1767851047.1003935,-0.2443654090166092
train/entropy_loss(熵損失),4259840,1767851050.8482265,-0.2259136289358139
train/entropy_loss(熵損失),4292608,1767851054.8405092,-0.2513662874698639
train/entropy_loss(熵損失),4325376,1767851058.8245432,-0.22131934762001038
train/entropy_loss(熵損失),4358144,1767851062.640887,-0.24107837677001953
train/entropy_loss(熵損失),4390912,1767851066.511372,-0.2352246195077896
train/entropy_loss(熵損失),4423680,1767851070.3151045,-0.2404673546552658
train/entropy_loss(熵損失),4456448,1767851074.1013825,-0.2298697978258133
train/entropy_loss(熵損失),4489216,1767851077.8736207,-0.23557312786579132
train/entropy_loss(熵損失),4521984,1767851081.7243874,-0.23311778903007507
train/entropy_loss(熵損失),4554752,1767851085.5352962,-0.23556245863437653
train/entropy_loss(熵損失),4587520,1767851089.4027958,-0.2292425036430359
train/entropy_loss(熵損失),4620288,1767851093.227601,-0.24048545956611633
train/entropy_loss(熵損失),4653056,1767851097.0151076,-0.24003326892852783
train/entropy_loss(熵損失),4685824,1767851100.8662007,-0.22394125163555145
train/entropy_loss(熵損失),4718592,1767851104.6115327,-0.23743608593940735
train/entropy_loss(熵損失),4751360,1767851108.3256793,-0.2341708540916443
train/entropy_loss(熵損失),4784128,1767851112.1232119,-0.2396809309720993
train/entropy_loss(熵損失),4800000,1767851120.069484,-0.21939128637313843
train/entropy_loss(熵損失),4849664,1767851125.9408178,-0.2502128481864929
train/entropy_loss(熵損失),4882432,1767851129.6968298,-0.25174275040626526
train/entropy_loss(熵損失),4915200,1767851133.48323,-0.24997757375240326
train/entropy_loss(熵損失),4947968,1767851137.2527626,-0.23538242280483246
train/entropy_loss(熵損失),4980736,1767851141.0984478,-0.2402511090040207
train/entropy_loss(熵損失),5013504,1767851144.8310637,-0.2622322142124176
train/entropy_loss(熵損失),5046272,1767851148.5421064,-0.24369679391384125
train/entropy_loss(熵損失),5079040,1767851152.4145024,-0.20667748153209686
train/entropy_loss(熵損失),5111808,1767851156.2059376,-0.25096121430397034
train/entropy_loss(熵損失),5144576,1767851159.8980644,-0.23020035028457642
train/entropy_loss(熵損失),5177344,1767851163.7191901,-0.2468775063753128
train/entropy_loss(熵損失),5210112,1767851167.4530969,-0.2315504550933838
train/entropy_loss(熵損失),5242880,1767851171.206861,-0.23609037697315216
train/entropy_loss(熵損失),5275648,1767851174.9225078,-0.22581414878368378
train/entropy_loss(熵損失),5308416,1767851178.7835948,-0.23028433322906494
train/entropy_loss(熵損失),5341184,1767851182.6305401,-0.23202073574066162
train/entropy_loss(熵損失),5373952,1767851186.3842208,-0.2397197037935257
train/entropy_loss(熵損失),5406720,1767851190.255159,-0.23397015035152435
train/entropy_loss(熵損失),5439488,1767851194.0659354,-0.22886835038661957
train/entropy_loss(熵損失),5472256,1767851197.8260283,-0.24437040090560913
train/entropy_loss(熵損失),5505024,1767851201.6629026,-0.21872153878211975
train/entropy_loss(熵損失),5537792,1767851205.4095185,-0.23484192788600922
train/entropy_loss(熵損失),5570560,1767851209.1647682,-0.20715612173080444
train/entropy_loss(熵損失),5603328,1767851212.9930987,-0.2438177615404129
train/entropy_loss(熵損失),5636096,1767851216.7795317,-0.20762838423252106
train/entropy_loss(熵損失),5668864,1767851220.50399,-0.22657854855060577
train/entropy_loss(熵損失),5701632,1767851224.3482041,-0.2213371843099594
train/entropy_loss(熵損失),5734400,1767851228.1825051,-0.21644280850887299
train/entropy_loss(熵損失),5767168,1767851231.940569,-0.2222597748041153
train/entropy_loss(熵損失),5799936,1767851235.8235393,-0.23401252925395966
train/entropy_loss(熵損失),5832704,1767851239.639634,-0.2235809862613678
train/entropy_loss(熵損失),5865472,1767851243.3867345,-0.24206218123435974
train/entropy_loss(熵損失),5898240,1767851247.2597299,-0.23319125175476074
train/entropy_loss(熵損失),5931008,1767851251.0267448,-0.22986093163490295
train/entropy_loss(熵損失),5963776,1767851254.8078127,-0.22874508798122406
train/entropy_loss(熵損失),5996544,1767851258.8188546,-0.21547800302505493
train/entropy_loss(熵損失),6029312,1767851262.7803826,-0.23587974905967712
train/entropy_loss(熵損失),6062080,1767851266.7045023,-0.20328643918037415
train/entropy_loss(熵損失),6094848,1767851270.5552242,-0.22798511385917664
train/entropy_loss(熵損失),6127616,1767851274.4984272,-0.2104136347770691
train/entropy_loss(熵損失),6160384,1767851278.5352979,-0.21610867977142334
train/entropy_loss(熵損失),6193152,1767851282.497792,-0.2114964872598648
train/entropy_loss(熵損失),6225920,1767851286.371077,-0.21572472155094147
train/entropy_loss(熵損失),6258688,1767851290.2993336,-0.1973571926355362
train/entropy_loss(熵損失),6291456,1767851294.1221151,-0.22138497233390808
train/entropy_loss(熵損失),6324224,1767851298.0558202,-0.20740684866905212
train/entropy_loss(熵損失),6356992,1767851301.9332805,-0.20257697999477386
train/entropy_loss(熵損失),6389760,1767851305.9020336,-0.23607231676578522
train/entropy_loss(熵損失),6400000,1767851311.462924,-0.21564242243766785
train/entropy_loss(熵損失),6455296,1767851318.2926252,-0.207210972905159
train/entropy_loss(熵損失),6488064,1767851322.189184,-0.20290032029151917
train/entropy_loss(熵損失),6520832,1767851326.0816662,-0.22205804288387299
train/entropy_loss(熵損失),6553600,1767851329.9729526,-0.20166395604610443
train/entropy_loss(熵損失),6586368,1767851333.914084,-0.2232944667339325
train/entropy_loss(熵損失),6619136,1767851337.7628021,-0.2054818570613861
train/entropy_loss(熵損失),6651904,1767851341.701503,-0.22918997704982758
train/entropy_loss(熵損失),6684672,1767851345.6731632,-0.20436036586761475
train/entropy_loss(熵損失),6717440,1767851349.560387,-0.21794649958610535
train/entropy_loss(熵損失),6750208,1767851353.5039809,-0.22511783242225647
train/entropy_loss(熵損失),6782976,1767851357.4343462,-0.21631821990013123
train/entropy_loss(熵損失),6815744,1767851361.2815995,-0.20996953547000885
train/entropy_loss(熵損失),6848512,1767851365.1255405,-0.21270573139190674
train/entropy_loss(熵損失),6881280,1767851369.1308281,-0.23509931564331055
train/entropy_loss(熵損失),6914048,1767851373.0831103,-0.1924140304327011
train/entropy_loss(熵損失),6946816,1767851376.9331527,-0.2448534220457077
train/entropy_loss(熵損失),6979584,1767851380.8888044,-0.1936781257390976
train/entropy_loss(熵損失),7012352,1767851384.8043604,-0.2273690551519394
train/entropy_loss(熵損失),7045120,1767851388.6258478,-0.20491626858711243
train/entropy_loss(熵損失),7077888,1767851392.4364486,-0.21240849792957306
train/entropy_loss(熵損失),7110656,1767851396.205339,-0.1990848034620285
train/entropy_loss(熵損失),7143424,1767851400.0019038,-0.22235709428787231
train/entropy_loss(熵損失),7176192,1767851403.8091478,-0.20028142631053925
train/entropy_loss(熵損失),7208960,1767851407.556572,-0.21881887316703796
train/entropy_loss(熵損失),7241728,1767851411.3092682,-0.2149089276790619
train/entropy_loss(熵損失),7274496,1767851415.177134,-0.21270109713077545
train/entropy_loss(熵損失),7307264,1767851418.9848976,-0.21409332752227783
train/entropy_loss(熵損失),7340032,1767851422.7503793,-0.20247966051101685
train/entropy_loss(熵損失),7372800,1767851426.6533804,-0.2154349535703659
train/entropy_loss(熵損失),7405568,1767851430.4099774,-0.20702332258224487
train/entropy_loss(熵損失),7438336,1767851434.2532735,-0.20614728331565857
train/entropy_loss(熵損失),7471104,1767851438.0266423,-0.2192998230457306
train/entropy_loss(熵損失),7503872,1767851441.8613071,-0.19314976036548615
train/entropy_loss(熵損失),7536640,1767851445.6970434,-0.22269394993782043
train/entropy_loss(熵損失),7569408,1767851449.6036465,-0.20977038145065308
train/entropy_loss(熵損失),7602176,1767851453.3829386,-0.20597422122955322
train/entropy_loss(熵損失),7634944,1767851457.202003,-0.21493223309516907
train/entropy_loss(熵損失),7667712,1767851461.0313587,-0.2078578621149063
train/entropy_loss(熵損失),7700480,1767851464.834783,-0.23196867108345032
train/entropy_loss(熵損失),7733248,1767851468.6625133,-0.18680720031261444
train/entropy_loss(熵損失),7766016,1767851472.5628033,-0.23698243498802185
train/entropy_loss(熵損失),7798784,1767851476.44101,-0.1892993450164795
train/entropy_loss(熵損失),7831552,1767851480.220457,-0.22865426540374756
train/entropy_loss(熵損失),7864320,1767851484.0781865,-0.19735653698444366
train/entropy_loss(熵損失),7897088,1767851487.9261947,-0.2295803278684616
train/entropy_loss(熵損失),7929856,1767851491.717675,-0.19333697855472565
train/entropy_loss(熵損失),7962624,1767851495.5764532,-0.22321194410324097
train/entropy_loss(熵損失),7995392,1767851499.3429677,-0.2161744087934494
train/entropy_loss(熵損失),8000000,1767851506.12033,-0.1873232126235962
train/entropy_loss(熵損失),8060928,1767851513.3896632,-0.22560840845108032
train/entropy_loss(熵損失),8093696,1767851517.216103,-0.18027178943157196
train/entropy_loss(熵損失),8126464,1767851521.0065434,-0.2240060269832611
train/entropy_loss(熵損失),8159232,1767851524.8318646,-0.18361037969589233
train/entropy_loss(熵損失),8192000,1767851528.6107416,-0.2316134124994278
train/entropy_loss(熵損失),8224768,1767851532.4548416,-0.18800942599773407
train/entropy_loss(熵損失),8257536,1767851536.3604865,-0.24207031726837158
train/entropy_loss(熵損失),8290304,1767851540.1405644,-0.2000429630279541
train/entropy_loss(熵損失),8323072,1767851543.9752173,-0.21308091282844543
train/entropy_loss(熵損失),8355840,1767851547.7974606,-0.2338252067565918
train/entropy_loss(熵損失),8388608,1767851551.5882347,-0.19659695029258728
train/entropy_loss(熵損失),8421376,1767851555.4249458,-0.21614447236061096
train/entropy_loss(熵損失),8454144,1767851559.1645546,-0.20294584333896637
train/entropy_loss(熵損失),8486912,1767851562.9092748,-0.22679458558559418
train/entropy_loss(熵損失),8519680,1767851566.6495507,-0.20240575075149536
train/entropy_loss(熵損失),8552448,1767851570.5102527,-0.2437695860862732
train/entropy_loss(熵損失),8585216,1767851574.3190894,-0.20558862388134003
train/entropy_loss(熵損失),8617984,1767851578.10446,-0.2319592982530594
train/entropy_loss(熵損失),8650752,1767851581.9328792,-0.20521065592765808
train/entropy_loss(熵損失),8683520,1767851585.6849768,-0.2552034556865692
train/entropy_loss(熵損失),8716288,1767851589.452577,-0.19915755093097687
train/entropy_loss(熵損失),8749056,1767851593.3209686,-0.24438174068927765
train/entropy_loss(熵損失),8781824,1767851597.117463,-0.19133761525154114
train/entropy_loss(熵損失),8814592,1767851600.8884895,-0.23695139586925507
train/entropy_loss(熵損失),8847360,1767851604.7932854,-0.23245885968208313
train/entropy_loss(熵損失),8880128,1767851608.6254165,-0.2152141034603119
train/entropy_loss(熵損失),8912896,1767851612.5267959,-0.2365732640028
train/entropy_loss(熵損失),8945664,1767851616.3148751,-0.207806795835495
train/entropy_loss(熵損失),8978432,1767851620.060589,-0.21932563185691833
train/entropy_loss(熵損失),9011200,1767851623.9150236,-0.21709059178829193
train/entropy_loss(熵損失),9043968,1767851627.6861043,-0.22081337869167328
train/entropy_loss(熵損失),9076736,1767851631.4564013,-0.2134018987417221
train/entropy_loss(熵損失),9109504,1767851635.3077714,-0.21669577062129974
train/entropy_loss(熵損失),9142272,1767851639.1065817,-0.20421378314495087
train/entropy_loss(熵損失),9175040,1767851642.8536239,-0.21364416182041168
train/entropy_loss(熵損失),9207808,1767851646.7242799,-0.19964514672756195
train/entropy_loss(熵損失),9240576,1767851650.523385,-0.2312554568052292
train/entropy_loss(熵損失),9273344,1767851654.3266377,-0.20100228488445282
train/entropy_loss(熵損失),9306112,1767851658.129918,-0.2198934257030487
train/entropy_loss(熵損失),9338880,1767851661.9003403,-0.22059468924999237
train/entropy_loss(熵損失),9371648,1767851665.6797972,-0.20546016097068787
train/entropy_loss(熵損失),9404416,1767851669.5427177,-0.257763534784317
train/entropy_loss(熵損失),9437184,1767851673.3655446,-0.19754154980182648
train/entropy_loss(熵損失),9469952,1767851677.180017,-0.2303643673658371
train/entropy_loss(熵損失),9502720,1767851680.9703443,-0.20460739731788635
train/entropy_loss(熵損失),9535488,1767851684.7552023,-0.21389004588127136
train/entropy_loss(熵損失),9568256,1767851688.5870562,-0.21742196381092072
train/entropy_loss(熵損失),9600000,1767851698.600738,-0.21477001905441284
train/entropy_loss(熵損失),9633792,1767851702.5447552,-0.2156352698802948
train/entropy_loss(熵損失),9666560,1767851706.3297298,-0.21363677084445953
train/entropy_loss(熵損失),9699328,1767851710.178134,-0.21996337175369263
train/entropy_loss(熵損失),9732096,1767851713.9104607,-0.24278759956359863
train/entropy_loss(熵損失),9764864,1767851717.6755009,-0.20176130533218384
train/entropy_loss(熵損失),9797632,1767851721.4707024,-0.22220152616500854
train/entropy_loss(熵損失),9830400,1767851725.2913725,-0.2371474802494049
train/entropy_loss(熵損失),9863168,1767851729.1073449,-0.2022990733385086
train/entropy_loss(熵損失),9895936,1767851732.8964748,-0.2360636442899704
train/entropy_loss(熵損失),9928704,1767851736.723532,-0.19814231991767883
train/entropy_loss(熵損失),9961472,1767851740.5198991,-0.21613582968711853
train/entropy_loss(熵損失),9994240,1767851744.2771597,-0.2232685089111328
train/entropy_loss(熵損失),10027008,1767851748.0839155,-0.23447583615779877
train/entropy_loss(熵損失),10059776,1767851751.8725479,-0.2087283581495285
train/entropy_loss(熵損失),10092544,1767851755.6664157,-0.21048419177532196
train/entropy_loss(熵損失),10125312,1767851759.5029423,-0.20617829263210297
train/entropy_loss(熵損失),10158080,1767851763.2659757,-0.20253346860408783
train/entropy_loss(熵損失),10190848,1767851767.0469668,-0.21622614562511444
train/entropy_loss(熵損失),10223616,1767851770.8760586,-0.21612507104873657
train/entropy_loss(熵損失),10256384,1767851774.7005332,-0.21347607672214508
train/entropy_loss(熵損失),10289152,1767851778.5006182,-0.23447923362255096
train/entropy_loss(熵損失),10321920,1767851782.3109753,-0.21920336782932281
train/entropy_loss(熵損失),10354688,1767851786.103872,-0.2523898482322693
train/entropy_loss(熵損失),10387456,1767851789.889282,-0.21493417024612427
train/entropy_loss(熵損失),10420224,1767851793.661537,-0.2271774709224701
train/entropy_loss(熵損失),10452992,1767851797.5050159,-0.2132798433303833
train/entropy_loss(熵損失),10485760,1767851801.2503831,-0.2102968394756317
train/entropy_loss(熵損失),10518528,1767851805.0712113,-0.2272990345954895
train/entropy_loss(熵損失),10551296,1767851808.8688548,-0.23995521664619446
train/entropy_loss(熵損失),10584064,1767851812.6389425,-0.19472278654575348
train/entropy_loss(熵損失),10616832,1767851816.490222,-0.237859308719635
train/entropy_loss(熵損失),10649600,1767851820.25121,-0.19563589990139008
train/entropy_loss(熵損失),10682368,1767851824.0040731,-0.2147834748029709
train/entropy_loss(熵損失),10715136,1767851827.861113,-0.2186228334903717
train/entropy_loss(熵損失),10747904,1767851831.6708193,-0.20310194790363312
train/entropy_loss(熵損失),10780672,1767851835.4792118,-0.23980644345283508
train/entropy_loss(熵損失),10813440,1767851839.280336,-0.21432402729988098
train/entropy_loss(熵損失),10846208,1767851843.065974,-0.19737966358661652
train/entropy_loss(熵損失),10878976,1767851846.8648553,-0.22729022800922394
train/entropy_loss(熵損失),10911744,1767851850.6482563,-0.19820250570774078
train/entropy_loss(熵損失),10944512,1767851854.4339461,-0.22015763819217682
train/entropy_loss(熵損失),10977280,1767851858.2310927,-0.22152377665042877
train/entropy_loss(熵損失),11010048,1767851862.1134384,-0.2089916318655014
train/entropy_loss(熵損失),11042816,1767851865.956484,-0.21450702846050262
train/entropy_loss(熵損失),11075584,1767851869.897537,-0.21178829669952393
train/entropy_loss(熵損失),11108352,1767851873.7397423,-0.2323605865240097
train/entropy_loss(熵損失),11141120,1767851877.6540227,-0.2293170988559723
train/entropy_loss(熵損失),11173888,1767851881.5055263,-0.21906974911689758
train/entropy_loss(熵損失),11200000,1767851890.859954,-0.2392108291387558
train/entropy_loss(熵損失),11239424,1767851895.6584544,-0.20790283381938934
train/entropy_loss(熵損失),11272192,1767851899.437363,-0.21588367223739624
train/entropy_loss(熵損失),11304960,1767851903.2367744,-0.2132437527179718
train/entropy_loss(熵損失),11337728,1767851907.0456638,-0.21431244909763336
train/entropy_loss(熵損失),11370496,1767851910.8145862,-0.2389194369316101
train/entropy_loss(熵損失),11403264,1767851914.5965257,-0.20040057599544525
train/entropy_loss(熵損失),11436032,1767851918.434133,-0.23822230100631714
train/entropy_loss(熵損失),11468800,1767851922.2353313,-0.21717038750648499
train/entropy_loss(熵損失),11501568,1767851926.0057366,-0.2621822655200958
train/entropy_loss(熵損失),11534336,1767851929.8337362,-0.22473986446857452
train/entropy_loss(熵損失),11567104,1767851933.6304746,-0.22493955492973328
train/entropy_loss(熵損失),11599872,1767851937.4094367,-0.20652653276920319
train/entropy_loss(熵損失),11632640,1767851941.2539635,-0.2540721297264099
train/entropy_loss(熵損失),11665408,1767851945.0449657,-0.2112865447998047
train/entropy_loss(熵損失),11698176,1767851948.827807,-0.25830334424972534
train/entropy_loss(熵損失),11730944,1767851952.675069,-0.23956331610679626
train/entropy_loss(熵損失),11763712,1767851956.4674273,-0.2615862786769867
train/entropy_loss(熵損失),11796480,1767851960.358683,-0.18983416259288788
train/entropy_loss(熵損失),11829248,1767851964.2478104,-0.2594138979911804
train/entropy_loss(熵損失),11862016,1767851968.0738328,-0.1818174123764038
train/entropy_loss(熵損失),11894784,1767851971.9493694,-0.25981685519218445
train/entropy_loss(熵損失),11927552,1767851975.8429923,-0.20841586589813232
train/entropy_loss(熵損失),11960320,1767851979.655874,-0.2567247450351715
train/entropy_loss(熵損失),11993088,1767851983.4819186,-0.2079804688692093
train/entropy_loss(熵損失),12025856,1767851987.3343585,-0.20681442320346832
train/entropy_loss(熵損失),12058624,1767851991.2070632,-0.2294870764017105
train/entropy_loss(熵損失),12091392,1767851995.0093503,-0.25263166427612305
train/entropy_loss(熵損失),12124160,1767851998.8575733,-0.21303130686283112
train/entropy_loss(熵損失),12156928,1767852002.723118,-0.21314094960689545
train/entropy_loss(熵損失),12189696,1767852006.6192544,-0.2377055436372757
train/entropy_loss(熵損失),12222464,1767852010.4443982,-0.19679094851016998
train/entropy_loss(熵損失),12255232,1767852014.2415743,-0.22936350107192993
train/entropy_loss(熵損失),12288000,1767852018.0783741,-0.24309682846069336
train/entropy_loss(熵損失),12320768,1767852021.9408715,-0.22141239047050476
train/entropy_loss(熵損失),12353536,1767852025.8486497,-0.20570971071720123
train/entropy_loss(熵損失),12386304,1767852029.716671,-0.2361961156129837
train/entropy_loss(熵損失),12419072,1767852033.6132348,-0.2154396027326584
train/entropy_loss(熵損失),12451840,1767852037.411729,-0.22565287351608276
train/entropy_loss(熵損失),12484608,1767852041.2448833,-0.185294508934021
train/entropy_loss(熵損失),12517376,1767852045.0343423,-0.22489126026630402
train/entropy_loss(熵損失),12550144,1767852048.8760827,-0.21264386177062988
train/entropy_loss(熵損失),12582912,1767852052.7375727,-0.255982369184494
train/entropy_loss(熵損失),12615680,1767852056.60109,-0.22613747417926788
train/entropy_loss(熵損失),12648448,1767852060.4723964,-0.20632915198802948
train/entropy_loss(熵損失),12681216,1767852064.3369222,-0.21264606714248657
train/entropy_loss(熵損失),12713984,1767852068.303477,-0.25967270135879517
train/entropy_loss(熵損失),12746752,1767852072.1466877,-0.24684195220470428
train/entropy_loss(熵損失),12779520,1767852076.0867941,-0.21912416815757751
train/entropy_loss(熵損失),12800000,1767852083.843321,-0.2517470419406891
train/entropy_loss(熵損失),12845056,1767852089.3506994,-0.2537961006164551
train/entropy_loss(熵損失),12877824,1767852093.240537,-0.24354863166809082
train/entropy_loss(熵損失),12910592,1767852097.047181,-0.22629587352275848
train/entropy_loss(熵損失),12943360,1767852100.8524952,-0.20097209513187408
train/entropy_loss(熵損失),12976128,1767852104.6656787,-0.23325328528881073
train/entropy_loss(熵損失),13008896,1767852108.5615203,-0.21116851270198822
train/entropy_loss(熵損失),13041664,1767852112.3818095,-0.28531336784362793
train/entropy_loss(熵損失),13074432,1767852116.144301,-0.2035285234451294
train/entropy_loss(熵損失),13107200,1767852119.9847195,-0.25792574882507324
train/entropy_loss(熵損失),13139968,1767852123.7673254,-0.22045469284057617
train/entropy_loss(熵損失),13172736,1767852127.555611,-0.21036525070667267
train/entropy_loss(熵損失),13205504,1767852131.4294608,-0.20511311292648315
train/entropy_loss(熵損失),13238272,1767852135.2610745,-0.2272566556930542
train/entropy_loss(熵損失),13271040,1767852139.1296704,-0.19672848284244537
train/entropy_loss(熵損失),13303808,1767852142.939284,-0.20302757620811462
train/entropy_loss(熵損失),13336576,1767852146.6933453,-0.19945913553237915
train/entropy_loss(熵損失),13369344,1767852150.5655675,-0.22147081792354584
train/entropy_loss(熵損失),13402112,1767852154.337042,-0.18657638132572174
train/entropy_loss(熵損失),13434880,1767852158.1100445,-0.21274052560329437
train/entropy_loss(熵損失),13467648,1767852161.9528158,-0.20530271530151367
train/entropy_loss(熵損失),13500416,1767852165.7732508,-0.21729938685894012
train/entropy_loss(熵損失),13533184,1767852169.5396895,-0.19039684534072876
train/entropy_loss(熵損失),13565952,1767852173.3529642,-0.21286161243915558
train/entropy_loss(熵損失),13598720,1767852177.1586583,-0.19718679785728455
train/entropy_loss(熵損失),13631488,1767852180.9323645,-0.21547895669937134
train/entropy_loss(熵損失),13664256,1767852184.7686446,-0.18664737045764923
train/entropy_loss(熵損失),13697024,1767852188.5371807,-0.20662644505500793
train/entropy_loss(熵損失),13729792,1767852192.3260584,-0.1696099042892456
train/entropy_loss(熵損失),13762560,1767852196.1565945,-0.229359969496727
train/entropy_loss(熵損失),13795328,1767852199.9392993,-0.14770077168941498
train/entropy_loss(熵損失),13828096,1767852203.7457683,-0.2307160198688507
train/entropy_loss(熵損失),13860864,1767852207.5603771,-0.2133176475763321
train/entropy_loss(熵損失),13893632,1767852211.3222716,-0.20106074213981628
train/entropy_loss(熵損失),13926400,1767852215.117207,-0.22739757597446442
train/entropy_loss(熵損失),13959168,1767852218.9593084,-0.20330925285816193
train/entropy_loss(熵損失),13991936,1767852222.7497587,-0.2079445719718933
train/entropy_loss(熵損失),14024704,1767852226.5376217,-0.21943874657154083
train/entropy_loss(熵損失),14057472,1767852230.341306,-0.23010234534740448
train/entropy_loss(熵損失),14090240,1767852234.1532724,-0.21128936111927032
train/entropy_loss(熵損失),14123008,1767852237.9555166,-0.18094472587108612
train/entropy_loss(熵損失),14155776,1767852241.7709186,-0.22810068726539612
train/entropy_loss(熵損失),14188544,1767852245.580831,-0.19751319289207458
train/entropy_loss(熵損失),14221312,1767852249.4112377,-0.18119317293167114
train/entropy_loss(熵損失),14254080,1767852253.1772535,-0.21042084693908691
train/entropy_loss(熵損失),14286848,1767852256.9677918,-0.19017267227172852
train/entropy_loss(熵損失),14319616,1767852260.8131015,-0.18371815979480743
train/entropy_loss(熵損失),14352384,1767852264.6120255,-0.22929790616035461
train/entropy_loss(熵損失),14385152,1767852268.473499,-0.16749930381774902
train/entropy_loss(熵損失),14400000,1767852276.521322,-0.21621893346309662
train/entropy_loss(熵損失),14450688,1767852282.5740464,-0.15962669253349304
train/entropy_loss(熵損失),14483456,1767852286.3921025,-0.21666176617145538
train/entropy_loss(熵損失),14516224,1767852290.2720983,-0.2089950442314148
train/entropy_loss(熵損失),14548992,1767852294.1244688,-0.17993055284023285
train/entropy_loss(熵損失),14581760,1767852297.9144642,-0.21081100404262543
train/entropy_loss(熵損失),14614528,1767852301.7823184,-0.19951492547988892
train/entropy_loss(熵損失),14647296,1767852305.590244,-0.23059377074241638
train/entropy_loss(熵損失),14680064,1767852309.4423165,-0.2109677791595459
train/entropy_loss(熵損失),14712832,1767852313.3254573,-0.19433057308197021
train/entropy_loss(熵損失),14745600,1767852317.128722,-0.23865239322185516
train/entropy_loss(熵損失),14778368,1767852320.9527233,-0.1794607788324356
train/entropy_loss(熵損失),14811136,1767852324.7873342,-0.204136922955513
train/entropy_loss(熵損失),14843904,1767852328.6576471,-0.2116169035434723
train/entropy_loss(熵損失),14876672,1767852332.5206673,-0.18882623314857483
train/entropy_loss(熵損失),14909440,1767852336.2900808,-0.20579618215560913
train/entropy_loss(熵損失),14942208,1767852340.1513834,-0.16152730584144592
train/entropy_loss(熵損失),14974976,1767852343.9663556,-0.22532565891742706
train/entropy_loss(熵損失),15007744,1767852347.8196182,-0.18132418394088745
train/explained_variance(價值預測準確度),65536,1767850559.228526,-0.04924583435058594
train/explained_variance(價值預測準確度),98304,1767850562.996143,0.36299794912338257
train/explained_variance(價值預測準確度),131072,1767850566.719327,0.4251636862754822
train/explained_variance(價值預測準確度),163840,1767850570.4483514,0.4170353412628174
train/explained_variance(價值預測準確度),196608,1767850574.1534498,0.4101223349571228
train/explained_variance(價值預測準確度),229376,1767850577.8905578,0.42832112312316895
train/explained_variance(價值預測準確度),262144,1767850581.583047,0.36287182569503784
train/explained_variance(價值預測準確度),294912,1767850585.2030509,0.29545408487319946
train/explained_variance(價值預測準確度),327680,1767850588.9230797,0.22443640232086182
train/explained_variance(價值預測準確度),360448,1767850592.6420286,0.19086503982543945
train/explained_variance(價值預測準確度),393216,1767850596.5343516,0.2000664472579956
train/explained_variance(價值預測準確度),425984,1767850600.2572355,0.21063965559005737
train/explained_variance(價值預測準確度),458752,1767850604.004208,0.19462120532989502
train/explained_variance(價值預測準確度),491520,1767850607.7767951,0.21510714292526245
train/explained_variance(價值預測準確度),524288,1767850611.5745854,0.21032583713531494
train/explained_variance(價值預測準確度),557056,1767850615.2046947,0.21336936950683594
train/explained_variance(價值預測準確度),589824,1767850618.933322,0.20280522108078003
train/explained_variance(價值預測準確度),622592,1767850622.619367,0.22801995277404785
train/explained_variance(價值預測準確度),655360,1767850626.3165457,0.25132542848587036
train/explained_variance(價值預測準確度),688128,1767850629.9219232,0.2532569169998169
train/explained_variance(價值預測準確度),720896,1767850633.6161911,0.27877622842788696
train/explained_variance(價值預測準確度),753664,1767850637.1983774,0.30139899253845215
train/explained_variance(價值預測準確度),786432,1767850640.8717477,0.3232472538948059
train/explained_variance(價值預測準確度),819200,1767850644.4654818,0.3374059200286865
train/explained_variance(價值預測準確度),851968,1767850648.1052475,0.3396216630935669
train/explained_variance(價值預測準確度),884736,1767850651.7045784,0.39029788970947266
train/explained_variance(價值預測準確度),917504,1767850655.3435278,0.3872401714324951
train/explained_variance(價值預測準確度),950272,1767850659.0710485,0.4616152048110962
train/explained_variance(價值預測準確度),983040,1767850662.7455473,0.4875808358192444
train/explained_variance(價值預測準確度),1015808,1767850666.481074,0.46877676248550415
train/explained_variance(價值預測準確度),1048576,1767850670.1074698,0.49458783864974976
train/explained_variance(價值預測準確度),1081344,1767850673.8068314,0.48311835527420044
train/explained_variance(價值預測準確度),1114112,1767850677.3988,0.5418635010719299
train/explained_variance(價值預測準確度),1146880,1767850681.0832002,0.5611040592193604
train/explained_variance(價值預測準確度),1179648,1767850684.683882,0.5195165872573853
train/explained_variance(價值預測準確度),1212416,1767850688.3471098,0.5469635725021362
train/explained_variance(價值預測準確度),1245184,1767850692.0412767,0.5813945531845093
train/explained_variance(價值預測準確度),1277952,1767850695.7100718,0.558221697807312
train/explained_variance(價值預測準確度),1310720,1767850699.3796778,0.5966019630432129
train/explained_variance(價值預測準確度),1343488,1767850703.1060586,0.5858774185180664
train/explained_variance(價值預測準確度),1376256,1767850706.7275863,0.6106020212173462
train/explained_variance(價值預測準確度),1409024,1767850710.4058769,0.2925742268562317
train/explained_variance(價值預測準確度),1441792,1767850713.9961836,0.5972451567649841
train/explained_variance(價值預測準確度),1474560,1767850717.6608357,0.6552883386611938
train/explained_variance(價值預測準確度),1507328,1767850721.2686496,0.21533316373825073
train/explained_variance(價值預測準確度),1540096,1767850724.905224,0.6581897735595703
train/explained_variance(價值預測準確度),1572864,1767850728.5152638,0.16118651628494263
train/explained_variance(價值預測準確度),1600000,1767850737.0012846,0.3349975347518921
train/explained_variance(價值預測準確度),1638400,1767850741.4428859,0.24092096090316772
train/explained_variance(價值預測準確度),1671168,1767850745.0722322,0.15156912803649902
train/explained_variance(價值預測準確度),1703936,1767850748.701232,0.24024003744125366
train/explained_variance(價值預測準確度),1736704,1767850752.3870256,0.19629186391830444
train/explained_variance(價值預測準確度),1769472,1767850755.9522567,0.24024683237075806
train/explained_variance(價值預測準確度),1802240,1767850759.612867,0.3418758511543274
train/explained_variance(價值預測準確度),1835008,1767850763.1786482,0.20350617170333862
train/explained_variance(價值預測準確度),1867776,1767850766.815694,0.24256813526153564
train/explained_variance(價值預測準確度),1900544,1767850770.3717258,0.14987492561340332
train/explained_variance(價值預測準確度),1933312,1767850774.0567575,0.19059395790100098
train/explained_variance(價值預測準確度),1966080,1767850777.6604764,0.19185054302215576
train/explained_variance(價值預測準確度),1998848,1767850781.2761362,0.2495923638343811
train/explained_variance(價值預測準確度),2031616,1767850784.883305,0.15970170497894287
train/explained_variance(價值預測準確度),2064384,1767850788.492404,0.20434921979904175
train/explained_variance(價值預測準確度),2097152,1767850792.2032356,0.2673083543777466
train/explained_variance(價值預測準確度),2129920,1767850795.866282,0.2674242854118347
train/explained_variance(價值預測準確度),2162688,1767850799.5272243,0.22032827138900757
train/explained_variance(價值預測準確度),2195456,1767850803.2312806,0.3613411784172058
train/explained_variance(價值預測準確度),2228224,1767850806.8434565,0.22112226486206055
train/explained_variance(價值預測準確度),2260992,1767850810.455892,0.26777154207229614
train/explained_variance(價值預測準確度),2293760,1767850814.0776038,0.19634902477264404
train/explained_variance(價值預測準確度),2326528,1767850817.7324646,0.16316205263137817
train/explained_variance(價值預測準確度),2359296,1767850821.3082688,0.25985997915267944
train/explained_variance(價值預測準確度),2392064,1767850824.9743595,0.20073121786117554
train/explained_variance(價值預測準確度),2424832,1767850828.55592,0.1623671054840088
train/explained_variance(價值預測準確度),2457600,1767850832.2084389,0.17828011512756348
train/explained_variance(價值預測準確度),2490368,1767850835.7887897,0.19408178329467773
train/explained_variance(價值預測準確度),2523136,1767850839.410689,0.2761297821998596
train/explained_variance(價值預測準確度),2555904,1767850842.9688787,0.17958980798721313
train/explained_variance(價值預測準確度),2588672,1767850846.6125402,0.17574542760849
train/explained_variance(價值預測準確度),2621440,1767850850.1919608,0.261838436126709
train/explained_variance(價值預測準確度),2654208,1767850853.8273733,0.22239136695861816
train/explained_variance(價值預測準確度),2686976,1767850857.4195008,0.20516133308410645
train/explained_variance(價值預測準確度),2719744,1767850861.3290613,0.16913801431655884
train/explained_variance(價值預測準確度),2752512,1767850865.0908148,0.18222254514694214
train/explained_variance(價值預測準確度),2785280,1767850869.031745,0.3736867904663086
train/explained_variance(價值預測準確度),2818048,1767850872.8489573,0.1409401297569275
train/explained_variance(價值預測準確度),2850816,1767850876.7107396,0.1369674801826477
train/explained_variance(價值預測準確度),2883584,1767850880.4894252,0.1397320032119751
train/explained_variance(價值預測準確度),2916352,1767850884.3961153,0.1548309326171875
train/explained_variance(價值預測準確度),2949120,1767850888.1782212,0.16743361949920654
train/explained_variance(價值預測準確度),2981888,1767850891.9776053,0.17553335428237915
train/explained_variance(價值預測準確度),3014656,1767850895.7577431,0.14547395706176758
train/explained_variance(價值預測準確度),3047424,1767850899.581668,0.24219554662704468
train/explained_variance(價值預測準確度),3080192,1767850903.3661573,0.1290421485900879
train/explained_variance(價值預測準確度),3112960,1767850907.1832235,0.17207825183868408
train/explained_variance(價值預測準確度),3145728,1767850911.2433429,0.15511232614517212
train/explained_variance(價值預測準確度),3178496,1767850915.1832602,0.131680428981781
train/explained_variance(價值預測準確度),3200000,1767850924.5230672,0.4018336534500122
train/explained_variance(價值預測準確度),3244032,1767850929.708885,0.14385157823562622
train/explained_variance(價值預測準確度),3276800,1767850933.5472097,0.18498849868774414
train/explained_variance(價值預測準確度),3309568,1767850937.467982,0.12199407815933228
train/explained_variance(價值預測準確度),3342336,1767850941.3087542,0.1761842966079712
train/explained_variance(價值預測準確度),3375104,1767850945.2967572,0.1126633882522583
train/explained_variance(價值預測準確度),3407872,1767850949.2090595,0.19919967651367188
train/explained_variance(價值預測準確度),3440640,1767850952.9483771,0.12859171628952026
train/explained_variance(價值預測準確度),3473408,1767850957.3175955,0.15922391414642334
train/explained_variance(價值預測準確度),3506176,1767850961.4267182,0.21256613731384277
train/explained_variance(價值預測準確度),3538944,1767850965.30745,0.11200690269470215
train/explained_variance(價值預測準確度),3571712,1767850969.296191,0.17468494176864624
train/explained_variance(價值預測準確度),3604480,1767850972.9610317,0.15040266513824463
train/explained_variance(價值預測準確度),3637248,1767850976.7373757,0.17566603422164917
train/explained_variance(價值預測準確度),3670016,1767850980.5669193,0.15660732984542847
train/explained_variance(價值預測準確度),3702784,1767850984.6186466,0.11067146062850952
train/explained_variance(價值預測準確度),3735552,1767850988.6584132,0.1609768271446228
train/explained_variance(價值預測準確度),3768320,1767850992.5548205,0.15588241815567017
train/explained_variance(價值預測準確度),3801088,1767850996.5146782,0.21426159143447876
train/explained_variance(價值預測準確度),3833856,1767851000.422122,0.19657981395721436
train/explained_variance(價值預測準確度),3866624,1767851004.6852853,0.1819460391998291
train/explained_variance(價值預測準確度),3899392,1767851008.561874,0.1385403275489807
train/explained_variance(價值預測準確度),3932160,1767851012.599403,0.15427172183990479
train/explained_variance(價值預測準確度),3964928,1767851016.6966462,0.1598418951034546
train/explained_variance(價值預測準確度),3997696,1767851020.5565472,0.10032236576080322
train/explained_variance(價值預測準確度),4030464,1767851024.2745268,0.14000368118286133
train/explained_variance(價值預測準確度),4063232,1767851027.931706,0.23281162977218628
train/explained_variance(價值預測準確度),4096000,1767851031.6902683,0.13595914840698242
train/explained_variance(價值預測準確度),4128768,1767851035.552128,0.1490710973739624
train/explained_variance(價值預測準確度),4161536,1767851039.3616033,0.1737130880355835
train/explained_variance(價值預測準確度),4194304,1767851043.1991954,0.21296316385269165
train/explained_variance(價值預測準確度),4227072,1767851047.1003935,0.3100084662437439
train/explained_variance(價值預測準確度),4259840,1767851050.8482265,0.1358928084373474
train/explained_variance(價值預測準確度),4292608,1767851054.8405092,0.19204288721084595
train/explained_variance(價值預測準確度),4325376,1767851058.8245432,0.15929275751113892
train/explained_variance(價值預測準確度),4358144,1767851062.640887,0.13979440927505493
train/explained_variance(價值預測準確度),4390912,1767851066.511372,0.18485736846923828
train/explained_variance(價值預測準確度),4423680,1767851070.3151045,0.14126187562942505
train/explained_variance(價值預測準確度),4456448,1767851074.1013825,0.19609814882278442
train/explained_variance(價值預測準確度),4489216,1767851077.8736207,0.18372571468353271
train/explained_variance(價值預測準確度),4521984,1767851081.7243874,0.12953680753707886
train/explained_variance(價值預測準確度),4554752,1767851085.5352962,0.13818466663360596
train/explained_variance(價值預測準確度),4587520,1767851089.4027958,0.11772382259368896
train/explained_variance(價值預測準確度),4620288,1767851093.227601,0.20938539505004883
train/explained_variance(價值預測準確度),4653056,1767851097.0151076,0.1411278247833252
train/explained_variance(價值預測準確度),4685824,1767851100.8662007,0.15769529342651367
train/explained_variance(價值預測準確度),4718592,1767851104.6115327,0.11211037635803223
train/explained_variance(價值預測準確度),4751360,1767851108.3256793,0.20351970195770264
train/explained_variance(價值預測準確度),4784128,1767851112.1232119,0.15708237886428833
train/explained_variance(價值預測準確度),4800000,1767851120.069484,0.12218600511550903
train/explained_variance(價值預測準確度),4849664,1767851125.9408178,0.16184061765670776
train/explained_variance(價值預測準確度),4882432,1767851129.6968298,0.21337229013442993
train/explained_variance(價值預測準確度),4915200,1767851133.48323,0.27321869134902954
train/explained_variance(價值預測準確度),4947968,1767851137.2527626,0.2245970368385315
train/explained_variance(價值預測準確度),4980736,1767851141.0984478,0.16316097974777222
train/explained_variance(價值預測準確度),5013504,1767851144.8310637,0.24290955066680908
train/explained_variance(價值預測準確度),5046272,1767851148.5421064,0.1906610131263733
train/explained_variance(價值預測準確度),5079040,1767851152.4145024,0.10226184129714966
train/explained_variance(價值預測準確度),5111808,1767851156.2059376,0.1441267728805542
train/explained_variance(價值預測準確度),5144576,1767851159.8980644,0.21952193975448608
train/explained_variance(價值預測準確度),5177344,1767851163.7191901,0.19147729873657227
train/explained_variance(價值預測準確度),5210112,1767851167.4530969,0.25060153007507324
train/explained_variance(價值預測準確度),5242880,1767851171.206861,0.17013245820999146
train/explained_variance(價值預測準確度),5275648,1767851174.9225078,0.14787381887435913
train/explained_variance(價值預測準確度),5308416,1767851178.7835948,0.1664244532585144
train/explained_variance(價值預測準確度),5341184,1767851182.6305401,0.21398138999938965
train/explained_variance(價值預測準確度),5373952,1767851186.3842208,0.256314218044281
train/explained_variance(價值預測準確度),5406720,1767851190.255159,0.7262694239616394
train/explained_variance(價值預測準確度),5439488,1767851194.0659354,0.18265032768249512
train/explained_variance(價值預測準確度),5472256,1767851197.8260283,0.17609161138534546
train/explained_variance(價值預測準確度),5505024,1767851201.6629026,0.18014073371887207
train/explained_variance(價值預測準確度),5537792,1767851205.4095185,0.17814719676971436
train/explained_variance(價值預測準確度),5570560,1767851209.1647682,0.11996501684188843
train/explained_variance(價值預測準確度),5603328,1767851212.9930987,0.19393259286880493
train/explained_variance(價值預測準確度),5636096,1767851216.7795317,0.2060287594795227
train/explained_variance(價值預測準確度),5668864,1767851220.50399,0.14522075653076172
train/explained_variance(價值預測準確度),5701632,1767851224.3482041,0.17538219690322876
train/explained_variance(價值預測準確度),5734400,1767851228.1825051,0.12568747997283936
train/explained_variance(價值預測準確度),5767168,1767851231.940569,0.17221873998641968
train/explained_variance(價值預測準確度),5799936,1767851235.8235393,0.18596935272216797
train/explained_variance(價值預測準確度),5832704,1767851239.639634,0.15096646547317505
train/explained_variance(價值預測準確度),5865472,1767851243.3867345,0.18263643980026245
train/explained_variance(價值預測準確度),5898240,1767851247.2597299,0.15651828050613403
train/explained_variance(價值預測準確度),5931008,1767851251.0267448,0.20903944969177246
train/explained_variance(價值預測準確度),5963776,1767851254.8078127,0.20710784196853638
train/explained_variance(價值預測準確度),5996544,1767851258.8188546,0.15675193071365356
train/explained_variance(價值預測準確度),6029312,1767851262.7803826,0.27076590061187744
train/explained_variance(價值預測準確度),6062080,1767851266.7045023,0.14183473587036133
train/explained_variance(價值預測準確度),6094848,1767851270.5552242,0.14429587125778198
train/explained_variance(價值預測準確度),6127616,1767851274.4984272,0.163685142993927
train/explained_variance(價值預測準確度),6160384,1767851278.5352979,0.13718795776367188
train/explained_variance(價值預測準確度),6193152,1767851282.497792,0.23567825555801392
train/explained_variance(價值預測準確度),6225920,1767851286.371077,0.14678484201431274
train/explained_variance(價值預測準確度),6258688,1767851290.3003335,0.15902084112167358
train/explained_variance(價值預測準確度),6291456,1767851294.1221151,0.12934601306915283
train/explained_variance(價值預測準確度),6324224,1767851298.0558202,0.17800372838974
train/explained_variance(價值預測準確度),6356992,1767851301.9332805,0.12685626745224
train/explained_variance(價值預測準確度),6389760,1767851305.9020336,0.21381276845932007
train/explained_variance(價值預測準確度),6400000,1767851311.462924,0.2595691680908203
train/explained_variance(價值預測準確度),6455296,1767851318.2926252,0.14236778020858765
train/explained_variance(價值預測準確度),6488064,1767851322.189184,0.16682219505310059
train/explained_variance(價值預測準確度),6520832,1767851326.0816662,0.14819365739822388
train/explained_variance(價值預測準確度),6553600,1767851329.9729526,0.15307366847991943
train/explained_variance(價值預測準確度),6586368,1767851333.914084,0.1588890552520752
train/explained_variance(價值預測準確度),6619136,1767851337.7628021,0.14894819259643555
train/explained_variance(價值預測準確度),6651904,1767851341.701503,0.20312798023223877
train/explained_variance(價值預測準確度),6684672,1767851345.6731632,0.15042203664779663
train/explained_variance(價值預測準確度),6717440,1767851349.560387,0.13816362619400024
train/explained_variance(價值預測準確度),6750208,1767851353.5039809,0.19686555862426758
train/explained_variance(價值預測準確度),6782976,1767851357.4343462,0.18299168348312378
train/explained_variance(價值預測準確度),6815744,1767851361.2815995,0.15874731540679932
train/explained_variance(價值預測準確度),6848512,1767851365.1255405,0.17954576015472412
train/explained_variance(價值預測準確度),6881280,1767851369.1308281,0.21294474601745605
train/explained_variance(價值預測準確度),6914048,1767851373.0831103,0.1583876609802246
train/explained_variance(價值預測準確度),6946816,1767851376.9331527,0.18220090866088867
train/explained_variance(價值預測準確度),6979584,1767851380.8888044,0.1713191270828247
train/explained_variance(價值預測準確度),7012352,1767851384.8043604,0.15860509872436523
train/explained_variance(價值預測準確度),7045120,1767851388.6258478,0.20681744813919067
train/explained_variance(價值預測準確度),7077888,1767851392.4364486,0.14574217796325684
train/explained_variance(價值預測準確度),7110656,1767851396.205339,0.14488303661346436
train/explained_variance(價值預測準確度),7143424,1767851400.0019038,0.1601741909980774
train/explained_variance(價值預測準確度),7176192,1767851403.8091478,0.19889891147613525
train/explained_variance(價值預測準確度),7208960,1767851407.556572,0.13914847373962402
train/explained_variance(價值預測準確度),7241728,1767851411.3092682,0.20529073476791382
train/explained_variance(價值預測準確度),7274496,1767851415.177134,0.13939440250396729
train/explained_variance(價值預測準確度),7307264,1767851418.9848976,0.15114450454711914
train/explained_variance(價值預測準確度),7340032,1767851422.7503793,0.14792734384536743
train/explained_variance(價值預測準確度),7372800,1767851426.6533804,0.14667892456054688
train/explained_variance(價值預測準確度),7405568,1767851430.4099774,0.17590278387069702
train/explained_variance(價值預測準確度),7438336,1767851434.2532735,0.18902450799942017
train/explained_variance(價值預測準確度),7471104,1767851438.0266423,0.19098526239395142
train/explained_variance(價值預測準確度),7503872,1767851441.8613071,0.12581521272659302
train/explained_variance(價值預測準確度),7536640,1767851445.6970434,0.16657006740570068
train/explained_variance(價值預測準確度),7569408,1767851449.6036465,0.1823154091835022
train/explained_variance(價值預測準確度),7602176,1767851453.3829386,0.1390317678451538
train/explained_variance(價值預測準確度),7634944,1767851457.202003,0.1413886547088623
train/explained_variance(價值預測準確度),7667712,1767851461.0313587,0.20376867055892944
train/explained_variance(價值預測準確度),7700480,1767851464.834783,0.17143374681472778
train/explained_variance(價值預測準確度),7733248,1767851468.6625133,0.2364397644996643
train/explained_variance(價值預測準確度),7766016,1767851472.5628033,0.13928252458572388
train/explained_variance(價值預測準確度),7798784,1767851476.44101,0.1870875358581543
train/explained_variance(價值預測準確度),7831552,1767851480.220457,0.16921770572662354
train/explained_variance(價值預測準確度),7864320,1767851484.0781865,0.25813591480255127
train/explained_variance(價值預測準確度),7897088,1767851487.9261947,0.15039581060409546
train/explained_variance(價值預測準確度),7929856,1767851491.717675,0.35292375087738037
train/explained_variance(價值預測準確度),7962624,1767851495.5764532,0.15609246492385864
train/explained_variance(價值預測準確度),7995392,1767851499.3429677,0.31744325160980225
train/explained_variance(價值預測準確度),8000000,1767851506.12033,0.12468641996383667
train/explained_variance(價值預測準確度),8060928,1767851513.3896632,0.19014644622802734
train/explained_variance(價值預測準確度),8093696,1767851517.216103,0.16568928956985474
train/explained_variance(價值預測準確度),8126464,1767851521.0065434,0.14389723539352417
train/explained_variance(價值預測準確度),8159232,1767851524.8318646,0.15174609422683716
train/explained_variance(價值預測準確度),8192000,1767851528.6107416,0.1509777307510376
train/explained_variance(價值預測準確度),8224768,1767851532.4548416,0.21449512243270874
train/explained_variance(價值預測準確度),8257536,1767851536.3604865,0.16610479354858398
train/explained_variance(價值預測準確度),8290304,1767851540.1405644,0.24497193098068237
train/explained_variance(價值預測準確度),8323072,1767851543.9752173,0.14532041549682617
train/explained_variance(價值預測準確度),8355840,1767851547.7974606,0.24417734146118164
train/explained_variance(價值預測準確度),8388608,1767851551.589234,0.18551170825958252
train/explained_variance(價值預測準確度),8421376,1767851555.4249458,0.16799437999725342
train/explained_variance(價值預測準確度),8454144,1767851559.1645546,0.14579403400421143
train/explained_variance(價值預測準確度),8486912,1767851562.9092748,0.15570753812789917
train/explained_variance(價值預測準確度),8519680,1767851566.6495507,0.1748102307319641
train/explained_variance(價值預測準確度),8552448,1767851570.5102527,0.23563385009765625
train/explained_variance(價值預測準確度),8585216,1767851574.3190894,0.22048991918563843
train/explained_variance(價值預測準確度),8617984,1767851578.10446,0.17848294973373413
train/explained_variance(價值預測準確度),8650752,1767851581.9328792,0.198095440864563
train/explained_variance(價值預測準確度),8683520,1767851585.6849768,0.18391907215118408
train/explained_variance(價值預測準確度),8716288,1767851589.452577,0.1827966570854187
train/explained_variance(價值預測準確度),8749056,1767851593.3209686,0.2052851915359497
train/explained_variance(價值預測準確度),8781824,1767851597.117463,0.2509447932243347
train/explained_variance(價值預測準確度),8814592,1767851600.8884895,0.1456502079963684
train/explained_variance(價值預測準確度),8847360,1767851604.7932854,0.35139894485473633
train/explained_variance(價值預測準確度),8880128,1767851608.6254165,0.32096922397613525
train/explained_variance(價值預測準確度),8912896,1767851612.5267959,0.18606168031692505
train/explained_variance(價值預測準確度),8945664,1767851616.3148751,0.16697907447814941
train/explained_variance(價值預測準確度),8978432,1767851620.060589,0.14228838682174683
train/explained_variance(價值預測準確度),9011200,1767851623.9150236,0.2197369933128357
train/explained_variance(價值預測準確度),9043968,1767851627.6861043,0.20439380407333374
train/explained_variance(價值預測準確度),9076736,1767851631.4564013,0.1922277808189392
train/explained_variance(價值預測準確度),9109504,1767851635.3077714,0.19589155912399292
train/explained_variance(價值預測準確度),9142272,1767851639.1065817,0.17517107725143433
train/explained_variance(價值預測準確度),9175040,1767851642.8536239,0.16794294118881226
train/explained_variance(價值預測準確度),9207808,1767851646.7242799,0.14171075820922852
train/explained_variance(價值預測準確度),9240576,1767851650.523385,0.19591695070266724
train/explained_variance(價值預測準確度),9273344,1767851654.3266377,0.20376592874526978
train/explained_variance(價值預測準確度),9306112,1767851658.129918,0.16143345832824707
train/explained_variance(價值預測準確度),9338880,1767851661.9003403,0.18732959032058716
train/explained_variance(價值預測準確度),9371648,1767851665.6797972,0.17688101530075073
train/explained_variance(價值預測準確度),9404416,1767851669.5427177,0.20313990116119385
train/explained_variance(價值預測準確度),9437184,1767851673.3655446,0.19691729545593262
train/explained_variance(價值預測準確度),9469952,1767851677.180017,0.22016245126724243
train/explained_variance(價值預測準確度),9502720,1767851680.9703443,0.2027478814125061
train/explained_variance(價值預測準確度),9535488,1767851684.7552023,0.16108685731887817
train/explained_variance(價值預測準確度),9568256,1767851688.5870562,0.17530423402786255
train/explained_variance(價值預測準確度),9600000,1767851698.600738,0.1377042531967163
train/explained_variance(價值預測準確度),9633792,1767851702.5447552,0.19063538312911987
train/explained_variance(價值預測準確度),9666560,1767851706.3297298,0.14074033498764038
train/explained_variance(價值預測準確度),9699328,1767851710.178134,0.17027997970581055
train/explained_variance(價值預測準確度),9732096,1767851713.9104607,0.20697319507598877
train/explained_variance(價值預測準確度),9764864,1767851717.6755009,0.2270103096961975
train/explained_variance(價值預測準確度),9797632,1767851721.4707024,0.14102894067764282
train/explained_variance(價值預測準確度),9830400,1767851725.2913725,0.21353375911712646
train/explained_variance(價值預測準確度),9863168,1767851729.1073449,0.19330883026123047
train/explained_variance(價值預測準確度),9895936,1767851732.8964748,0.17855346202850342
train/explained_variance(價值預測準確度),9928704,1767851736.723532,0.18808424472808838
train/explained_variance(價值預測準確度),9961472,1767851740.5198991,0.14776575565338135
train/explained_variance(價值預測準確度),9994240,1767851744.2771597,0.26539963483810425
train/explained_variance(價值預測準確度),10027008,1767851748.0839155,0.19073933362960815
train/explained_variance(價值預測準確度),10059776,1767851751.8725479,0.2201138734817505
train/explained_variance(價值預測準確度),10092544,1767851755.6664157,0.1609775424003601
train/explained_variance(價值預測準確度),10125312,1767851759.5029423,0.17858946323394775
train/explained_variance(價值預測準確度),10158080,1767851763.2659757,0.14596796035766602
train/explained_variance(價值預測準確度),10190848,1767851767.0469668,0.2334117293357849
train/explained_variance(價值預測準確度),10223616,1767851770.8760586,0.16457784175872803
train/explained_variance(價值預測準確度),10256384,1767851774.7005332,0.1921299695968628
train/explained_variance(價值預測準確度),10289152,1767851778.5006182,0.16627919673919678
train/explained_variance(價值預測準確度),10321920,1767851782.3109753,0.2822141647338867
train/explained_variance(價值預測準確度),10354688,1767851786.103872,0.20983368158340454
train/explained_variance(價值預測準確度),10387456,1767851789.889282,0.3064765930175781
train/explained_variance(價值預測準確度),10420224,1767851793.661537,0.17748409509658813
train/explained_variance(價值預測準確度),10452992,1767851797.5050159,0.26714181900024414
train/explained_variance(價值預測準確度),10485760,1767851801.2503831,0.1522272825241089
train/explained_variance(價值預測準確度),10518528,1767851805.0712113,0.1743067502975464
train/explained_variance(價值預測準確度),10551296,1767851808.8688548,0.2703828811645508
train/explained_variance(價值預測準確度),10584064,1767851812.6389425,0.2171025276184082
train/explained_variance(價值預測準確度),10616832,1767851816.490222,0.20918583869934082
train/explained_variance(價值預測準確度),10649600,1767851820.25121,0.3905404806137085
train/explained_variance(價值預測準確度),10682368,1767851824.0040731,0.12059396505355835
train/explained_variance(價值預測準確度),10715136,1767851827.861113,0.32091623544692993
train/explained_variance(價值預測準確度),10747904,1767851831.6708193,0.15184879302978516
train/explained_variance(價值預測準確度),10780672,1767851835.4792118,0.18608754873275757
train/explained_variance(價值預測準確度),10813440,1767851839.280336,0.21680647134780884
train/explained_variance(價值預測準確度),10846208,1767851843.065974,0.187594473361969
train/explained_variance(價值預測準確度),10878976,1767851846.8648553,0.16316008567810059
train/explained_variance(價值預測準確度),10911744,1767851850.6482563,0.16793584823608398
train/explained_variance(價值預測準確度),10944512,1767851854.4339461,0.18667709827423096
train/explained_variance(價值預測準確度),10977280,1767851858.2310927,0.20178484916687012
train/explained_variance(價值預測準確度),11010048,1767851862.1134384,0.19071674346923828
train/explained_variance(價值預測準確度),11042816,1767851865.956484,0.17536020278930664
train/explained_variance(價值預測準確度),11075584,1767851869.897537,0.19964927434921265
train/explained_variance(價值預測準確度),11108352,1767851873.7397423,0.22587525844573975
train/explained_variance(價值預測準確度),11141120,1767851877.6540227,0.26895248889923096
train/explained_variance(價值預測準確度),11173888,1767851881.5055263,0.1861160397529602
train/explained_variance(價值預測準確度),11200000,1767851890.859954,0.19275707006454468
train/explained_variance(價值預測準確度),11239424,1767851895.6584544,0.45799094438552856
train/explained_variance(價值預測準確度),11272192,1767851899.437363,0.18458998203277588
train/explained_variance(價值預測準確度),11304960,1767851903.2367744,0.17621290683746338
train/explained_variance(價值預測準確度),11337728,1767851907.0456638,0.17487382888793945
train/explained_variance(價值預測準確度),11370496,1767851910.8145862,0.2185901403427124
train/explained_variance(價值預測準確度),11403264,1767851914.5965257,0.2048712968826294
train/explained_variance(價值預測準確度),11436032,1767851918.434133,0.21268218755722046
train/explained_variance(價值預測準確度),11468800,1767851922.2353313,0.19455569982528687
train/explained_variance(價值預測準確度),11501568,1767851926.0057366,0.376828134059906
train/explained_variance(價值預測準確度),11534336,1767851929.8337362,0.4739822745323181
train/explained_variance(價值預測準確度),11567104,1767851933.6304746,0.177512526512146
train/explained_variance(價值預測準確度),11599872,1767851937.4094367,0.17004358768463135
train/explained_variance(價值預測準確度),11632640,1767851941.2539635,0.1903037428855896
train/explained_variance(價值預測準確度),11665408,1767851945.0449657,0.4439379572868347
train/explained_variance(價值預測準確度),11698176,1767851948.827807,0.22721117734909058
train/explained_variance(價值預測準確度),11730944,1767851952.675069,0.3188086152076721
train/explained_variance(價值預測準確度),11763712,1767851956.4674273,0.25354158878326416
train/explained_variance(價值預測準確度),11796480,1767851960.358683,0.19208717346191406
train/explained_variance(價值預測準確度),11829248,1767851964.2478104,0.17463606595993042
train/explained_variance(價值預測準確度),11862016,1767851968.0738328,0.29067206382751465
train/explained_variance(價值預測準確度),11894784,1767851971.9493694,0.1648416519165039
train/explained_variance(價值預測準確度),11927552,1767851975.8429923,0.5069993734359741
train/explained_variance(價值預測準確度),11960320,1767851979.655874,0.23375725746154785
train/explained_variance(價值預測準確度),11993088,1767851983.4819186,0.2961685061454773
train/explained_variance(價值預測準確度),12025856,1767851987.3343585,0.20258718729019165
train/explained_variance(價值預測準確度),12058624,1767851991.2070632,0.20234894752502441
train/explained_variance(價值預測準確度),12091392,1767851995.0093503,0.32061952352523804
train/explained_variance(價值預測準確度),12124160,1767851998.8575733,0.3521614074707031
train/explained_variance(價值預測準確度),12156928,1767852002.723118,0.18670541048049927
train/explained_variance(價值預測準確度),12189696,1767852006.6192544,0.2192860245704651
train/explained_variance(價值預測準確度),12222464,1767852010.4443982,0.19515293836593628
train/explained_variance(價值預測準確度),12255232,1767852014.2415743,0.2084285020828247
train/explained_variance(價值預測準確度),12288000,1767852018.0783741,0.21102792024612427
train/explained_variance(價值預測準確度),12320768,1767852021.9408715,0.3776278495788574
train/explained_variance(價值預測準確度),12353536,1767852025.8486497,0.20198386907577515
train/explained_variance(價值預測準確度),12386304,1767852029.716671,0.1929948329925537
train/explained_variance(價值預測準確度),12419072,1767852033.6132348,0.28133970499038696
train/explained_variance(價值預測準確度),12451840,1767852037.411729,0.21395641565322876
train/explained_variance(價值預測準確度),12484608,1767852041.2448833,0.21241694688796997
train/explained_variance(價值預測準確度),12517376,1767852045.0343423,0.17177659273147583
train/explained_variance(價值預測準確度),12550144,1767852048.8760827,0.25538432598114014
train/explained_variance(價值預測準確度),12582912,1767852052.7375727,0.310263454914093
train/explained_variance(價值預測準確度),12615680,1767852056.60109,0.37052929401397705
train/explained_variance(價值預測準確度),12648448,1767852060.4723964,0.2124420404434204
train/explained_variance(價值預測準確度),12681216,1767852064.3369222,0.23550426959991455
train/explained_variance(價值預測準確度),12713984,1767852068.303477,0.2412537932395935
train/explained_variance(價值預測準確度),12746752,1767852072.1466877,0.32258373498916626
train/explained_variance(價值預測準確度),12779520,1767852076.0867941,0.2733454704284668
train/explained_variance(價值預測準確度),12800000,1767852083.843321,0.24608302116394043
train/explained_variance(價值預測準確度),12845056,1767852089.3506994,0.31551486253738403
train/explained_variance(價值預測準確度),12877824,1767852093.240537,0.3866117000579834
train/explained_variance(價值預測準確度),12910592,1767852097.047181,0.20554578304290771
train/explained_variance(價值預測準確度),12943360,1767852100.8524952,0.24296385049819946
train/explained_variance(價值預測準確度),12976128,1767852104.6656787,0.20860552787780762
train/explained_variance(價值預測準確度),13008896,1767852108.5615203,0.2815495729446411
train/explained_variance(價值預測準確度),13041664,1767852112.3818095,0.25838327407836914
train/explained_variance(價值預測準確度),13074432,1767852116.144301,0.7909858822822571
train/explained_variance(價值預測準確度),13107200,1767852119.9847195,0.1955547332763672
train/explained_variance(價值預測準確度),13139968,1767852123.7673254,0.45873451232910156
train/explained_variance(價值預測準確度),13172736,1767852127.555611,0.19190609455108643
train/explained_variance(價值預測準確度),13205504,1767852131.4294608,0.2523568272590637
train/explained_variance(價值預測準確度),13238272,1767852135.2610745,0.17744308710098267
train/explained_variance(價值預測準確度),13271040,1767852139.1296704,0.3227408528327942
train/explained_variance(價值預測準確度),13303808,1767852142.939284,0.15766119956970215
train/explained_variance(價值預測準確度),13336576,1767852146.6933453,0.22103548049926758
train/explained_variance(價值預測準確度),13369344,1767852150.5655675,0.17947429418563843
train/explained_variance(價值預測準確度),13402112,1767852154.337042,0.19534331560134888
train/explained_variance(價值預測準確度),13434880,1767852158.1100445,0.1964477300643921
train/explained_variance(價值預測準確度),13467648,1767852161.9528158,0.22366762161254883
train/explained_variance(價值預測準確度),13500416,1767852165.7732508,0.25231122970581055
train/explained_variance(價值預測準確度),13533184,1767852169.5396895,0.1702589988708496
train/explained_variance(價值預測準確度),13565952,1767852173.3529642,0.18686366081237793
train/explained_variance(價值預測準確度),13598720,1767852177.1586583,0.19509679079055786
train/explained_variance(價值預測準確度),13631488,1767852180.9323645,0.18668174743652344
train/explained_variance(價值預測準確度),13664256,1767852184.7686446,0.2029067873954773
train/explained_variance(價值預測準確度),13697024,1767852188.5371807,0.1920059323310852
train/explained_variance(價值預測準確度),13729792,1767852192.3260584,0.18690097332000732
train/explained_variance(價值預測準確度),13762560,1767852196.1565945,0.16490507125854492
train/explained_variance(價值預測準確度),13795328,1767852199.9392993,0.2598400115966797
train/explained_variance(價值預測準確度),13828096,1767852203.7457683,0.188798725605011
train/explained_variance(價值預測準確度),13860864,1767852207.5603771,0.22779065370559692
train/explained_variance(價值預測準確度),13893632,1767852211.3222716,0.21515631675720215
train/explained_variance(價值預測準確度),13926400,1767852215.117207,0.2194482684135437
train/explained_variance(價值預測準確度),13959168,1767852218.9593084,0.2182103395462036
train/explained_variance(價值預測準確度),13991936,1767852222.7497587,0.2707985043525696
train/explained_variance(價值預測準確度),14024704,1767852226.5376217,0.22243589162826538
train/explained_variance(價值預測準確度),14057472,1767852230.341306,0.25911945104599
train/explained_variance(價值預測準確度),14090240,1767852234.1532724,0.24214613437652588
train/explained_variance(價值預測準確度),14123008,1767852237.9555166,0.16091883182525635
train/explained_variance(價值預測準確度),14155776,1767852241.7709186,0.24975496530532837
train/explained_variance(價值預測準確度),14188544,1767852245.580831,0.2990504503250122
train/explained_variance(價值預測準確度),14221312,1767852249.4112377,0.17536044120788574
train/explained_variance(價值預測準確度),14254080,1767852253.1772535,0.1867484450340271
train/explained_variance(價值預測準確度),14286848,1767852256.9677918,0.20105695724487305
train/explained_variance(價值預測準確度),14319616,1767852260.8131015,0.23780757188796997
train/explained_variance(價值預測準確度),14352384,1767852264.6120255,0.18623971939086914
train/explained_variance(價值預測準確度),14385152,1767852268.473499,0.32311421632766724
train/explained_variance(價值預測準確度),14400000,1767852276.521322,0.15973514318466187
train/explained_variance(價值預測準確度),14450688,1767852282.5740464,0.18277204036712646
train/explained_variance(價值預測準確度),14483456,1767852286.3921025,0.21134573221206665
train/explained_variance(價值預測準確度),14516224,1767852290.2720983,0.22759318351745605
train/explained_variance(價值預測準確度),14548992,1767852294.1244688,0.21909677982330322
train/explained_variance(價值預測準確度),14581760,1767852297.9144642,0.1688089370727539
train/explained_variance(價值預測準確度),14614528,1767852301.7823184,0.24940431118011475
train/explained_variance(價值預測準確度),14647296,1767852305.590244,0.2466256022453308
train/explained_variance(價值預測準確度),14680064,1767852309.4423165,0.23885107040405273
train/explained_variance(價值預測準確度),14712832,1767852313.3254573,0.25069892406463623
train/explained_variance(價值預測準確度),14745600,1767852317.128722,0.2138163447380066
train/explained_variance(價值預測準確度),14778368,1767852320.9527233,0.249181866645813
train/explained_variance(價值預測準確度),14811136,1767852324.7873342,0.16098392009735107
train/explained_variance(價值預測準確度),14843904,1767852328.6576471,0.26443201303482056
train/explained_variance(價值預測準確度),14876672,1767852332.5206673,0.21917647123336792
train/explained_variance(價值預測準確度),14909440,1767852336.2900808,0.2102007269859314
train/explained_variance(價值預測準確度),14942208,1767852340.1513834,0.1486663818359375
train/explained_variance(價值預測準確度),14974976,1767852343.9663556,0.21730053424835205
train/explained_variance(價值預測準確度),15007744,1767852347.8196182,0.22420692443847656
train/learning_rate(學習率),65536,1767850559.228526,0.00019967231492046267
train/learning_rate(學習率),98304,1767850562.9971344,0.0001993446348933503
train/learning_rate(學習率),131072,1767850566.719327,0.00019901695486623794
train/learning_rate(學習率),163840,1767850570.4483514,0.00019868927483912557
train/learning_rate(學習率),196608,1767850574.1534498,0.0001983615948120132
train/learning_rate(學習率),229376,1767850577.8905578,0.00019803391478490084
train/learning_rate(學習率),262144,1767850581.583047,0.00019770623475778848
train/learning_rate(學習率),294912,1767850585.2030509,0.00019737855473067611
train/learning_rate(學習率),327680,1767850588.9230797,0.00019705087470356375
train/learning_rate(學習率),360448,1767850592.6420286,0.00019672319467645139
train/learning_rate(學習率),393216,1767850596.5343516,0.00019639551464933902
train/learning_rate(學習率),425984,1767850600.2572355,0.00019606783462222666
train/learning_rate(學習率),458752,1767850604.004208,0.0001957401545951143
train/learning_rate(學習率),491520,1767850607.7767951,0.00019541247456800193
train/learning_rate(學習率),524288,1767850611.5745854,0.00019508479454088956
train/learning_rate(學習率),557056,1767850615.2046947,0.0001947571145137772
train/learning_rate(學習率),589824,1767850618.933322,0.00019442943448666483
train/learning_rate(學習率),622592,1767850622.619367,0.00019410175445955247
train/learning_rate(學習率),655360,1767850626.3165457,0.0001937740744324401
train/learning_rate(學習率),688128,1767850629.9219232,0.00019344639440532774
train/learning_rate(學習率),720896,1767850633.6161911,0.00019311871437821537
train/learning_rate(學習率),753664,1767850637.1993759,0.000192791034351103
train/learning_rate(學習率),786432,1767850640.8717477,0.00019246335432399064
train/learning_rate(學習率),819200,1767850644.4654818,0.00019213567429687828
train/learning_rate(學習率),851968,1767850648.1052475,0.0001918079942697659
train/learning_rate(學習率),884736,1767850651.7045784,0.00019148031424265355
train/learning_rate(學習率),917504,1767850655.3435278,0.00019115263421554118
train/learning_rate(學習率),950272,1767850659.0710485,0.00019082495418842882
train/learning_rate(學習率),983040,1767850662.7455473,0.00019049727416131645
train/learning_rate(學習率),1015808,1767850666.481074,0.0001901695941342041
train/learning_rate(學習率),1048576,1767850670.1074698,0.00018984191410709172
train/learning_rate(學習率),1081344,1767850673.8068314,0.00018951423407997936
train/learning_rate(學習率),1114112,1767850677.3988,0.000189186554052867
train/learning_rate(學習率),1146880,1767850681.0832002,0.00018885887402575463
train/learning_rate(學習率),1179648,1767850684.6848807,0.00018853119399864227
train/learning_rate(學習率),1212416,1767850688.3471098,0.0001882035139715299
train/learning_rate(學習率),1245184,1767850692.0412767,0.00018787583394441754
train/learning_rate(學習率),1277952,1767850695.7100718,0.00018754815391730517
train/learning_rate(學習率),1310720,1767850699.3796778,0.0001872204738901928
train/learning_rate(學習率),1343488,1767850703.1060586,0.00018689279386308044
train/learning_rate(學習率),1376256,1767850706.7275863,0.00018656511383596808
train/learning_rate(學習率),1409024,1767850710.4058769,0.0001862374338088557
train/learning_rate(學習率),1441792,1767850713.9961836,0.00018590975378174335
train/learning_rate(學習率),1474560,1767850717.6608357,0.00018558207375463098
train/learning_rate(學習率),1507328,1767850721.2696497,0.00018525439372751862
train/learning_rate(學習率),1540096,1767850724.905224,0.00018492671370040625
train/learning_rate(學習率),1572864,1767850728.5152638,0.0001845990336732939
train/learning_rate(學習率),1600000,1767850737.0012846,0.00018427135364618152
train/learning_rate(學習率),1638400,1767850741.4428859,0.00018394367361906916
train/learning_rate(學習率),1671168,1767850745.0722322,0.0001836159935919568
train/learning_rate(學習率),1703936,1767850748.701232,0.00018328831356484443
train/learning_rate(學習率),1736704,1767850752.3870256,0.00018296063353773206
train/learning_rate(學習率),1769472,1767850755.9522567,0.0001826329535106197
train/learning_rate(學習率),1802240,1767850759.612867,0.00018230527348350734
train/learning_rate(學習率),1835008,1767850763.1786482,0.00018197759345639497
train/learning_rate(學習率),1867776,1767850766.815694,0.0001816499134292826
train/learning_rate(學習率),1900544,1767850770.3717258,0.00018132223340217024
train/learning_rate(學習率),1933312,1767850774.0567575,0.00018099455337505788
train/learning_rate(學習率),1966080,1767850777.6604764,0.0001806668733479455
train/learning_rate(學習率),1998848,1767850781.2771404,0.00018033919332083315
train/learning_rate(學習率),2031616,1767850784.884306,0.00018001151329372078
train/learning_rate(學習率),2064384,1767850788.493375,0.00017968383326660842
train/learning_rate(學習率),2097152,1767850792.2032356,0.00017935615323949605
train/learning_rate(學習率),2129920,1767850795.866282,0.0001790284732123837
train/learning_rate(學習率),2162688,1767850799.5272243,0.00017870079318527132
train/learning_rate(學習率),2195456,1767850803.2312806,0.00017837311315815896
train/learning_rate(學習率),2228224,1767850806.8434565,0.0001780454331310466
train/learning_rate(學習率),2260992,1767850810.4568942,0.00017771775310393423
train/learning_rate(學習率),2293760,1767850814.0776038,0.00017739007307682186
train/learning_rate(學習率),2326528,1767850817.7324646,0.0001770623930497095
train/learning_rate(學習率),2359296,1767850821.3082688,0.00017673471302259713
train/learning_rate(學習率),2392064,1767850824.9743595,0.00017640703299548477
train/learning_rate(學習率),2424832,1767850828.55592,0.0001760793529683724
train/learning_rate(學習率),2457600,1767850832.2089677,0.00017575167294126004
train/learning_rate(學習率),2490368,1767850835.7887897,0.00017542399291414768
train/learning_rate(學習率),2523136,1767850839.410689,0.0001750963128870353
train/learning_rate(學習率),2555904,1767850842.9688787,0.00017476863285992295
train/learning_rate(學習率),2588672,1767850846.6125402,0.00017444095283281058
train/learning_rate(學習率),2621440,1767850850.1919608,0.00017411327280569822
train/learning_rate(學習率),2654208,1767850853.8273733,0.00017378559277858585
train/learning_rate(學習率),2686976,1767850857.4195008,0.00017345791275147349
train/learning_rate(學習率),2719744,1767850861.3290613,0.00017313023272436112
train/learning_rate(學習率),2752512,1767850865.0908148,0.00017280256724916399
train/learning_rate(學習率),2785280,1767850869.031745,0.00017247488722205162
train/learning_rate(學習率),2818048,1767850872.8499599,0.00017214720719493926
train/learning_rate(學習率),2850816,1767850876.7107396,0.0001718195271678269
train/learning_rate(學習率),2883584,1767850880.4894252,0.00017149184714071453
train/learning_rate(學習率),2916352,1767850884.3961153,0.00017116416711360216
train/learning_rate(學習率),2949120,1767850888.1782212,0.0001708364870864898
train/learning_rate(學習率),2981888,1767850891.9776053,0.00017050880705937743
train/learning_rate(學習率),3014656,1767850895.7577431,0.00017018112703226507
train/learning_rate(學習率),3047424,1767850899.581668,0.0001698534470051527
train/learning_rate(學習率),3080192,1767850903.3661573,0.00016952576697804034
train/learning_rate(學習率),3112960,1767850907.1832235,0.00016919808695092797
train/learning_rate(學習率),3145728,1767850911.2433429,0.0001688704069238156
train/learning_rate(學習率),3178496,1767850915.1832602,0.00016854272689670324
train/learning_rate(學習率),3200000,1767850924.5230672,0.00016821504686959088
train/learning_rate(學習率),3244032,1767850929.708885,0.00016788736684247851
train/learning_rate(學習率),3276800,1767850933.5472097,0.00016755968681536615
train/learning_rate(學習率),3309568,1767850937.467982,0.00016723200678825378
train/learning_rate(學習率),3342336,1767850941.3087542,0.00016690432676114142
train/learning_rate(學習率),3375104,1767850945.2967665,0.00016657664673402905
train/learning_rate(學習率),3407872,1767850949.2090595,0.0001662489667069167
train/learning_rate(學習率),3440640,1767850952.9483771,0.00016592128667980433
train/learning_rate(學習率),3473408,1767850957.3175955,0.00016559360665269196
train/learning_rate(學習率),3506176,1767850961.4267182,0.0001652659266255796
train/learning_rate(學習率),3538944,1767850965.3084548,0.00016493824659846723
train/learning_rate(學習率),3571712,1767850969.296191,0.00016461056657135487
train/learning_rate(學習率),3604480,1767850972.9610317,0.0001642828865442425
train/learning_rate(學習率),3637248,1767850976.7373757,0.00016395520651713014
train/learning_rate(學習率),3670016,1767850980.5679212,0.00016362752649001777
train/learning_rate(學習率),3702784,1767850984.6186466,0.0001632998464629054
train/learning_rate(學習率),3735552,1767850988.6584132,0.00016297216643579304
train/learning_rate(學習率),3768320,1767850992.5548205,0.00016264448640868068
train/learning_rate(學習率),3801088,1767850996.5146782,0.0001623168063815683
train/learning_rate(學習率),3833856,1767851000.422122,0.00016198912635445595
train/learning_rate(學習率),3866624,1767851004.6852853,0.00016166144632734358
train/learning_rate(學習率),3899392,1767851008.561874,0.00016133376630023122
train/learning_rate(學習率),3932160,1767851012.599403,0.00016100608627311885
train/learning_rate(學習率),3964928,1767851016.6966462,0.0001606784062460065
train/learning_rate(學習率),3997696,1767851020.5565472,0.00016035072621889412
train/learning_rate(學習率),4030464,1767851024.2745268,0.00016002304619178176
train/learning_rate(學習率),4063232,1767851027.931706,0.0001596953661646694
train/learning_rate(學習率),4096000,1767851031.6902683,0.00015936768613755703
train/learning_rate(學習率),4128768,1767851035.552128,0.00015904000611044466
train/learning_rate(學習率),4161536,1767851039.362606,0.0001587123260833323
train/learning_rate(學習率),4194304,1767851043.1991954,0.00015838464605621994
train/learning_rate(學習率),4227072,1767851047.1003935,0.00015805696602910757
train/learning_rate(學習率),4259840,1767851050.8482265,0.0001577292860019952
train/learning_rate(學習率),4292608,1767851054.8405092,0.00015740160597488284
train/learning_rate(學習率),4325376,1767851058.8245432,0.00015707392594777048
train/learning_rate(學習率),4358144,1767851062.640887,0.0001567462459206581
train/learning_rate(學習率),4390912,1767851066.511372,0.00015641856589354575
train/learning_rate(學習率),4423680,1767851070.3151045,0.00015609088586643338
train/learning_rate(學習率),4456448,1767851074.1013825,0.00015576320583932102
train/learning_rate(學習率),4489216,1767851077.8736207,0.00015543552581220865
train/learning_rate(學習率),4521984,1767851081.7243874,0.0001551078457850963
train/learning_rate(學習率),4554752,1767851085.5352962,0.00015478016575798392
train/learning_rate(學習率),4587520,1767851089.4037945,0.00015445248573087156
train/learning_rate(學習率),4620288,1767851093.227601,0.0001541248057037592
train/learning_rate(學習率),4653056,1767851097.0151076,0.00015379712567664683
train/learning_rate(學習率),4685824,1767851100.8662007,0.00015346944564953446
train/learning_rate(學習率),4718592,1767851104.6115327,0.0001531417656224221
train/learning_rate(學習率),4751360,1767851108.3256793,0.00015281408559530973
train/learning_rate(學習率),4784128,1767851112.1232119,0.00015248640556819737
train/learning_rate(學習率),4800000,1767851120.069484,0.000152158725541085
train/learning_rate(學習率),4849664,1767851125.9408178,0.00015183104551397264
train/learning_rate(學習率),4882432,1767851129.6968298,0.00015150336548686028
train/learning_rate(學習率),4915200,1767851133.48323,0.0001511756854597479
train/learning_rate(學習率),4947968,1767851137.2527626,0.00015084800543263555
train/learning_rate(學習率),4980736,1767851141.0994492,0.00015052032540552318
train/learning_rate(學習率),5013504,1767851144.8310637,0.00015019264537841082
train/learning_rate(學習率),5046272,1767851148.5421064,0.00014986496535129845
train/learning_rate(學習率),5079040,1767851152.4145024,0.0001495372853241861
train/learning_rate(學習率),5111808,1767851156.2059376,0.00014920960529707372
train/learning_rate(學習率),5144576,1767851159.8980644,0.00014888192526996136
train/learning_rate(學習率),5177344,1767851163.7191901,0.000148554245242849
train/learning_rate(學習率),5210112,1767851167.4530969,0.00014822656521573663
train/learning_rate(學習率),5242880,1767851171.206861,0.00014789888518862426
train/learning_rate(學習率),5275648,1767851174.9225078,0.0001475712051615119
train/learning_rate(學習率),5308416,1767851178.7835948,0.00014724352513439953
train/learning_rate(學習率),5341184,1767851182.6305401,0.00014691584510728717
train/learning_rate(學習率),5373952,1767851186.3842208,0.0001465881650801748
train/learning_rate(學習率),5406720,1767851190.256159,0.00014626048505306244
train/learning_rate(學習率),5439488,1767851194.0659354,0.00014593280502595007
train/learning_rate(學習率),5472256,1767851197.8260283,0.0001456051249988377
train/learning_rate(學習率),5505024,1767851201.6639018,0.00014527744497172534
train/learning_rate(學習率),5537792,1767851205.4095185,0.00014494976494461298
train/learning_rate(學習率),5570560,1767851209.1647682,0.00014462208491750062
train/learning_rate(學習率),5603328,1767851212.9930987,0.00014429440489038825
train/learning_rate(學習率),5636096,1767851216.780533,0.00014396672486327589
train/learning_rate(學習率),5668864,1767851220.50399,0.00014363904483616352
train/learning_rate(學習率),5701632,1767851224.3482041,0.00014331136480905116
train/learning_rate(學習率),5734400,1767851228.1825051,0.0001429836847819388
train/learning_rate(學習率),5767168,1767851231.9415665,0.00014265600475482643
train/learning_rate(學習率),5799936,1767851235.8235393,0.00014232832472771406
train/learning_rate(學習率),5832704,1767851239.639634,0.0001420006447006017
train/learning_rate(學習率),5865472,1767851243.3867345,0.00014167296467348933
train/learning_rate(學習率),5898240,1767851247.2597299,0.00014134528464637697
train/learning_rate(學習率),5931008,1767851251.027742,0.0001410176046192646
train/learning_rate(學習率),5963776,1767851254.8078127,0.00014068992459215224
train/learning_rate(學習率),5996544,1767851258.8188546,0.00014036224456503987
train/learning_rate(學習率),6029312,1767851262.7803826,0.0001400345645379275
train/learning_rate(學習率),6062080,1767851266.7045023,0.00013970688451081514
train/learning_rate(學習率),6094848,1767851270.5552242,0.00013937920448370278
train/learning_rate(學習率),6127616,1767851274.4984272,0.00013905152445659041
train/learning_rate(學習率),6160384,1767851278.5352979,0.00013872384442947805
train/learning_rate(學習率),6193152,1767851282.497792,0.00013839616440236568
train/learning_rate(學習率),6225920,1767851286.371077,0.00013806848437525332
train/learning_rate(學習率),6258688,1767851290.3003335,0.00013774080434814095
train/learning_rate(學習率),6291456,1767851294.1221151,0.0001374131243210286
train/learning_rate(學習率),6324224,1767851298.0558202,0.00013708544429391623
train/learning_rate(學習率),6356992,1767851301.9332805,0.00013675776426680386
train/learning_rate(學習率),6389760,1767851305.9020336,0.0001364300842396915
train/learning_rate(學習率),6400000,1767851311.462924,0.00013610240421257913
train/learning_rate(學習率),6455296,1767851318.2926252,0.00013577472418546677
train/learning_rate(學習率),6488064,1767851322.189184,0.0001354470441583544
train/learning_rate(學習率),6520832,1767851326.0816662,0.00013511936413124204
train/learning_rate(學習率),6553600,1767851329.9729526,0.00013479168410412967
train/learning_rate(學習率),6586368,1767851333.914084,0.0001344640040770173
train/learning_rate(學習率),6619136,1767851337.7628021,0.00013413632404990494
train/learning_rate(學習率),6651904,1767851341.701503,0.00013380864402279258
train/learning_rate(學習率),6684672,1767851345.6731632,0.0001334809639956802
train/learning_rate(學習率),6717440,1767851349.560387,0.00013315328396856785
train/learning_rate(學習率),6750208,1767851353.5039809,0.00013282560394145548
train/learning_rate(學習率),6782976,1767851357.4343462,0.00013249792391434312
train/learning_rate(學習率),6815744,1767851361.2815995,0.00013217024388723075
train/learning_rate(學習率),6848512,1767851365.1255405,0.0001318425638601184
train/learning_rate(學習率),6881280,1767851369.1308281,0.00013151488383300602
train/learning_rate(學習率),6914048,1767851373.0831103,0.00013118720380589366
train/learning_rate(學習率),6946816,1767851376.9331527,0.0001308595237787813
train/learning_rate(學習率),6979584,1767851380.8888044,0.00013053184375166893
train/learning_rate(學習率),7012352,1767851384.8043604,0.00013020416372455657
train/learning_rate(學習率),7045120,1767851388.6258478,0.0001298764836974442
train/learning_rate(學習率),7077888,1767851392.4364486,0.00012954880367033184
train/learning_rate(學習率),7110656,1767851396.205339,0.00012922112364321947
train/learning_rate(學習率),7143424,1767851400.0019038,0.0001288934436161071
train/learning_rate(學習率),7176192,1767851403.8091478,0.00012856576358899474
train/learning_rate(學習率),7208960,1767851407.556572,0.00012823808356188238
train/learning_rate(學習率),7241728,1767851411.3092682,0.00012791040353477
train/learning_rate(學習率),7274496,1767851415.177134,0.00012758272350765765
train/learning_rate(學習率),7307264,1767851418.9848976,0.00012725504348054528
train/learning_rate(學習率),7340032,1767851422.7513814,0.00012692736345343292
train/learning_rate(學習率),7372800,1767851426.6533804,0.00012659968342632055
train/learning_rate(學習率),7405568,1767851430.4099774,0.0001262720033992082
train/learning_rate(學習率),7438336,1767851434.2532735,0.00012594432337209582
train/learning_rate(學習率),7471104,1767851438.0266423,0.00012561664334498346
train/learning_rate(學習率),7503872,1767851441.8613071,0.0001252889633178711
train/learning_rate(學習率),7536640,1767851445.6970434,0.00012496128329075873
train/learning_rate(學習率),7569408,1767851449.6036465,0.00012463360326364636
train/learning_rate(學習率),7602176,1767851453.3829386,0.000124305923236534
train/learning_rate(學習率),7634944,1767851457.202003,0.00012397824320942163
train/learning_rate(學習率),7667712,1767851461.0313587,0.00012365056318230927
train/learning_rate(學習率),7700480,1767851464.834783,0.0001233228831551969
train/learning_rate(學習率),7733248,1767851468.6625133,0.00012299520312808454
train/learning_rate(學習率),7766016,1767851472.5628033,0.00012266752310097218
train/learning_rate(學習率),7798784,1767851476.44101,0.0001223398430738598
train/learning_rate(學習率),7831552,1767851480.220457,0.00012201216304674745
train/learning_rate(學習率),7864320,1767851484.0791864,0.00012168448301963508
train/learning_rate(學習率),7897088,1767851487.9261947,0.00012135680299252272
train/learning_rate(學習率),7929856,1767851491.717675,0.00012102912296541035
train/learning_rate(學習率),7962624,1767851495.5764532,0.00012070144293829799
train/learning_rate(學習率),7995392,1767851499.3429677,0.00012037376291118562
train/learning_rate(學習率),8000000,1767851506.12033,0.00012004608288407326
train/learning_rate(學習率),8060928,1767851513.3896632,0.00011971840285696089
train/learning_rate(學習率),8093696,1767851517.216103,0.00011939072282984853
train/learning_rate(學習率),8126464,1767851521.0065434,0.00011906304280273616
train/learning_rate(學習率),8159232,1767851524.8328652,0.0001187353627756238
train/learning_rate(學習率),8192000,1767851528.6107416,0.00011840768274851143
train/learning_rate(學習率),8224768,1767851532.4548416,0.00011808000272139907
train/learning_rate(學習率),8257536,1767851536.3604865,0.0001177523226942867
train/learning_rate(學習率),8290304,1767851540.1405644,0.00011742464266717434
train/learning_rate(學習率),8323072,1767851543.9752173,0.00011709696264006197
train/learning_rate(學習率),8355840,1767851547.7974606,0.00011676928261294961
train/learning_rate(學習率),8388608,1767851551.589234,0.00011644160258583724
train/learning_rate(學習率),8421376,1767851555.4249458,0.00011611392255872488
train/learning_rate(學習率),8454144,1767851559.1645546,0.00011578624253161252
train/learning_rate(學習率),8486912,1767851562.9092748,0.00011545856250450015
train/learning_rate(學習率),8519680,1767851566.6495507,0.00011513088247738779
train/learning_rate(學習率),8552448,1767851570.5102527,0.00011480320245027542
train/learning_rate(學習率),8585216,1767851574.3190894,0.00011447552242316306
train/learning_rate(學習率),8617984,1767851578.10446,0.00011414784239605069
train/learning_rate(學習率),8650752,1767851581.9328792,0.00011382016236893833
train/learning_rate(學習率),8683520,1767851585.6849768,0.00011349248234182596
train/learning_rate(學習率),8716288,1767851589.452577,0.0001131648023147136
train/learning_rate(學習率),8749056,1767851593.3209686,0.00011283712228760123
train/learning_rate(學習率),8781824,1767851597.117463,0.00011250944226048887
train/learning_rate(學習率),8814592,1767851600.8884895,0.0001121817622333765
train/learning_rate(學習率),8847360,1767851604.7932854,0.00011185408220626414
train/learning_rate(學習率),8880128,1767851608.6254165,0.00011152640217915177
train/learning_rate(學習率),8912896,1767851612.5267959,0.00011119872215203941
train/learning_rate(學習率),8945664,1767851616.3148751,0.00011087104212492704
train/learning_rate(學習率),8978432,1767851620.060589,0.00011054336209781468
train/learning_rate(學習率),9011200,1767851623.9150236,0.00011021568207070231
train/learning_rate(學習率),9043968,1767851627.6861043,0.00010988800204358995
train/learning_rate(學習率),9076736,1767851631.4564013,0.00010956032201647758
train/learning_rate(學習率),9109504,1767851635.3077714,0.00010923264198936522
train/learning_rate(學習率),9142272,1767851639.1065817,0.00010890496196225286
train/learning_rate(學習率),9175040,1767851642.8536239,0.00010857728193514049
train/learning_rate(學習率),9207808,1767851646.7242799,0.00010824960190802813
train/learning_rate(學習率),9240576,1767851650.524385,0.00010792192188091576
train/learning_rate(學習率),9273344,1767851654.3266377,0.0001075942418538034
train/learning_rate(學習率),9306112,1767851658.129918,0.00010726656182669103
train/learning_rate(學習率),9338880,1767851661.9003403,0.00010693888179957867
train/learning_rate(學習率),9371648,1767851665.6797972,0.0001066112017724663
train/learning_rate(學習率),9404416,1767851669.5427177,0.00010628352174535394
train/learning_rate(學習率),9437184,1767851673.3665462,0.00010595584171824157
train/learning_rate(學習率),9469952,1767851677.180017,0.00010562816169112921
train/learning_rate(學習率),9502720,1767851680.9703443,0.00010530048166401684
train/learning_rate(學習率),9535488,1767851684.7552023,0.00010497280163690448
train/learning_rate(學習率),9568256,1767851688.5870562,0.00010464512160979211
train/learning_rate(學習率),9600000,1767851698.600738,0.00010431744158267975
train/learning_rate(學習率),9633792,1767851702.5447552,0.00010398976155556738
train/learning_rate(學習率),9666560,1767851706.3297298,0.00010366208152845502
train/learning_rate(學習率),9699328,1767851710.178134,0.00010333440150134265
train/learning_rate(學習率),9732096,1767851713.911464,0.00010300672147423029
train/learning_rate(學習率),9764864,1767851717.6755009,0.00010267904144711792
train/learning_rate(學習率),9797632,1767851721.4707024,0.00010235136142000556
train/learning_rate(學習率),9830400,1767851725.2913725,0.0001020236813928932
train/learning_rate(學習率),9863168,1767851729.1073449,0.00010169600136578083
train/learning_rate(學習率),9895936,1767851732.8964748,0.00010136832133866847
train/learning_rate(學習率),9928704,1767851736.723532,0.0001010406413115561
train/learning_rate(學習率),9961472,1767851740.5198991,0.00010071296128444374
train/learning_rate(學習率),9994240,1767851744.2771597,0.00010038528125733137
train/learning_rate(學習率),10027008,1767851748.0839155,0.000100057601230219
train/learning_rate(學習率),10059776,1767851751.8725479,9.972992120310664e-05
train/learning_rate(學習率),10092544,1767851755.6664157,9.940224117599428e-05
train/learning_rate(學習率),10125312,1767851759.5029423,9.907456114888191e-05
train/learning_rate(學習率),10158080,1767851763.2659757,9.874688112176955e-05
train/learning_rate(學習率),10190848,1767851767.0469668,9.841920109465718e-05
train/learning_rate(學習率),10223616,1767851770.87706,9.809152106754482e-05
train/learning_rate(學習率),10256384,1767851774.7005332,9.776384104043245e-05
train/learning_rate(學習率),10289152,1767851778.5006182,9.743616101332009e-05
train/learning_rate(學習率),10321920,1767851782.3119752,9.710848098620772e-05
train/learning_rate(學習率),10354688,1767851786.103872,9.678080095909536e-05
train/learning_rate(學習率),10387456,1767851789.889282,9.6453120931983e-05
train/learning_rate(學習率),10420224,1767851793.662539,9.612544090487063e-05
train/learning_rate(學習率),10452992,1767851797.5050159,9.579776087775826e-05
train/learning_rate(學習率),10485760,1767851801.2513824,9.54700808506459e-05
train/learning_rate(學習率),10518528,1767851805.0712113,9.514240082353354e-05
train/learning_rate(學習率),10551296,1767851808.8688548,9.481472079642117e-05
train/learning_rate(學習率),10584064,1767851812.6389425,9.44870407693088e-05
train/learning_rate(學習率),10616832,1767851816.490222,9.415936074219644e-05
train/learning_rate(學習率),10649600,1767851820.25121,9.383168071508408e-05
train/learning_rate(學習率),10682368,1767851824.0040731,9.350400068797171e-05
train/learning_rate(學習率),10715136,1767851827.861113,9.317632066085935e-05
train/learning_rate(學習率),10747904,1767851831.6708193,9.284864063374698e-05
train/learning_rate(學習率),10780672,1767851835.4792118,9.252096060663462e-05
train/learning_rate(學習率),10813440,1767851839.2813346,9.219328057952225e-05
train/learning_rate(學習率),10846208,1767851843.065974,9.186560055240989e-05
train/learning_rate(學習率),10878976,1767851846.8648553,9.153792052529752e-05
train/learning_rate(學習率),10911744,1767851850.6482563,9.121024049818516e-05
train/learning_rate(學習率),10944512,1767851854.4339461,9.088256047107279e-05
train/learning_rate(學習率),10977280,1767851858.2310927,9.055488044396043e-05
train/learning_rate(學習率),11010048,1767851862.1134384,9.022720041684806e-05
train/learning_rate(學習率),11042816,1767851865.956484,8.98995203897357e-05
train/learning_rate(學習率),11075584,1767851869.897537,8.957184036262333e-05
train/learning_rate(學習率),11108352,1767851873.7397423,8.924416033551097e-05
train/learning_rate(學習率),11141120,1767851877.6540227,8.89164803083986e-05
train/learning_rate(學習率),11173888,1767851881.506524,8.858880028128624e-05
train/learning_rate(學習率),11200000,1767851890.859954,8.826112025417387e-05
train/learning_rate(學習率),11239424,1767851895.6584544,8.793344022706151e-05
train/learning_rate(學習率),11272192,1767851899.437363,8.760576019994915e-05
train/learning_rate(學習率),11304960,1767851903.2367744,8.727808017283678e-05
train/learning_rate(學習率),11337728,1767851907.0456638,8.695040014572442e-05
train/learning_rate(學習率),11370496,1767851910.8145862,8.662272011861205e-05
train/learning_rate(學習率),11403264,1767851914.5965257,8.629504009149969e-05
train/learning_rate(學習率),11436032,1767851918.4351337,8.596736006438732e-05
train/learning_rate(學習率),11468800,1767851922.2353313,8.563968003727496e-05
train/learning_rate(學習率),11501568,1767851926.0057366,8.531200001016259e-05
train/learning_rate(學習率),11534336,1767851929.8337362,8.498431998305023e-05
train/learning_rate(學習率),11567104,1767851933.6304746,8.465663995593786e-05
train/learning_rate(學習率),11599872,1767851937.4094367,8.43289599288255e-05
train/learning_rate(學習率),11632640,1767851941.2539635,8.400127990171313e-05
train/learning_rate(學習率),11665408,1767851945.045703,8.367359987460077e-05
train/learning_rate(學習率),11698176,1767851948.827807,8.33459198474884e-05
train/learning_rate(學習率),11730944,1767851952.675069,8.301823982037604e-05
train/learning_rate(學習率),11763712,1767851956.4674273,8.269055979326367e-05
train/learning_rate(學習率),11796480,1767851960.358683,8.236287976615131e-05
train/learning_rate(學習率),11829248,1767851964.2478104,8.203519973903894e-05
train/learning_rate(學習率),11862016,1767851968.0738328,8.170751971192658e-05
train/learning_rate(學習率),11894784,1767851971.9493694,8.137983968481421e-05
train/learning_rate(學習率),11927552,1767851975.8439918,8.105215965770185e-05
train/learning_rate(學習率),11960320,1767851979.655874,8.072447963058949e-05
train/learning_rate(學習率),11993088,1767851983.4819186,8.039679960347712e-05
train/learning_rate(學習率),12025856,1767851987.3353593,8.006911957636476e-05
train/learning_rate(學習率),12058624,1767851991.2070632,7.974143954925239e-05
train/learning_rate(學習率),12091392,1767851995.0093503,7.941375952214003e-05
train/learning_rate(學習率),12124160,1767851998.8575733,7.908607949502766e-05
train/learning_rate(學習率),12156928,1767852002.723118,7.87583994679153e-05
train/learning_rate(學習率),12189696,1767852006.6192544,7.843071944080293e-05
train/learning_rate(學習率),12222464,1767852010.4443982,7.810303941369057e-05
train/learning_rate(學習率),12255232,1767852014.2415743,7.77753593865782e-05
train/learning_rate(學習率),12288000,1767852018.0783741,7.744767935946584e-05
train/learning_rate(學習率),12320768,1767852021.9418716,7.711999933235347e-05
train/learning_rate(學習率),12353536,1767852025.8486497,7.679231930524111e-05
train/learning_rate(學習率),12386304,1767852029.716671,7.646463927812874e-05
train/learning_rate(學習率),12419072,1767852033.6132348,7.613695925101638e-05
train/learning_rate(學習率),12451840,1767852037.411729,7.580927922390401e-05
train/learning_rate(學習率),12484608,1767852041.2448833,7.548159919679165e-05
train/learning_rate(學習率),12517376,1767852045.0343423,7.515391916967928e-05
train/learning_rate(學習率),12550144,1767852048.8760827,7.482623914256692e-05
train/learning_rate(學習率),12582912,1767852052.7375727,7.449855911545455e-05
train/learning_rate(學習率),12615680,1767852056.60109,7.417087908834219e-05
train/learning_rate(學習率),12648448,1767852060.4723964,7.384319906122983e-05
train/learning_rate(學習率),12681216,1767852064.3374374,7.351551903411746e-05
train/learning_rate(學習率),12713984,1767852068.303477,7.31878390070051e-05
train/learning_rate(學習率),12746752,1767852072.1466877,7.286015897989273e-05
train/learning_rate(學習率),12779520,1767852076.0877922,7.253247895278037e-05
train/learning_rate(學習率),12800000,1767852083.8443215,7.2204798925668e-05
train/learning_rate(學習率),12845056,1767852089.3506994,7.187711889855564e-05
train/learning_rate(學習率),12877824,1767852093.2415376,7.154943887144327e-05
train/learning_rate(學習率),12910592,1767852097.0481791,7.122175884433091e-05
train/learning_rate(學習率),12943360,1767852100.8524952,7.089407881721854e-05
train/learning_rate(學習率),12976128,1767852104.6656787,7.056639879010618e-05
train/learning_rate(學習率),13008896,1767852108.5615203,7.023871876299381e-05
train/learning_rate(學習率),13041664,1767852112.3818095,6.991103873588145e-05
train/learning_rate(學習率),13074432,1767852116.1452997,6.958335870876908e-05
train/learning_rate(學習率),13107200,1767852119.9847195,6.925567868165672e-05
train/learning_rate(學習率),13139968,1767852123.7673254,6.892799865454435e-05
train/learning_rate(學習率),13172736,1767852127.555611,6.860031862743199e-05
train/learning_rate(學習率),13205504,1767852131.4294608,6.827263860031962e-05
train/learning_rate(學習率),13238272,1767852135.2610745,6.794495857320726e-05
train/learning_rate(學習率),13271040,1767852139.1296704,6.76172785460949e-05
train/learning_rate(學習率),13303808,1767852142.939284,6.728959851898253e-05
train/learning_rate(學習率),13336576,1767852146.6933453,6.696191849187016e-05
train/learning_rate(學習率),13369344,1767852150.5655675,6.66342384647578e-05
train/learning_rate(學習率),13402112,1767852154.337042,6.630655843764544e-05
train/learning_rate(學習率),13434880,1767852158.1100445,6.597887841053307e-05
train/learning_rate(學習率),13467648,1767852161.9528158,6.56511983834207e-05
train/learning_rate(學習率),13500416,1767852165.7732508,6.532351835630834e-05
train/learning_rate(學習率),13533184,1767852169.5396895,6.499583832919598e-05
train/learning_rate(學習率),13565952,1767852173.3529642,6.466815830208361e-05
train/learning_rate(學習率),13598720,1767852177.1586583,6.434047827497125e-05
train/learning_rate(學習率),13631488,1767852180.9323645,6.401279824785888e-05
train/learning_rate(學習率),13664256,1767852184.7686446,6.368511822074652e-05
train/learning_rate(學習率),13697024,1767852188.5371807,6.335743819363415e-05
train/learning_rate(學習率),13729792,1767852192.3260584,6.302975816652179e-05
train/learning_rate(學習率),13762560,1767852196.1565945,6.270207813940942e-05
train/learning_rate(學習率),13795328,1767852199.9402995,6.237439811229706e-05
train/learning_rate(學習率),13828096,1767852203.746766,6.20467180851847e-05
train/learning_rate(學習率),13860864,1767852207.5603771,6.171903805807233e-05
train/learning_rate(學習率),13893632,1767852211.3222716,6.139135803095996e-05
train/learning_rate(學習率),13926400,1767852215.117207,6.10636780038476e-05
train/learning_rate(學習率),13959168,1767852218.9593084,6.073600161471404e-05
train/learning_rate(學習率),13991936,1767852222.7497587,6.0408321587601677e-05
train/learning_rate(學習率),14024704,1767852226.5376217,6.008064156048931e-05
train/learning_rate(學習率),14057472,1767852230.341306,5.975296153337695e-05
train/learning_rate(學習率),14090240,1767852234.1532724,5.942528150626458e-05
train/learning_rate(學習率),14123008,1767852237.9555166,5.909760147915222e-05
train/learning_rate(學習率),14155776,1767852241.7709186,5.876992145203985e-05
train/learning_rate(學習率),14188544,1767852245.580831,5.844224142492749e-05
train/learning_rate(學習率),14221312,1767852249.4112377,5.811456139781512e-05
train/learning_rate(學習率),14254080,1767852253.1772535,5.778688137070276e-05
train/learning_rate(學習率),14286848,1767852256.9677918,5.7459201343590394e-05
train/learning_rate(學習率),14319616,1767852260.8131015,5.713152131647803e-05
train/learning_rate(學習率),14352384,1767852264.6120255,5.6803841289365664e-05
train/learning_rate(學習率),14385152,1767852268.473499,5.64761612622533e-05
train/learning_rate(學習率),14400000,1767852276.521322,5.6148481235140935e-05
train/learning_rate(學習率),14450688,1767852282.5740464,5.582080120802857e-05
train/learning_rate(學習率),14483456,1767852286.3921025,5.5493121180916205e-05
train/learning_rate(學習率),14516224,1767852290.2720983,5.516544115380384e-05
train/learning_rate(學習率),14548992,1767852294.1244688,5.4837761126691476e-05
train/learning_rate(學習率),14581760,1767852297.9144642,5.451008109957911e-05
train/learning_rate(學習率),14614528,1767852301.7823184,5.4182401072466746e-05
train/learning_rate(學習率),14647296,1767852305.5912447,5.385472104535438e-05
train/learning_rate(學習率),14680064,1767852309.4423165,5.3527041018242016e-05
train/learning_rate(學習率),14712832,1767852313.3264575,5.319936099112965e-05
train/learning_rate(學習率),14745600,1767852317.128722,5.287168096401729e-05
train/learning_rate(學習率),14778368,1767852320.9527233,5.254400093690492e-05
train/learning_rate(學習率),14811136,1767852324.7873342,5.221632090979256e-05
train/learning_rate(學習率),14843904,1767852328.6576471,5.188864088268019e-05
train/learning_rate(學習率),14876672,1767852332.5206673,5.156096085556783e-05
train/learning_rate(學習率),14909440,1767852336.2900808,5.123328082845546e-05
train/learning_rate(學習率),14942208,1767852340.1513834,5.09056008013431e-05
train/learning_rate(學習率),14974976,1767852343.9663556,5.0577920774230734e-05
train/learning_rate(學習率),15007744,1767852347.8196182,5.025024074711837e-05
train/loss(總損失),65536,1767850559.2295241,0.4475935101509094
train/loss(總損失),98304,1767850562.9971344,0.4764057397842407
train/loss(總損失),131072,1767850566.7199862,0.5176271796226501
train/loss(總損失),163840,1767850570.4483514,0.5189940929412842
train/loss(總損失),196608,1767850574.1534498,0.5155245065689087
train/loss(總損失),229376,1767850577.8905578,0.42656105756759644
train/loss(總損失),262144,1767850581.583047,0.33482107520103455
train/loss(總損失),294912,1767850585.2030509,0.20241974294185638
train/loss(總損失),327680,1767850588.9230797,0.11851277202367783
train/loss(總損失),360448,1767850592.6420286,0.0821811631321907
train/loss(總損失),393216,1767850596.5343516,0.06421060115098953
train/loss(總損失),425984,1767850600.2572355,0.046514566987752914
train/loss(總損失),458752,1767850604.004208,0.034543368965387344
train/loss(總損失),491520,1767850607.7767951,0.02410324476659298
train/loss(總損失),524288,1767850611.5745854,0.019504137337207794
train/loss(總損失),557056,1767850615.2046947,0.017264200374484062
train/loss(總損失),589824,1767850618.933322,0.0116902906447649
train/loss(總損失),622592,1767850622.620369,0.00902019627392292
train/loss(總損失),655360,1767850626.317546,0.006764696910977364
train/loss(總損失),688128,1767850629.9229238,0.007182248868048191
train/loss(總損失),720896,1767850633.6161911,0.007079639472067356
train/loss(總損失),753664,1767850637.1993759,0.007294459734112024
train/loss(總損失),786432,1767850640.8727472,0.0038814758881926537
train/loss(總損失),819200,1767850644.4664817,0.0037118522450327873
train/loss(總損失),851968,1767850648.1052475,0.001267770305275917
train/loss(總損失),884736,1767850651.7045784,0.0022773053497076035
train/loss(總損失),917504,1767850655.3435278,0.0019207997247576714
train/loss(總損失),950272,1767850659.0710485,0.0007020183838903904
train/loss(總損失),983040,1767850662.7455473,0.0009022164158523083
train/loss(總損失),1015808,1767850666.481074,-3.649061545729637e-05
train/loss(總損失),1048576,1767850670.1074698,-0.0003570578992366791
train/loss(總損失),1081344,1767850673.8068314,4.542805254459381e-05
train/loss(總損失),1114112,1767850677.3988,-0.001927997451275587
train/loss(總損失),1146880,1767850681.0852022,0.0004988731816411018
train/loss(總損失),1179648,1767850684.685882,-0.0007097618654370308
train/loss(總損失),1212416,1767850688.3471098,-0.0005614752881228924
train/loss(總損失),1245184,1767850692.0412767,-0.0024323295801877975
train/loss(總損失),1277952,1767850695.7100718,-0.0013644960708916187
train/loss(總損失),1310720,1767850699.3796778,-0.0016942694783210754
train/loss(總損失),1343488,1767850703.1060586,-0.0006784149445593357
train/loss(總損失),1376256,1767850706.7275863,-0.0017173364758491516
train/loss(總損失),1409024,1767850710.4058769,0.01504695788025856
train/loss(總損失),1441792,1767850713.9961836,-0.0014673271216452122
train/loss(總損失),1474560,1767850717.6608357,-0.0009351056069135666
train/loss(總損失),1507328,1767850721.2696497,0.013799745589494705
train/loss(總損失),1540096,1767850724.9062245,-0.0030863925348967314
train/loss(總損失),1572864,1767850728.5162637,0.023099012672901154
train/loss(總損失),1600000,1767850737.0012846,0.012157165445387363
train/loss(總損失),1638400,1767850741.4428859,0.031501900404691696
train/loss(總損失),1671168,1767850745.0722322,0.04498156160116196
train/loss(總損失),1703936,1767850748.701232,0.004560019820928574
train/loss(總損失),1736704,1767850752.3870256,0.019697649404406548
train/loss(總損失),1769472,1767850755.9532557,0.0002072933129966259
train/loss(總損失),1802240,1767850759.612867,0.028334051370620728
train/loss(總損失),1835008,1767850763.1796484,0.024960223585367203
train/loss(總損失),1867776,1767850766.815694,0.03426355496048927
train/loss(總損失),1900544,1767850770.3717258,0.07179325819015503
train/loss(總損失),1933312,1767850774.0567575,0.024145565927028656
train/loss(總損失),1966080,1767850777.6604764,0.017604123800992966
train/loss(總損失),1998848,1767850781.2771404,0.032467763870954514
train/loss(總損失),2031616,1767850784.884306,0.06760953366756439
train/loss(總損失),2064384,1767850788.493375,0.04578186199069023
train/loss(總損失),2097152,1767850792.2032356,0.007177101913839579
train/loss(總損失),2129920,1767850795.866282,0.009182831272482872
train/loss(總損失),2162688,1767850799.5272243,0.03937799483537674
train/loss(總損失),2195456,1767850803.2312806,0.007917482405900955
train/loss(總損失),2228224,1767850806.8444574,0.03360404074192047
train/loss(總損失),2260992,1767850810.4568942,0.025742702186107635
train/loss(總損失),2293760,1767850814.0776038,0.03316841647028923
train/loss(總損失),2326528,1767850817.7324646,0.03507411107420921
train/loss(總損失),2359296,1767850821.3082688,0.039635784924030304
train/loss(總損失),2392064,1767850824.9743595,0.024396760389208794
train/loss(總損失),2424832,1767850828.55592,0.0541711151599884
train/loss(總損失),2457600,1767850832.2089677,0.028120005503296852
train/loss(總損失),2490368,1767850835.7887897,0.048165831714868546
train/loss(總損失),2523136,1767850839.410689,0.021427787840366364
train/loss(總損失),2555904,1767850842.9688787,0.07969105988740921
train/loss(總損失),2588672,1767850846.6125402,0.031323134899139404
train/loss(總損失),2621440,1767850850.1919608,0.02508504129946232
train/loss(總損失),2654208,1767850853.8273733,0.01788158155977726
train/loss(總損失),2686976,1767850857.4195008,0.08603989332914352
train/loss(總損失),2719744,1767850861.3290613,0.07248813658952713
train/loss(總損失),2752512,1767850865.0908148,0.05511298030614853
train/loss(總損失),2785280,1767850869.031745,-0.0019863033667206764
train/loss(總損失),2818048,1767850872.8499599,0.06158813089132309
train/loss(總損失),2850816,1767850876.7107396,0.0377291664481163
train/loss(總損失),2883584,1767850880.490425,0.0983319878578186
train/loss(總損失),2916352,1767850884.3961153,0.06297282129526138
train/loss(總損失),2949120,1767850888.1792123,0.03646216541528702
train/loss(總損失),2981888,1767850891.9776053,0.0624270923435688
train/loss(總損失),3014656,1767850895.7587442,0.10342208296060562
train/loss(總損失),3047424,1767850899.581668,0.005413966253399849
train/loss(總損失),3080192,1767850903.3661573,0.08586914837360382
train/loss(總損失),3112960,1767850907.1832235,0.0912030041217804
train/loss(總損失),3145728,1767850911.2443433,0.04972104728221893
train/loss(總損失),3178496,1767850915.1832602,0.08696004748344421
train/loss(總損失),3200000,1767850924.5230672,0.0095083462074399
train/loss(總損失),3244032,1767850929.708885,0.0423569492995739
train/loss(總損失),3276800,1767850933.5472097,0.04614732787013054
train/loss(總損失),3309568,1767850937.467982,0.08946815133094788
train/loss(總損失),3342336,1767850941.3097546,0.04426371306180954
train/loss(總損失),3375104,1767850945.2967665,0.15802964568138123
train/loss(總損失),3407872,1767850949.2090595,0.036915846168994904
train/loss(總損失),3440640,1767850952.9483771,0.11219169199466705
train/loss(總損失),3473408,1767850957.3185942,0.13894356787204742
train/loss(總損失),3506176,1767850961.4267182,0.03922446444630623
train/loss(總損失),3538944,1767850965.3084548,0.11798027157783508
train/loss(總損失),3571712,1767850969.296191,0.07753186672925949
train/loss(總損失),3604480,1767850972.9710395,0.0664718896150589
train/loss(總損失),3637248,1767850976.7373757,0.11560525745153427
train/loss(總損失),3670016,1767850980.5689178,0.026316184550523758
train/loss(總損失),3702784,1767850984.6186466,0.08691408485174179
train/loss(總損失),3735552,1767850988.6584132,0.07596571743488312
train/loss(總損失),3768320,1767850992.5548205,0.09443642199039459
train/loss(總損失),3801088,1767850996.51568,0.02237103506922722
train/loss(總損失),3833856,1767851000.422122,0.07790405303239822
train/loss(總損失),3866624,1767851004.6852853,0.04789294674992561
train/loss(總損失),3899392,1767851008.561874,0.1153334528207779
train/loss(總損失),3932160,1767851012.599403,0.04182002693414688
train/loss(總損失),3964928,1767851016.6966462,0.12103940546512604
train/loss(總損失),3997696,1767851020.5575488,0.058137498795986176
train/loss(總損失),4030464,1767851024.2745268,0.09820874780416489
train/loss(總損失),4063232,1767851027.931706,0.03376792371273041
train/loss(總損失),4096000,1767851031.6902683,0.08755765855312347
train/loss(總損失),4128768,1767851035.552128,0.1332705020904541
train/loss(總損失),4161536,1767851039.362606,0.06806319206953049
train/loss(總損失),4194304,1767851043.200196,0.1337536722421646
train/loss(總損失),4227072,1767851047.1003935,0.00901385210454464
train/loss(總損失),4259840,1767851050.8482265,0.06560787558555603
train/loss(總損失),4292608,1767851054.8405092,0.07540638744831085
train/loss(總損失),4325376,1767851058.8245432,0.05159889534115791
train/loss(總損失),4358144,1767851062.640887,0.10179156064987183
train/loss(總損失),4390912,1767851066.511372,0.07442381232976913
train/loss(總損失),4423680,1767851070.3151045,0.12991978228092194
train/loss(總損失),4456448,1767851074.102386,0.05075579509139061
train/loss(總損失),4489216,1767851077.8736207,0.02182478830218315
train/loss(總損失),4521984,1767851081.7243874,0.06645432859659195
train/loss(總損失),4554752,1767851085.5352962,0.12061908841133118
train/loss(總損失),4587520,1767851089.4037945,0.08419354259967804
train/loss(總損失),4620288,1767851093.227601,0.0723349004983902
train/loss(總損失),4653056,1767851097.0151076,0.11337298154830933
train/loss(總損失),4685824,1767851100.8662007,0.03681750223040581
train/loss(總損失),4718592,1767851104.6115327,0.19411218166351318
train/loss(總損失),4751360,1767851108.3256793,0.014308520592749119
train/loss(總損失),4784128,1767851112.1232119,0.10319272428750992
train/loss(總損失),4800000,1767851120.069484,0.07359956949949265
train/loss(總損失),4849664,1767851125.9418159,0.10057023167610168
train/loss(總損失),4882432,1767851129.6968298,0.04052083194255829
train/loss(總損失),4915200,1767851133.48323,0.057721126824617386
train/loss(總損失),4947968,1767851137.2527626,0.02221386507153511
train/loss(總損失),4980736,1767851141.0994492,0.07755496352910995
train/loss(總損失),5013504,1767851144.8320682,0.05217228829860687
train/loss(總損失),5046272,1767851148.5421064,0.06783102452754974
train/loss(總損失),5079040,1767851152.4145024,0.08149059116840363
train/loss(總損失),5111808,1767851156.206934,0.11214172095060349
train/loss(總損失),5144576,1767851159.8980644,0.10951240360736847
train/loss(總損失),5177344,1767851163.7191901,0.09884615987539291
train/loss(總損失),5210112,1767851167.4530969,0.08997237682342529
train/loss(總損失),5242880,1767851171.2078493,0.08326088637113571
train/loss(總損失),5275648,1767851174.9225078,0.17781607806682587
train/loss(總損失),5308416,1767851178.7845979,0.0841628834605217
train/loss(總損失),5341184,1767851182.6305401,0.06114354357123375
train/loss(總損失),5373952,1767851186.3842208,0.01733497530221939
train/loss(總損失),5406720,1767851190.256159,0.0012712241150438786
train/loss(總損失),5439488,1767851194.0659354,0.055528994649648666
train/loss(總損失),5472256,1767851197.8260283,0.07865174114704132
train/loss(總損失),5505024,1767851201.6639018,0.0793699249625206
train/loss(總損失),5537792,1767851205.4095185,0.04176926612854004
train/loss(總損失),5570560,1767851209.1647682,0.16859859228134155
train/loss(總損失),5603328,1767851212.9930987,0.07202887535095215
train/loss(總損失),5636096,1767851216.780533,0.08234919607639313
train/loss(總損失),5668864,1767851220.50399,0.09273426234722137
train/loss(總損失),5701632,1767851224.349205,0.09383945167064667
train/loss(總損失),5734400,1767851228.1825051,0.11687404662370682
train/loss(總損失),5767168,1767851231.9415665,0.07291732728481293
train/loss(總損失),5799936,1767851235.8235393,0.039354920387268066
train/loss(總損失),5832704,1767851239.6419158,0.11417823284864426
train/loss(總損失),5865472,1767851243.3867345,0.07628066837787628
train/loss(總損失),5898240,1767851247.2597299,0.11538651585578918
train/loss(總損失),5931008,1767851251.027742,0.07738947123289108
train/loss(總損失),5963776,1767851254.8078127,0.08515579998493195
train/loss(總損失),5996544,1767851258.8198528,0.09445686638355255
train/loss(總損失),6029312,1767851262.7803826,0.033893804997205734
train/loss(總損失),6062080,1767851266.7045023,0.11246988922357559
train/loss(總損失),6094848,1767851270.5552242,0.13878026604652405
train/loss(總損失),6127616,1767851274.4984272,0.06189917027950287
train/loss(總損失),6160384,1767851278.5363,0.15186092257499695
train/loss(總損失),6193152,1767851282.497792,0.04175545275211334
train/loss(總損失),6225920,1767851286.371077,0.13387732207775116
train/loss(總損失),6258688,1767851290.3003335,0.07883406430482864
train/loss(總損失),6291456,1767851294.1221151,0.14213040471076965
train/loss(總損失),6324224,1767851298.0558202,0.08792074769735336
train/loss(總損失),6356992,1767851301.9332805,0.13384142518043518
train/loss(總損失),6389760,1767851305.9020336,0.13605494797229767
train/loss(總損失),6400000,1767851311.462924,0.06280669569969177
train/loss(總損失),6455296,1767851318.2926252,0.10215366631746292
train/loss(總損失),6488064,1767851322.189184,0.06096841022372246
train/loss(總損失),6520832,1767851326.0816662,0.11583828926086426
train/loss(總損失),6553600,1767851329.9729526,0.10426037013530731
train/loss(總損失),6586368,1767851333.9150825,0.09281634539365768
train/loss(總損失),6619136,1767851337.7628021,0.07973051071166992
train/loss(總損失),6651904,1767851341.701503,0.12635144591331482
train/loss(總損失),6684672,1767851345.6731632,0.09131277352571487
train/loss(總損失),6717440,1767851349.560387,0.1574985384941101
train/loss(總損失),6750208,1767851353.5049803,0.06816646456718445
train/loss(總損失),6782976,1767851357.4353492,0.05139508098363876
train/loss(總損失),6815744,1767851361.282602,0.10127373784780502
train/loss(總損失),6848512,1767851365.1255405,0.12295623123645782
train/loss(總損失),6881280,1767851369.1308281,0.06369397044181824
train/loss(總損失),6914048,1767851373.0831103,0.09851211309432983
train/loss(總損失),6946816,1767851376.9341528,0.14358404278755188
train/loss(總損失),6979584,1767851380.8888044,0.07778023928403854
train/loss(總損失),7012352,1767851384.8043604,0.1265636682510376
train/loss(總損失),7045120,1767851388.6258478,0.06580890715122223
train/loss(總損失),7077888,1767851392.4364486,0.21682456135749817
train/loss(總損失),7110656,1767851396.2063391,0.11691378057003021
train/loss(總損失),7143424,1767851400.0019038,0.15544508397579193
train/loss(總損失),7176192,1767851403.8091478,0.0728224366903305
train/loss(總損失),7208960,1767851407.5575747,0.2173689901828766
train/loss(總損失),7241728,1767851411.3092682,0.05911681056022644
train/loss(總損失),7274496,1767851415.177134,0.13970069587230682
train/loss(總損失),7307264,1767851418.9848976,0.1260708123445511
train/loss(總損失),7340032,1767851422.7513814,0.12121649086475372
train/loss(總損失),7372800,1767851426.6543834,0.13429498672485352
train/loss(總損失),7405568,1767851430.4099774,0.0963117852807045
train/loss(總損失),7438336,1767851434.2532735,0.06946959346532822
train/loss(總損失),7471104,1767851438.027645,0.08694974333047867
train/loss(總損失),7503872,1767851441.8613071,0.10941224545240402
train/loss(總損失),7536640,1767851445.6970434,0.12891684472560883
train/loss(總損失),7569408,1767851449.6036465,0.053102217614650726
train/loss(總損失),7602176,1767851453.3829386,0.14793403446674347
train/loss(總損失),7634944,1767851457.2030041,0.14913634955883026
train/loss(總損失),7667712,1767851461.0323594,0.12361042946577072
train/loss(總損失),7700480,1767851464.8357837,0.1144154965877533
train/loss(總損失),7733248,1767851468.663515,0.03659505024552345
train/loss(總損失),7766016,1767851472.5628033,0.1829763948917389
train/loss(總損失),7798784,1767851476.44101,0.12220627069473267
train/loss(總損失),7831552,1767851480.2209823,0.16222107410430908
train/loss(總損失),7864320,1767851484.0791864,0.06816096603870392
train/loss(總損失),7897088,1767851487.9261947,0.2022046446800232
train/loss(總損失),7929856,1767851491.717675,0.009640617296099663
train/loss(總損失),7962624,1767851495.5764532,0.19422271847724915
train/loss(總損失),7995392,1767851499.3429677,0.04939938709139824
train/loss(總損失),8000000,1767851506.12033,0.14416563510894775
train/loss(總損失),8060928,1767851513.3896632,0.08584180474281311
train/loss(總損失),8093696,1767851517.217103,0.094392791390419
train/loss(總損失),8126464,1767851521.0065434,0.09977279603481293
train/loss(總損失),8159232,1767851524.8328652,0.04477595537900925
train/loss(總損失),8192000,1767851528.6117404,0.17881570756435394
train/loss(總損失),8224768,1767851532.4548416,0.03522603213787079
train/loss(總損失),8257536,1767851536.3604865,0.1367436796426773
train/loss(總損失),8290304,1767851540.1405644,0.04687678813934326
train/loss(總損失),8323072,1767851543.9752173,0.1334819346666336
train/loss(總損失),8355840,1767851547.7974606,0.08155060559511185
train/loss(總損失),8388608,1767851551.589234,0.08447466790676117
train/loss(總損失),8421376,1767851555.4249458,0.1232997253537178
train/loss(總損失),8454144,1767851559.1645546,0.08926154673099518
train/loss(總損失),8486912,1767851562.9092748,0.13560780882835388
train/loss(總損失),8519680,1767851566.6495507,0.05347689986228943
train/loss(總損失),8552448,1767851570.5102527,0.0839180275797844
train/loss(總損失),8585216,1767851574.3190894,0.08815600723028183
train/loss(總損失),8617984,1767851578.1054616,0.08763759583234787
train/loss(總損失),8650752,1767851581.9335535,0.05678663030266762
train/loss(總損失),8683520,1767851585.6849768,0.12091347575187683
train/loss(總損失),8716288,1767851589.452577,0.0441058985888958
train/loss(總損失),8749056,1767851593.3209686,0.0752195417881012
train/loss(總損失),8781824,1767851597.1184623,0.018166784197092056
train/loss(總損失),8814592,1767851600.8884895,0.1660553514957428
train/loss(總損失),8847360,1767851604.7932854,0.032378703355789185
train/loss(總損失),8880128,1767851608.6254165,0.03526997193694115
train/loss(總損失),8912896,1767851612.5267959,0.09962684661149979
train/loss(總損失),8945664,1767851616.3148751,0.08461938798427582
train/loss(總損失),8978432,1767851620.060589,0.17298661172389984
train/loss(總損失),9011200,1767851623.9160254,0.13485483825206757
train/loss(總損失),9043968,1767851627.6871045,0.08817257732152939
train/loss(總損失),9076736,1767851631.4564013,0.11363633722066879
train/loss(總損失),9109504,1767851635.3077714,0.09167152643203735
train/loss(總損失),9142272,1767851639.1065817,0.10834778845310211
train/loss(總損失),9175040,1767851642.8536239,0.05641721189022064
train/loss(總損失),9207808,1767851646.7252815,0.11663711071014404
train/loss(總損失),9240576,1767851650.524385,0.13197940587997437
train/loss(總損失),9273344,1767851654.3266377,0.1086268424987793
train/loss(總損失),9306112,1767851658.129918,0.12222066521644592
train/loss(總損失),9338880,1767851661.9003403,0.11247335374355316
train/loss(總損失),9371648,1767851665.6797972,0.11825532466173172
train/loss(總損失),9404416,1767851669.5437174,0.08042462170124054
train/loss(總損失),9437184,1767851673.3665462,0.08622297644615173
train/loss(總損失),9469952,1767851677.180017,0.06580124795436859
train/loss(總損失),9502720,1767851680.9703443,0.07367119193077087
train/loss(總損失),9535488,1767851684.7552023,0.14670974016189575
train/loss(總損失),9568256,1767851688.5870562,0.12989018857479095
train/loss(總損失),9600000,1767851698.600738,0.15320897102355957
train/loss(總損失),9633792,1767851702.5447552,0.07943408936262131
train/loss(總損失),9666560,1767851706.3297298,0.19560952484607697
train/loss(總損失),9699328,1767851710.178134,0.11950602382421494
train/loss(總損失),9732096,1767851713.911464,0.16632632911205292
train/loss(總損失),9764864,1767851717.676499,0.022452548146247864
train/loss(總損失),9797632,1767851721.4707024,0.16659015417099
train/loss(總損失),9830400,1767851725.2913725,0.12973029911518097
train/loss(總損失),9863168,1767851729.1073449,0.09288017451763153
train/loss(總損失),9895936,1767851732.8964748,0.14166295528411865
train/loss(總損失),9928704,1767851736.723532,0.07723011076450348
train/loss(總損失),9961472,1767851740.5198991,0.13603174686431885
train/loss(總損失),9994240,1767851744.2771597,0.11106133460998535
train/loss(總損失),10027008,1767851748.0849175,0.17038004100322723
train/loss(總損失),10059776,1767851751.8735495,0.07509037852287292
train/loss(總損失),10092544,1767851755.6664157,0.11119917780160904
train/loss(總損失),10125312,1767851759.5029423,0.052232857793569565
train/loss(總損失),10158080,1767851763.2659757,0.11978220194578171
train/loss(總損失),10190848,1767851767.0469668,0.08739715814590454
train/loss(總損失),10223616,1767851770.87706,0.08288996666669846
train/loss(總損失),10256384,1767851774.7015347,0.10157360136508942
train/loss(總損失),10289152,1767851778.5006182,0.08318696916103363
train/loss(總損失),10321920,1767851782.3119752,0.06673041731119156
train/loss(總損失),10354688,1767851786.103872,0.058349404484033585
train/loss(總損失),10387456,1767851789.889282,0.03872808441519737
train/loss(總損失),10420224,1767851793.662539,0.08767831325531006
train/loss(總損失),10452992,1767851797.5050159,0.07321882247924805
train/loss(總損失),10485760,1767851801.2513824,0.15390799939632416
train/loss(總損失),10518528,1767851805.0712113,0.07061077654361725
train/loss(總損失),10551296,1767851808.8688548,0.052029531449079514
train/loss(總損失),10584064,1767851812.6389425,0.049109719693660736
train/loss(總損失),10616832,1767851816.490222,0.07688897848129272
train/loss(總損失),10649600,1767851820.25121,0.02393445558845997
train/loss(總損失),10682368,1767851824.0040731,0.17013584077358246
train/loss(總損失),10715136,1767851827.861113,0.028732573613524437
train/loss(總損失),10747904,1767851831.6708193,0.0878252238035202
train/loss(總損失),10780672,1767851835.4792118,0.12176387757062912
train/loss(總損失),10813440,1767851839.2813346,0.07480842620134354
train/loss(總損失),10846208,1767851843.0669723,0.08708126842975616
train/loss(總損失),10878976,1767851846.8648553,0.15004298090934753
train/loss(總損失),10911744,1767851850.6492507,0.09189799427986145
train/loss(總損失),10944512,1767851854.4339461,0.09374070912599564
train/loss(總損失),10977280,1767851858.2310927,0.093850277364254
train/loss(總損失),11010048,1767851862.1134384,0.10735879838466644
train/loss(總損失),11042816,1767851865.956484,0.09282394498586655
train/loss(總損失),11075584,1767851869.8980806,0.06861589848995209
train/loss(總損失),11108352,1767851873.7402625,0.06837835162878036
train/loss(總損失),11141120,1767851877.6550186,0.04759514704346657
train/loss(總損失),11173888,1767851881.506524,0.10772433876991272
train/loss(總損失),11200000,1767851890.859954,0.12479595094919205
train/loss(總損失),11239424,1767851895.6584544,0.0029481067322194576
train/loss(總損失),11272192,1767851899.437363,0.12471724301576614
train/loss(總損失),11304960,1767851903.2367744,0.07810179889202118
train/loss(總損失),11337728,1767851907.0456638,0.13423752784729004
train/loss(總損失),11370496,1767851910.8145862,0.06544475257396698
train/loss(總損失),11403264,1767851914.5975258,0.0841180756688118
train/loss(總損失),11436032,1767851918.4351337,0.10686980187892914
train/loss(總損失),11468800,1767851922.2353313,0.14104631543159485
train/loss(總損失),11501568,1767851926.0057366,0.024743366986513138
train/loss(總損失),11534336,1767851929.8337362,0.011129342019557953
train/loss(總損失),11567104,1767851933.6304746,0.08505292981863022
train/loss(總損失),11599872,1767851937.410437,0.06987638026475906
train/loss(總損失),11632640,1767851941.2539635,0.10077222436666489
train/loss(總損失),11665408,1767851945.045703,0.02611539512872696
train/loss(總損失),11698176,1767851948.827807,0.10527316480875015
train/loss(總損失),11730944,1767851952.675069,0.06047504395246506
train/loss(總損失),11763712,1767851956.4674273,0.07095103710889816
train/loss(總損失),11796480,1767851960.358683,0.1151140108704567
train/loss(總損失),11829248,1767851964.2478104,0.14669522643089294
train/loss(總損失),11862016,1767851968.0738328,0.018902190029621124
train/loss(總損失),11894784,1767851971.9493694,0.20661649107933044
train/loss(總損失),11927552,1767851975.8439918,0.027994126081466675
train/loss(總損失),11960320,1767851979.655874,0.07024891674518585
train/loss(總損失),11993088,1767851983.4819186,0.03176989406347275
train/loss(總損失),12025856,1767851987.3353593,0.11666491627693176
train/loss(總損失),12058624,1767851991.2070632,0.14193430542945862
train/loss(總損失),12091392,1767851995.0093503,0.03998210281133652
train/loss(總損失),12124160,1767851998.8575733,0.07245930284261703
train/loss(總損失),12156928,1767852002.723118,0.09793795645236969
train/loss(總損失),12189696,1767852006.6192544,0.08779975771903992
train/loss(總損失),12222464,1767852010.4443982,0.11160924285650253
train/loss(總損失),12255232,1767852014.2415743,0.10144758224487305
train/loss(總損失),12288000,1767852018.0783741,0.10551301389932632
train/loss(總損失),12320768,1767852021.9418716,0.03270893171429634
train/loss(總損失),12353536,1767852025.8486497,0.10225328058004379
train/loss(總損失),12386304,1767852029.716671,0.15373770892620087
train/loss(總損失),12419072,1767852033.6132348,0.04894169047474861
train/loss(總損失),12451840,1767852037.411729,0.11609131097793579
train/loss(總損失),12484608,1767852041.2448833,0.0668160617351532
train/loss(總損失),12517376,1767852045.0343423,0.11563381552696228
train/loss(總損失),12550144,1767852048.8770835,0.06265357881784439
train/loss(總損失),12582912,1767852052.7375727,0.06535317003726959
train/loss(總損失),12615680,1767852056.6020916,0.0067554647102952
train/loss(總損失),12648448,1767852060.4723964,0.04982301592826843
train/loss(總損失),12681216,1767852064.3374374,0.03918046876788139
train/loss(總損失),12713984,1767852068.303477,0.08504167944192886
train/loss(總損失),12746752,1767852072.1466877,0.031201612204313278
train/loss(總損失),12779520,1767852076.0877922,0.07397628575563431
train/loss(總損失),12800000,1767852083.8443215,0.09650064259767532
train/loss(總損失),12845056,1767852089.3506994,0.039694588631391525
train/loss(總損失),12877824,1767852093.2415376,0.0308085884898901
train/loss(總損失),12910592,1767852097.0481791,0.07413747906684875
train/loss(總損失),12943360,1767852100.8524952,0.06330855190753937
train/loss(總損失),12976128,1767852104.6656787,0.09215284138917923
train/loss(總損失),13008896,1767852108.5615203,0.012098237872123718
train/loss(總損失),13041664,1767852112.3818095,0.054589297622442245
train/loss(總損失),13074432,1767852116.1452997,-0.0005047712475061417
train/loss(總損失),13107200,1767852119.9847195,0.12346888333559036
train/loss(總損失),13139968,1767852123.7683256,0.004713829606771469
train/loss(總損失),13172736,1767852127.555611,0.21125032007694244
train/loss(總損失),13205504,1767852131.4304585,0.02820693328976631
train/loss(總損失),13238272,1767852135.2610745,0.15623502433300018
train/loss(總損失),13271040,1767852139.1306732,0.07068584859371185
train/loss(總損失),13303808,1767852142.939284,0.0742311179637909
train/loss(總損失),13336576,1767852146.6933453,0.14121243357658386
train/loss(總損失),13369344,1767852150.5655675,0.13616208732128143
train/loss(總損失),13402112,1767852154.3380415,0.061306264251470566
train/loss(總損失),13434880,1767852158.1100445,0.08594571053981781
train/loss(總損失),13467648,1767852161.9528158,0.1070295199751854
train/loss(總損失),13500416,1767852165.7732508,0.10054292529821396
train/loss(總損失),13533184,1767852169.5396895,0.07149560004472733
train/loss(總損失),13565952,1767852173.3529642,0.0725235715508461
train/loss(總損失),13598720,1767852177.1586583,0.1203431561589241
train/loss(總損失),13631488,1767852180.9323645,0.08765534311532974
train/loss(總損失),13664256,1767852184.7696428,0.08296946436166763
train/loss(總損失),13697024,1767852188.5371807,0.10971610993146896
train/loss(總損失),13729792,1767852192.3270588,0.1064433753490448
train/loss(總損失),13762560,1767852196.1565945,0.12190168350934982
train/loss(總損失),13795328,1767852199.9402995,0.027097851037979126
train/loss(總損失),13828096,1767852203.746766,0.18463034927845
train/loss(總損失),13860864,1767852207.5613794,0.03981367126107216
train/loss(總損失),13893632,1767852211.3222716,0.13341566920280457
train/loss(總損失),13926400,1767852215.117207,0.16696767508983612
train/loss(總損失),13959168,1767852218.9593084,0.08174651861190796
train/loss(總損失),13991936,1767852222.7497587,0.10062801092863083
train/loss(總損失),14024704,1767852226.5376217,0.09502802044153214
train/loss(總損失),14057472,1767852230.341306,0.0804443359375
train/loss(總損失),14090240,1767852234.1542726,0.06968951970338821
train/loss(總損失),14123008,1767852237.9555166,0.16266649961471558
train/loss(總損失),14155776,1767852241.7709186,0.08644711226224899
train/loss(總損失),14188544,1767852245.580831,0.06137791648507118
train/loss(總損失),14221312,1767852249.4112377,0.08441963791847229
train/loss(總損失),14254080,1767852253.1772535,0.1924215853214264
train/loss(總損失),14286848,1767852256.9687953,0.0868915468454361
train/loss(總損失),14319616,1767852260.8131015,0.06401356309652328
train/loss(總損失),14352384,1767852264.6120255,0.13382555544376373
train/loss(總損失),14385152,1767852268.473499,0.019106213003396988
train/loss(總損失),14400000,1767852276.521322,0.1918945461511612
train/loss(總損失),14450688,1767852282.5740464,0.09652978926897049
train/loss(總損失),14483456,1767852286.392631,0.08900650590658188
train/loss(總損失),14516224,1767852290.2720983,0.08004719018936157
train/loss(總損失),14548992,1767852294.1244688,0.08987565338611603
train/loss(總損失),14581760,1767852297.9144642,0.14186429977416992
train/loss(總損失),14614528,1767852301.783318,0.09116081893444061
train/loss(總損失),14647296,1767852305.5912447,0.059319909662008286
train/loss(總損失),14680064,1767852309.4423165,0.10682867467403412
train/loss(總損失),14712832,1767852313.3264575,0.07485796511173248
train/loss(總損失),14745600,1767852317.128722,0.10579165816307068
train/loss(總損失),14778368,1767852320.953251,0.09345591068267822
train/loss(總損失),14811136,1767852324.7873342,0.24424710869789124
train/loss(總損失),14843904,1767852328.6576471,0.06835740804672241
train/loss(總損失),14876672,1767852332.5206673,0.11317015439271927
train/loss(總損失),14909440,1767852336.2900808,0.1031307652592659
train/loss(總損失),14942208,1767852340.1513834,0.09714248031377792
train/loss(總損失),14974976,1767852343.9663556,0.15147703886032104
train/loss(總損失),15007744,1767852347.8206189,0.09816581010818481
train/policy_gradient_loss(策略梯度損失),65536,1767850559.2295241,-0.005169752985239029
train/policy_gradient_loss(策略梯度損失),98304,1767850562.9971344,-0.00898636132478714
train/policy_gradient_loss(策略梯度損失),131072,1767850566.7199862,-0.011899720877408981
train/policy_gradient_loss(策略梯度損失),163840,1767850570.4483514,-0.011658276431262493
train/policy_gradient_loss(策略梯度損失),196608,1767850574.154448,-0.012540210969746113
train/policy_gradient_loss(策略梯度損失),229376,1767850577.891555,-0.01207986194640398
train/policy_gradient_loss(策略梯度損失),262144,1767850581.5840447,-0.01093054749071598
train/policy_gradient_loss(策略梯度損失),294912,1767850585.2045236,-0.009068361483514309
train/policy_gradient_loss(策略梯度損失),327680,1767850588.9230797,-0.007749570533633232
train/policy_gradient_loss(策略梯度損失),360448,1767850592.6430264,-0.0065734428353607655
train/policy_gradient_loss(策略梯度損失),393216,1767850596.5343516,-0.005552888847887516
train/policy_gradient_loss(策略梯度損失),425984,1767850600.2572355,-0.004940937738865614
train/policy_gradient_loss(策略梯度損失),458752,1767850604.004208,-0.004229329526424408
train/policy_gradient_loss(策略梯度損失),491520,1767850607.7777953,-0.004421992693096399
train/policy_gradient_loss(策略梯度損失),524288,1767850611.5745854,-0.0036682123318314552
train/policy_gradient_loss(策略梯度損失),557056,1767850615.2046947,-0.003445781534537673
train/policy_gradient_loss(策略梯度損失),589824,1767850618.933322,-0.0034097046591341496
train/policy_gradient_loss(策略梯度損失),622592,1767850622.620369,-0.0032178841065615416
train/policy_gradient_loss(策略梯度損失),655360,1767850626.317546,-0.003120821202173829
train/policy_gradient_loss(策略梯度損失),688128,1767850629.9229238,-0.0024516673292964697
train/policy_gradient_loss(策略梯度損失),720896,1767850633.6161911,-0.002545572817325592
train/policy_gradient_loss(策略梯度損失),753664,1767850637.1993759,-0.0022711455821990967
train/policy_gradient_loss(策略梯度損失),786432,1767850640.8727472,-0.0021495826076716185
train/policy_gradient_loss(策略梯度損失),819200,1767850644.4664817,-0.002220701426267624
train/policy_gradient_loss(策略梯度損失),851968,1767850648.1062481,-0.002331122988834977
train/policy_gradient_loss(策略梯度損失),884736,1767850651.7045784,-0.002068659057840705
train/policy_gradient_loss(策略梯度損失),917504,1767850655.3435278,-0.002382502891123295
train/policy_gradient_loss(策略梯度損失),950272,1767850659.0720494,-0.0018511960515752435
train/policy_gradient_loss(策略梯度損失),983040,1767850662.7465475,-0.0018882964504882693
train/policy_gradient_loss(策略梯度損失),1015808,1767850666.481074,-0.0021811651531606913
train/policy_gradient_loss(策略梯度損失),1048576,1767850670.1074698,-0.0019011326367035508
train/policy_gradient_loss(策略梯度損失),1081344,1767850673.8078308,-0.00211742939427495
train/policy_gradient_loss(策略梯度損失),1114112,1767850677.3988,-0.0017196197295561433
train/policy_gradient_loss(策略梯度損失),1146880,1767850681.0852022,-0.0018143984489142895
train/policy_gradient_loss(策略梯度損失),1179648,1767850684.685882,-0.001804678002372384
train/policy_gradient_loss(策略梯度損失),1212416,1767850688.3471098,-0.002119639189913869
train/policy_gradient_loss(策略梯度損失),1245184,1767850692.0412767,-0.0016382348258048296
train/policy_gradient_loss(策略梯度損失),1277952,1767850695.7110772,-0.0018723106477409601
train/policy_gradient_loss(策略梯度損失),1310720,1767850699.3796778,-0.001546345534734428
train/policy_gradient_loss(策略梯度損失),1343488,1767850703.107059,-0.001459954190067947
train/policy_gradient_loss(策略梯度損失),1376256,1767850706.7285848,-0.001810916350223124
train/policy_gradient_loss(策略梯度損失),1409024,1767850710.4058769,-0.0010652233613654971
train/policy_gradient_loss(策略梯度損失),1441792,1767850713.9961836,-0.001676661428064108
train/policy_gradient_loss(策略梯度損失),1474560,1767850717.6608357,-0.0014648594660684466
train/policy_gradient_loss(策略梯度損失),1507328,1767850721.2696497,-0.0011962985154241323
train/policy_gradient_loss(策略梯度損失),1540096,1767850724.9062245,-0.001995207043364644
train/policy_gradient_loss(策略梯度損失),1572864,1767850728.5162637,-0.0009292375179938972
train/policy_gradient_loss(策略梯度損失),1600000,1767850737.0012846,-0.001188296009786427
train/policy_gradient_loss(策略梯度損失),1638400,1767850741.4428859,-0.0008627024362795055
train/policy_gradient_loss(策略梯度損失),1671168,1767850745.0722322,-0.0011286553926765919
train/policy_gradient_loss(策略梯度損失),1703936,1767850748.701232,-0.0008352415752597153
train/policy_gradient_loss(策略梯度損失),1736704,1767850752.3870256,-0.0007652283529751003
train/policy_gradient_loss(策略梯度損失),1769472,1767850755.9532557,-0.0008803986711427569
train/policy_gradient_loss(策略梯度損失),1802240,1767850759.612867,-0.0009085103520192206
train/policy_gradient_loss(策略梯度損失),1835008,1767850763.1796484,-0.0007147220894694328
train/policy_gradient_loss(策略梯度損失),1867776,1767850766.815694,-0.0004914659075438976
train/policy_gradient_loss(策略梯度損失),1900544,1767850770.3727283,-0.0010432640556246042
train/policy_gradient_loss(策略梯度損失),1933312,1767850774.0577557,-0.0007342743338085711
train/policy_gradient_loss(策略梯度損失),1966080,1767850777.6604764,-0.000560435582883656
train/policy_gradient_loss(策略梯度損失),1998848,1767850781.2771404,-0.0006915710982866585
train/policy_gradient_loss(策略梯度損失),2031616,1767850784.884306,-0.0009140254696831107
train/policy_gradient_loss(策略梯度損失),2064384,1767850788.493375,-0.0009797035017982125
train/policy_gradient_loss(策略梯度損失),2097152,1767850792.2032356,-0.0009598174947313964
train/policy_gradient_loss(策略梯度損失),2129920,1767850795.866282,-0.0009225188405252993
train/policy_gradient_loss(策略梯度損失),2162688,1767850799.5272243,-0.0010593571932986379
train/policy_gradient_loss(策略梯度損失),2195456,1767850803.2312806,-0.0009765321738086641
train/policy_gradient_loss(策略梯度損失),2228224,1767850806.8444574,-0.0004917698679491878
train/policy_gradient_loss(策略梯度損失),2260992,1767850810.4568942,-0.000966479885391891
train/policy_gradient_loss(策略梯度損失),2293760,1767850814.0776038,-0.0006602911162190139
train/policy_gradient_loss(策略梯度損失),2326528,1767850817.7324646,-0.000721477554179728
train/policy_gradient_loss(策略梯度損失),2359296,1767850821.3082688,-0.0004454255977179855
train/policy_gradient_loss(策略梯度損失),2392064,1767850824.97536,-0.0007537170313298702
train/policy_gradient_loss(策略梯度損失),2424832,1767850828.5569177,-0.000920199672691524
train/policy_gradient_loss(策略梯度損失),2457600,1767850832.2089677,-0.0006287465221248567
train/policy_gradient_loss(策略梯度損失),2490368,1767850835.7887897,-0.0003853850648738444
train/policy_gradient_loss(策略梯度損失),2523136,1767850839.410689,-0.0008648352231830359
train/policy_gradient_loss(策略梯度損失),2555904,1767850842.9698803,-0.0007596305222250521
train/policy_gradient_loss(策略梯度損失),2588672,1767850846.6125402,-0.0006788077298551798
train/policy_gradient_loss(策略梯度損失),2621440,1767850850.1919608,-0.0009362357668578625
train/policy_gradient_loss(策略梯度損失),2654208,1767850853.8273733,-0.0009469611686654389
train/policy_gradient_loss(策略梯度損失),2686976,1767850857.4195008,-0.0006873199017718434
train/policy_gradient_loss(策略梯度損失),2719744,1767850861.3290613,-0.000671051733661443
train/policy_gradient_loss(策略梯度損失),2752512,1767850865.0908148,-0.0008671209798194468
train/policy_gradient_loss(策略梯度損失),2785280,1767850869.031745,-0.0008852254832163453
train/policy_gradient_loss(策略梯度損失),2818048,1767850872.8499599,-0.0010195387294515967
train/policy_gradient_loss(策略梯度損失),2850816,1767850876.711256,-0.0006571438862010837
train/policy_gradient_loss(策略梯度損失),2883584,1767850880.490425,-0.0006347530288621783
train/policy_gradient_loss(策略梯度損失),2916352,1767850884.397116,-0.0004912562435492873
train/policy_gradient_loss(策略梯度損失),2949120,1767850888.1792123,-0.0007660484407097101
train/policy_gradient_loss(策略梯度損失),2981888,1767850891.9776053,-0.0004879874468315393
train/policy_gradient_loss(策略梯度損失),3014656,1767850895.7587442,-0.0007750156801193953
train/policy_gradient_loss(策略梯度損失),3047424,1767850899.581668,-0.0007265856256708503
train/policy_gradient_loss(策略梯度損失),3080192,1767850903.3671603,-0.0009221527143381536
train/policy_gradient_loss(策略梯度損失),3112960,1767850907.1832235,-0.0007327779312618077
train/policy_gradient_loss(策略梯度損失),3145728,1767850911.2443433,-0.0009094028500840068
train/policy_gradient_loss(策略梯度損失),3178496,1767850915.1832602,-0.0008677766309119761
train/policy_gradient_loss(策略梯度損失),3200000,1767850924.5230672,-0.0010382805485278368
train/policy_gradient_loss(策略梯度損失),3244032,1767850929.709888,-0.001125405658967793
train/policy_gradient_loss(策略梯度損失),3276800,1767850933.5482094,-0.0007630898617208004
train/policy_gradient_loss(策略梯度損失),3309568,1767850937.4689844,-0.0010578669607639313
train/policy_gradient_loss(策略梯度損失),3342336,1767850941.3097546,-0.0005131754442118108
train/policy_gradient_loss(策略梯度損失),3375104,1767850945.2967665,-0.0009429828496649861
train/policy_gradient_loss(策略梯度損失),3407872,1767850949.2090595,-0.0009485529735684395
train/policy_gradient_loss(策略梯度損失),3440640,1767850952.9483771,-0.000537227198947221
train/policy_gradient_loss(策略梯度損失),3473408,1767850957.3185942,-0.0008828210411593318
train/policy_gradient_loss(策略梯度損失),3506176,1767850961.4277205,-0.0009634320740588009
train/policy_gradient_loss(策略梯度損失),3538944,1767850965.3084548,-0.000748761638533324
train/policy_gradient_loss(策略梯度損失),3571712,1767850969.296191,-0.0005398187204264104
train/policy_gradient_loss(策略梯度損失),3604480,1767850972.9710395,-0.0006457314011640847
train/policy_gradient_loss(策略梯度損失),3637248,1767850976.7373757,-0.0006925825146026909
train/policy_gradient_loss(策略梯度損失),3670016,1767850980.5689178,-0.0007824247004464269
train/policy_gradient_loss(策略梯度損失),3702784,1767850984.6186466,-0.0007326883496716619
train/policy_gradient_loss(策略梯度損失),3735552,1767850988.6584132,-0.0007221781997941434
train/policy_gradient_loss(策略梯度損失),3768320,1767850992.555819,-0.0008789264829829335
train/policy_gradient_loss(策略梯度損失),3801088,1767850996.51568,-0.0007043895311653614
train/policy_gradient_loss(策略梯度損失),3833856,1767851000.422122,-0.0007787268841639161
train/policy_gradient_loss(策略梯度損失),3866624,1767851004.6852853,-0.0006036368431523442
train/policy_gradient_loss(策略梯度損失),3899392,1767851008.561874,-0.0006595937884412706
train/policy_gradient_loss(策略梯度損失),3932160,1767851012.599403,-0.0006235603941604495
train/policy_gradient_loss(策略梯度損失),3964928,1767851016.6966462,-0.0006078323349356651
train/policy_gradient_loss(策略梯度損失),3997696,1767851020.5575488,-0.0006291480967774987
train/policy_gradient_loss(策略梯度損失),4030464,1767851024.2745268,-0.0005305239465087652
train/policy_gradient_loss(策略梯度損失),4063232,1767851027.9327044,-0.0006454272661358118
train/policy_gradient_loss(策略梯度損失),4096000,1767851031.6902683,-0.0009561444749124348
train/policy_gradient_loss(策略梯度損失),4128768,1767851035.552128,-0.0006630322313867509
train/policy_gradient_loss(策略梯度損失),4161536,1767851039.362606,-0.0006275847554206848
train/policy_gradient_loss(策略梯度損失),4194304,1767851043.200196,-0.0007748015923425555
train/policy_gradient_loss(策略梯度損失),4227072,1767851047.1013942,-0.0006264694966375828
train/policy_gradient_loss(策略梯度損失),4259840,1767851050.849227,-0.0007671299972571433
train/policy_gradient_loss(策略梯度損失),4292608,1767851054.8405092,-0.0005021093529649079
train/policy_gradient_loss(策略梯度損失),4325376,1767851058.8245432,-0.0003126390220131725
train/policy_gradient_loss(策略梯度損失),4358144,1767851062.6418846,-0.0006865285104140639
train/policy_gradient_loss(策略梯度損失),4390912,1767851066.511372,-0.0005483427084982395
train/policy_gradient_loss(策略梯度損失),4423680,1767851070.3151045,-0.0006705986452288926
train/policy_gradient_loss(策略梯度損失),4456448,1767851074.102386,-0.0007756163249723613
train/policy_gradient_loss(策略梯度損失),4489216,1767851077.8736207,-0.0006953232223168015
train/policy_gradient_loss(策略梯度損失),4521984,1767851081.7243874,-0.0005533461226150393
train/policy_gradient_loss(策略梯度損失),4554752,1767851085.5352962,-0.0007382819312624633
train/policy_gradient_loss(策略梯度損失),4587520,1767851089.4037945,-0.0007601113175041974
train/policy_gradient_loss(策略梯度損失),4620288,1767851093.227601,-0.0007503273664042354
train/policy_gradient_loss(策略梯度損失),4653056,1767851097.0151076,-0.0006946134380996227
train/policy_gradient_loss(策略梯度損失),4685824,1767851100.8662007,-0.0005383419338613749
train/policy_gradient_loss(策略梯度損失),4718592,1767851104.6115327,-0.0007922111544758081
train/policy_gradient_loss(策略梯度損失),4751360,1767851108.32668,-0.000692256900947541
train/policy_gradient_loss(策略梯度損失),4784128,1767851112.1232119,-0.0011513548670336604
train/policy_gradient_loss(策略梯度損失),4800000,1767851120.069484,-0.0005455571808852255
train/policy_gradient_loss(策略梯度損失),4849664,1767851125.9418159,-0.0005690702237188816
train/policy_gradient_loss(策略梯度損失),4882432,1767851129.6968298,-0.0007875830633565784
train/policy_gradient_loss(策略梯度損失),4915200,1767851133.48323,-0.0006851493380963802
train/policy_gradient_loss(策略梯度損失),4947968,1767851137.2527626,-0.0005884830025024712
train/policy_gradient_loss(策略梯度損失),4980736,1767851141.0994492,-0.000653472903650254
train/policy_gradient_loss(策略梯度損失),5013504,1767851144.8320682,-0.0007556435302831233
train/policy_gradient_loss(策略梯度損失),5046272,1767851148.5426276,-0.0008705874206498265
train/policy_gradient_loss(策略梯度損失),5079040,1767851152.4145024,-0.0007604987476952374
train/policy_gradient_loss(策略梯度損失),5111808,1767851156.206934,-0.0006153435679152608
train/policy_gradient_loss(策略梯度損失),5144576,1767851159.8990655,-0.0006043463363312185
train/policy_gradient_loss(策略梯度損失),5177344,1767851163.7191901,-0.0006808710168115795
train/policy_gradient_loss(策略梯度損失),5210112,1767851167.4530969,-0.0006639548810198903
train/policy_gradient_loss(策略梯度損失),5242880,1767851171.2078493,-0.000586866051889956
train/policy_gradient_loss(策略梯度損失),5275648,1767851174.9225078,-0.0006736527429893613
train/policy_gradient_loss(策略梯度損失),5308416,1767851178.7845979,-0.0005255765863694251
train/policy_gradient_loss(策略梯度損失),5341184,1767851182.6305401,-0.0005896718357689679
train/policy_gradient_loss(策略梯度損失),5373952,1767851186.3842208,-0.0005826319684274495
train/policy_gradient_loss(策略梯度損失),5406720,1767851190.256159,-0.001538276905193925
train/policy_gradient_loss(策略梯度損失),5439488,1767851194.0659354,-0.000628734240308404
train/policy_gradient_loss(策略梯度損失),5472256,1767851197.8270295,-0.0007499645580537617
train/policy_gradient_loss(策略梯度損失),5505024,1767851201.6639018,-0.0005819785874336958
train/policy_gradient_loss(策略梯度損失),5537792,1767851205.410516,-0.0006133584538474679
train/policy_gradient_loss(策略梯度損失),5570560,1767851209.1647682,-0.0005637674476020038
train/policy_gradient_loss(策略梯度損失),5603328,1767851212.9941003,-0.0006388640613295138
train/policy_gradient_loss(策略梯度損失),5636096,1767851216.780533,-0.0010433521820232272
train/policy_gradient_loss(策略梯度損失),5668864,1767851220.50399,-0.0005939679685980082
train/policy_gradient_loss(策略梯度損失),5701632,1767851224.349205,-0.0008430764428339899
train/policy_gradient_loss(策略梯度損失),5734400,1767851228.1825051,-0.0007383410120382905
train/policy_gradient_loss(策略梯度損失),5767168,1767851231.9415665,-0.0007051749853417277
train/policy_gradient_loss(策略梯度損失),5799936,1767851235.8245368,-0.000578795385081321
train/policy_gradient_loss(策略梯度損失),5832704,1767851239.6419158,-0.000726458034478128
train/policy_gradient_loss(策略梯度損失),5865472,1767851243.3877335,-0.0005956358509138227
train/policy_gradient_loss(策略梯度損失),5898240,1767851247.2597299,-0.0005009063170291483
train/policy_gradient_loss(策略梯度損失),5931008,1767851251.027742,-0.0006634331657551229
train/policy_gradient_loss(策略梯度損失),5963776,1767851254.8088129,-0.000687131192535162
train/policy_gradient_loss(策略梯度損失),5996544,1767851258.8198528,-0.0006730776512995362
train/policy_gradient_loss(策略梯度損失),6029312,1767851262.7803826,-0.000646611035335809
train/policy_gradient_loss(策略梯度損失),6062080,1767851266.7045023,-0.0004771609092131257
train/policy_gradient_loss(策略梯度損失),6094848,1767851270.5552242,-0.000654118659440428
train/policy_gradient_loss(策略梯度損失),6127616,1767851274.4994256,-0.000419764342950657
train/policy_gradient_loss(策略梯度損失),6160384,1767851278.5363,-0.0008425041451118886
train/policy_gradient_loss(策略梯度損失),6193152,1767851282.497792,-0.000556721119210124
train/policy_gradient_loss(策略梯度損失),6225920,1767851286.371077,-0.00036738498602062464
train/policy_gradient_loss(策略梯度損失),6258688,1767851290.3003335,-0.00047991840983740985
train/policy_gradient_loss(策略梯度損失),6291456,1767851294.1221151,-0.0007167793228290975
train/policy_gradient_loss(策略梯度損失),6324224,1767851298.0558202,-0.0007220844854600728
train/policy_gradient_loss(策略梯度損失),6356992,1767851301.9332805,-0.0005563670420087874
train/policy_gradient_loss(策略梯度損失),6389760,1767851305.9020336,-0.0007597643998451531
train/policy_gradient_loss(策略梯度損失),6400000,1767851311.462924,-0.0006261461530812085
train/policy_gradient_loss(策略梯度損失),6455296,1767851318.2926252,-0.0007910677813924849
train/policy_gradient_loss(策略梯度損失),6488064,1767851322.189184,-0.0006553161074407399
train/policy_gradient_loss(策略梯度損失),6520832,1767851326.0816662,-0.0005549584748223424
train/policy_gradient_loss(策略梯度損失),6553600,1767851329.9729526,-0.0007962039089761674
train/policy_gradient_loss(策略梯度損失),6586368,1767851333.9150825,-0.0006428795168176293
train/policy_gradient_loss(策略梯度損失),6619136,1767851337.7638006,-0.0004725066537503153
train/policy_gradient_loss(策略梯度損失),6651904,1767851341.701503,-0.0006673548487015069
train/policy_gradient_loss(策略梯度損失),6684672,1767851345.6731632,-0.0004210892948321998
train/policy_gradient_loss(策略梯度損失),6717440,1767851349.560387,-0.00045588435023091733
train/policy_gradient_loss(策略梯度損失),6750208,1767851353.5049803,-0.0007429234683513641
train/policy_gradient_loss(策略梯度損失),6782976,1767851357.4353492,-0.0008489752071909606
train/policy_gradient_loss(策略梯度損失),6815744,1767851361.282602,-0.0006104905623942614
train/policy_gradient_loss(策略梯度損失),6848512,1767851365.1255405,-0.0005284629878588021
train/policy_gradient_loss(策略梯度損失),6881280,1767851369.1308281,-0.0007831405964680016
train/policy_gradient_loss(策略梯度損失),6914048,1767851373.0831103,-0.00022499843908008188
train/policy_gradient_loss(策略梯度損失),6946816,1767851376.9341528,-0.0006747973384335637
train/policy_gradient_loss(策略梯度損失),6979584,1767851380.8898056,-0.0007846209337003529
train/policy_gradient_loss(策略梯度損失),7012352,1767851384.8043604,-0.0004042770015075803
train/policy_gradient_loss(策略梯度損失),7045120,1767851388.6268508,-0.0005840632948093116
train/policy_gradient_loss(策略梯度損失),7077888,1767851392.4364486,-0.0006878732820041478
train/policy_gradient_loss(策略梯度損失),7110656,1767851396.2063391,-0.0005662124021910131
train/policy_gradient_loss(策略梯度損失),7143424,1767851400.0019038,-0.00026870780857279897
train/policy_gradient_loss(策略梯度損失),7176192,1767851403.8101492,-0.0005820629303343594
train/policy_gradient_loss(策略梯度損失),7208960,1767851407.5575747,-0.000629537389613688
train/policy_gradient_loss(策略梯度損失),7241728,1767851411.3102684,-0.0005742937792092562
train/policy_gradient_loss(策略梯度損失),7274496,1767851415.177134,-0.0006820420385338366
train/policy_gradient_loss(策略梯度損失),7307264,1767851418.9848976,-0.0007035256712697446
train/policy_gradient_loss(策略梯度損失),7340032,1767851422.7513814,-0.0005928876926191151
train/policy_gradient_loss(策略梯度損失),7372800,1767851426.6543834,-0.0005829675355926156
train/policy_gradient_loss(策略梯度損失),7405568,1767851430.4099774,-0.0006185504607856274
train/policy_gradient_loss(策略梯度損失),7438336,1767851434.2532735,-0.0007742150919511914
train/policy_gradient_loss(策略梯度損失),7471104,1767851438.027645,-0.0008485070429742336
train/policy_gradient_loss(策略梯度損失),7503872,1767851441.8613071,-0.0005517906975001097
train/policy_gradient_loss(策略梯度損失),7536640,1767851445.6970434,-0.0006119743338786066
train/policy_gradient_loss(策略梯度損失),7569408,1767851449.6046464,-0.000708468200173229
train/policy_gradient_loss(策略梯度損失),7602176,1767851453.3829386,-0.0008154202369041741
train/policy_gradient_loss(策略梯度損失),7634944,1767851457.2030041,-0.0006344554130919278
train/policy_gradient_loss(策略梯度損失),7667712,1767851461.0323594,-0.0006464404868893325
train/policy_gradient_loss(策略梯度損失),7700480,1767851464.8357837,-0.0007497008773498237
train/policy_gradient_loss(策略梯度損失),7733248,1767851468.663515,-0.0002729373227339238
train/policy_gradient_loss(策略梯度損失),7766016,1767851472.5628033,-0.0006085675559006631
train/policy_gradient_loss(策略梯度損失),7798784,1767851476.44101,-0.0007150474702939391
train/policy_gradient_loss(策略梯度損失),7831552,1767851480.2209823,-0.0007320830482058227
train/policy_gradient_loss(策略梯度損失),7864320,1767851484.0791864,-0.0006188315455801785
train/policy_gradient_loss(策略梯度損失),7897088,1767851487.9261947,-0.000548319541849196
train/policy_gradient_loss(策略梯度損失),7929856,1767851491.7186759,-0.0008742159116081893
train/policy_gradient_loss(策略梯度損失),7962624,1767851495.5764532,-0.0006368100875988603
train/policy_gradient_loss(策略梯度損失),7995392,1767851499.3429677,-0.0007751200464554131
train/policy_gradient_loss(策略梯度損失),8000000,1767851506.12033,-0.0005957891698926687
train/policy_gradient_loss(策略梯度損失),8060928,1767851513.3896632,-0.0005432648467831314
train/policy_gradient_loss(策略梯度損失),8093696,1767851517.217103,-0.00043963786447420716
train/policy_gradient_loss(策略梯度損失),8126464,1767851521.0065434,-0.0006636935868300498
train/policy_gradient_loss(策略梯度損失),8159232,1767851524.8328652,-0.000597585691139102
train/policy_gradient_loss(策略梯度損失),8192000,1767851528.6117404,-0.0006741462857462466
train/policy_gradient_loss(策略梯度損失),8224768,1767851532.4558406,-0.0007179533131420612
train/policy_gradient_loss(策略梯度損失),8257536,1767851536.3614888,-0.0003984851064160466
train/policy_gradient_loss(策略梯度損失),8290304,1767851540.1405644,-0.0005823672981932759
train/policy_gradient_loss(策略梯度損失),8323072,1767851543.9752173,-0.000829461554531008
train/policy_gradient_loss(策略梯度損失),8355840,1767851547.7974606,-0.0006981468759477139
train/policy_gradient_loss(策略梯度損失),8388608,1767851551.589234,-0.0005858915392309427
train/policy_gradient_loss(策略梯度損失),8421376,1767851555.4259474,-0.0007870279951021075
train/policy_gradient_loss(策略梯度損失),8454144,1767851559.1645546,-0.000759533082600683
train/policy_gradient_loss(策略梯度損失),8486912,1767851562.9092748,-0.00044077535858377814
train/policy_gradient_loss(策略梯度損失),8519680,1767851566.6515493,-0.0006599205080419779
train/policy_gradient_loss(策略梯度損失),8552448,1767851570.5102527,-0.0006872519734315574
train/policy_gradient_loss(策略梯度損失),8585216,1767851574.3190894,-0.0006926644127815962
train/policy_gradient_loss(策略梯度損失),8617984,1767851578.1054616,-0.0005413892213255167
train/policy_gradient_loss(策略梯度損失),8650752,1767851581.9335651,-0.0006213338929228485
train/policy_gradient_loss(策略梯度損失),8683520,1767851585.6849768,-0.0003934437991119921
train/policy_gradient_loss(策略梯度損失),8716288,1767851589.452577,-0.0005687825614586473
train/policy_gradient_loss(策略梯度損失),8749056,1767851593.3209686,-0.0007940006908029318
train/policy_gradient_loss(策略梯度損失),8781824,1767851597.1184623,-0.0008643151959404349
train/policy_gradient_loss(策略梯度損失),8814592,1767851600.8884895,-0.0007783174514770508
train/policy_gradient_loss(策略梯度損失),8847360,1767851604.7932854,-0.0005758191691711545
train/policy_gradient_loss(策略梯度損失),8880128,1767851608.6254165,-0.0005889979074709117
train/policy_gradient_loss(策略梯度損失),8912896,1767851612.527798,-0.0007760170847177505
train/policy_gradient_loss(策略梯度損失),8945664,1767851616.315878,-0.0005303799407556653
train/policy_gradient_loss(策略梯度損失),8978432,1767851620.060589,-0.0007443958311341703
train/policy_gradient_loss(策略梯度損失),9011200,1767851623.9160254,-0.0008169298525899649
train/policy_gradient_loss(策略梯度損失),9043968,1767851627.6871045,-0.0005509160691872239
train/policy_gradient_loss(策略梯度損失),9076736,1767851631.4564013,-0.0005440117092803121
train/policy_gradient_loss(策略梯度損失),9109504,1767851635.3087697,-0.00042704783845692873
train/policy_gradient_loss(策略梯度損失),9142272,1767851639.1065817,-0.0006598536274395883
train/policy_gradient_loss(策略梯度損失),9175040,1767851642.8536239,-0.0009316288633272052
train/policy_gradient_loss(策略梯度損失),9207808,1767851646.7252815,-0.0005748636904172599
train/policy_gradient_loss(策略梯度損失),9240576,1767851650.524385,-0.0005810056463815272
train/policy_gradient_loss(策略梯度損失),9273344,1767851654.3276289,-0.000544684415217489
train/policy_gradient_loss(策略梯度損失),9306112,1767851658.130435,-0.0004830824036616832
train/policy_gradient_loss(策略梯度損失),9338880,1767851661.901342,-0.0005235136486589909
train/policy_gradient_loss(策略梯度損失),9371648,1767851665.6797972,-0.0006602465873584151
train/policy_gradient_loss(策略梯度損失),9404416,1767851669.5437174,-0.0004721873556263745
train/policy_gradient_loss(策略梯度損失),9437184,1767851673.3665462,-0.00042128178756684065
train/policy_gradient_loss(策略梯度損失),9469952,1767851677.1810167,-0.0005171991651877761
train/policy_gradient_loss(策略梯度損失),9502720,1767851680.9703443,-0.0007801296305842698
train/policy_gradient_loss(策略梯度損失),9535488,1767851684.7552023,-0.0007121170638129115
train/policy_gradient_loss(策略梯度損失),9568256,1767851688.5880558,-0.0006112391129136086
train/policy_gradient_loss(策略梯度損失),9600000,1767851698.600738,-0.0006034505786374211
train/policy_gradient_loss(策略梯度損失),9633792,1767851702.5447552,-0.0007624486461281776
train/policy_gradient_loss(策略梯度損失),9666560,1767851706.3297298,-0.0007697842083871365
train/policy_gradient_loss(策略梯度損失),9699328,1767851710.178134,-0.0007721967995166779
train/policy_gradient_loss(策略梯度損失),9732096,1767851713.911464,-0.0005446011782623827
train/policy_gradient_loss(策略梯度損失),9764864,1767851717.676499,-0.0008737252792343497
train/policy_gradient_loss(策略梯度損失),9797632,1767851721.4707024,-0.000715028727427125
train/policy_gradient_loss(策略梯度損失),9830400,1767851725.2913725,-0.0007181904511526227
train/policy_gradient_loss(策略梯度損失),9863168,1767851729.1073449,-0.00046975340228527784
train/policy_gradient_loss(策略梯度損失),9895936,1767851732.8964748,-0.0005250405520200729
train/policy_gradient_loss(策略梯度損失),9928704,1767851736.723532,-0.0005259035970084369
train/policy_gradient_loss(策略梯度損失),9961472,1767851740.5208952,-0.0008349643321707845
train/policy_gradient_loss(策略梯度損失),9994240,1767851744.2781618,-0.0007400178583338857
train/policy_gradient_loss(策略梯度損失),10027008,1767851748.0849175,-0.0006684008985757828
train/policy_gradient_loss(策略梯度損失),10059776,1767851751.8735495,-0.0005798344500362873
train/policy_gradient_loss(策略梯度損失),10092544,1767851755.6664157,-0.000734040339011699
train/policy_gradient_loss(策略梯度損失),10125312,1767851759.5029423,-0.000572719145566225
train/policy_gradient_loss(策略梯度損失),10158080,1767851763.2669768,-0.0005957772373221815
train/policy_gradient_loss(策略梯度損失),10190848,1767851767.0469668,-0.0005884622223675251
train/policy_gradient_loss(策略梯度損失),10223616,1767851770.87706,-0.0006871820660308003
train/policy_gradient_loss(策略梯度損失),10256384,1767851774.7015347,-0.0008970563649199903
train/policy_gradient_loss(策略梯度損失),10289152,1767851778.5006182,-0.0006091022514738142
train/policy_gradient_loss(策略梯度損失),10321920,1767851782.3119752,-0.0006232117884792387
train/policy_gradient_loss(策略梯度損失),10354688,1767851786.103872,-0.0008367520640604198
train/policy_gradient_loss(策略梯度損失),10387456,1767851789.8902838,-0.0005038199597038329
train/policy_gradient_loss(策略梯度損失),10420224,1767851793.662539,-0.0008199887233786285
train/policy_gradient_loss(策略梯度損失),10452992,1767851797.5050159,-0.0007329758373089135
train/policy_gradient_loss(策略梯度損失),10485760,1767851801.2513824,-0.0006006003823131323
train/policy_gradient_loss(策略梯度損失),10518528,1767851805.0712113,-0.0006763545679859817
train/policy_gradient_loss(策略梯度損失),10551296,1767851808.8693852,-0.0006620042840950191
train/policy_gradient_loss(策略梯度損失),10584064,1767851812.6389425,-0.0007832640549167991
train/policy_gradient_loss(策略梯度損失),10616832,1767851816.491222,-0.0009455608669668436
train/policy_gradient_loss(策略梯度損失),10649600,1767851820.25121,-0.0007046737591736019
train/policy_gradient_loss(策略梯度損失),10682368,1767851824.0040731,-0.0007502335938625038
train/policy_gradient_loss(策略梯度損失),10715136,1767851827.861113,-0.000744897173717618
train/policy_gradient_loss(策略梯度損失),10747904,1767851831.6708193,-0.0007047494291327894
train/policy_gradient_loss(策略梯度損失),10780672,1767851835.4792118,-0.0006531680119223893
train/policy_gradient_loss(策略梯度損失),10813440,1767851839.2813346,-0.0006966341752558947
train/policy_gradient_loss(策略梯度損失),10846208,1767851843.0669723,-0.0006691860617138445
train/policy_gradient_loss(策略梯度損失),10878976,1767851846.8648553,-0.00048625492490828037
train/policy_gradient_loss(策略梯度損失),10911744,1767851850.6492507,-0.0004401334736030549
train/policy_gradient_loss(策略梯度損失),10944512,1767851854.434947,-0.0005371358711272478
train/policy_gradient_loss(策略梯度損失),10977280,1767851858.2310927,-0.000631798233371228
train/policy_gradient_loss(策略梯度損失),11010048,1767851862.1134384,-0.0005930544575676322
train/policy_gradient_loss(策略梯度損失),11042816,1767851865.956484,-0.0005317027098499238
train/policy_gradient_loss(策略梯度損失),11075584,1767851869.8980806,-0.0006351275951601565
train/policy_gradient_loss(策略梯度損失),11108352,1767851873.7402625,-0.000699780706781894
train/policy_gradient_loss(策略梯度損失),11141120,1767851877.6550186,-0.0007735659019090235
train/policy_gradient_loss(策略梯度損失),11173888,1767851881.506524,-0.0006517028086818755
train/policy_gradient_loss(策略梯度損失),11200000,1767851890.859954,-0.0005762948421761394
train/policy_gradient_loss(策略梯度損失),11239424,1767851895.6584544,-0.0008447357686236501
train/policy_gradient_loss(策略梯度損失),11272192,1767851899.437363,-0.0006065089837647974
train/policy_gradient_loss(策略梯度損失),11304960,1767851903.2367744,-0.0006018251879140735
train/policy_gradient_loss(策略梯度損失),11337728,1767851907.0456638,-0.0006369218463078141
train/policy_gradient_loss(策略梯度損失),11370496,1767851910.8155873,-0.000612167059443891
train/policy_gradient_loss(策略梯度損失),11403264,1767851914.5975258,-0.0008815894252620637
train/policy_gradient_loss(策略梯度損失),11436032,1767851918.4351337,-0.0005331267602741718
train/policy_gradient_loss(策略梯度損失),11468800,1767851922.2353313,-0.0008396063349209726
train/policy_gradient_loss(策略梯度損失),11501568,1767851926.0057366,-0.0006542311748489738
train/policy_gradient_loss(策略梯度損失),11534336,1767851929.8337362,-0.0010384974302724004
train/policy_gradient_loss(策略梯度損失),11567104,1767851933.6304746,-0.0005573630332946777
train/policy_gradient_loss(策略梯度損失),11599872,1767851937.410437,-0.0005048825405538082
train/policy_gradient_loss(策略梯度損失),11632640,1767851941.254964,-0.0006628476548939943
train/policy_gradient_loss(策略梯度損失),11665408,1767851945.045703,-0.0007334447000175714
train/policy_gradient_loss(策略梯度損失),11698176,1767851948.8288078,-0.0006321010878309608
train/policy_gradient_loss(策略梯度損失),11730944,1767851952.675069,-0.000572174321860075
train/policy_gradient_loss(策略梯度損失),11763712,1767851956.4674273,-0.0006163447978906333
train/policy_gradient_loss(策略梯度損失),11796480,1767851960.358683,-0.0007747975760139525
train/policy_gradient_loss(策略梯度損失),11829248,1767851964.2488096,-0.0008288085809908807
train/policy_gradient_loss(策略梯度損失),11862016,1767851968.0738328,-0.0006033967365510762
train/policy_gradient_loss(策略梯度損失),11894784,1767851971.9493694,-0.0006651473813690245
train/policy_gradient_loss(策略梯度損失),11927552,1767851975.8439918,-0.0010096911573782563
train/policy_gradient_loss(策略梯度損失),11960320,1767851979.655874,-0.000732973450794816
train/policy_gradient_loss(策略梯度損失),11993088,1767851983.4819186,-0.0006214383174665272
train/policy_gradient_loss(策略梯度損失),12025856,1767851987.3353593,-0.0004707653424702585
train/policy_gradient_loss(策略梯度損失),12058624,1767851991.2070632,-0.0005656980210915208
train/policy_gradient_loss(策略梯度損失),12091392,1767851995.0093503,-0.0006163489888422191
train/policy_gradient_loss(策略梯度損失),12124160,1767851998.8585718,-0.0007964204996824265
train/policy_gradient_loss(策略梯度損失),12156928,1767852002.723118,-0.0005478552775457501
train/policy_gradient_loss(策略梯度損失),12189696,1767852006.6192544,-0.00046682587708346546
train/policy_gradient_loss(策略梯度損失),12222464,1767852010.4443982,-0.0005650531384162605
train/policy_gradient_loss(策略梯度損失),12255232,1767852014.2425733,-0.0004619836690835655
train/policy_gradient_loss(策略梯度損失),12288000,1767852018.0783741,-0.0005492200143635273
train/policy_gradient_loss(策略梯度損失),12320768,1767852021.9418716,-0.0005353731685318053
train/policy_gradient_loss(策略梯度損失),12353536,1767852025.84965,-0.00036911145434714854
train/policy_gradient_loss(策略梯度損失),12386304,1767852029.716671,-0.0007596887880936265
train/policy_gradient_loss(策略梯度損失),12419072,1767852033.6132348,-0.0006965894717723131
train/policy_gradient_loss(策略梯度損失),12451840,1767852037.4127305,-0.0005834084004163742
train/policy_gradient_loss(策略梯度損失),12484608,1767852041.2448833,-0.0004318375140428543
train/policy_gradient_loss(策略梯度損失),12517376,1767852045.0353427,-0.0006468325154855847
train/policy_gradient_loss(策略梯度損失),12550144,1767852048.8770835,-0.0005136289983056486
train/policy_gradient_loss(策略梯度損失),12582912,1767852052.738572,-0.0005061546107754111
train/policy_gradient_loss(策略梯度損失),12615680,1767852056.6020916,-0.0009016920812427998
train/policy_gradient_loss(策略梯度損失),12648448,1767852060.4723964,-0.0005609343061223626
train/policy_gradient_loss(策略梯度損失),12681216,1767852064.3374374,-0.0005790704162791371
train/policy_gradient_loss(策略梯度損失),12713984,1767852068.303477,-0.000705546117387712
train/policy_gradient_loss(策略梯度損失),12746752,1767852072.1466877,-0.0009263796382583678
train/policy_gradient_loss(策略梯度損失),12779520,1767852076.0877922,-0.0008252417319454253
train/policy_gradient_loss(策略梯度損失),12800000,1767852083.8443215,-0.000657398602925241
train/policy_gradient_loss(策略梯度損失),12845056,1767852089.3506994,-0.000962285790592432
train/policy_gradient_loss(策略梯度損失),12877824,1767852093.2415376,-0.0007327720522880554
train/policy_gradient_loss(策略梯度損失),12910592,1767852097.0481791,-0.0006513099651783705
train/policy_gradient_loss(策略梯度損失),12943360,1767852100.8524952,-0.0006300949607975781
train/policy_gradient_loss(策略梯度損失),12976128,1767852104.6656787,-0.0006479449803009629
train/policy_gradient_loss(策略梯度損失),13008896,1767852108.5625186,-0.0010319572174921632
train/policy_gradient_loss(策略梯度損失),13041664,1767852112.3818095,-0.0008658901788294315
train/policy_gradient_loss(策略梯度損失),13074432,1767852116.1452997,-0.0015873686643317342
train/policy_gradient_loss(策略梯度損失),13107200,1767852119.9847195,-0.000591843097936362
train/policy_gradient_loss(策略梯度損失),13139968,1767852123.7683256,-0.0006959676393307745
train/policy_gradient_loss(策略梯度損失),13172736,1767852127.556609,-0.00059422169579193
train/policy_gradient_loss(策略梯度損失),13205504,1767852131.4304585,-0.0006349137984216213
train/policy_gradient_loss(策略梯度損失),13238272,1767852135.2610745,-0.0006168504478409886
train/policy_gradient_loss(策略梯度損失),13271040,1767852139.1306732,-0.0005858148215338588
train/policy_gradient_loss(策略梯度損失),13303808,1767852142.939284,-0.000518730899784714
train/policy_gradient_loss(策略梯度損失),13336576,1767852146.6933453,-0.0006010154029354453
train/policy_gradient_loss(策略梯度損失),13369344,1767852150.5655675,-0.0006884410977363586
train/policy_gradient_loss(策略梯度損失),13402112,1767852154.3380415,-0.0005518677644431591
train/policy_gradient_loss(策略梯度損失),13434880,1767852158.1100445,-0.0006399427657015622
train/policy_gradient_loss(策略梯度損失),13467648,1767852161.9528158,-0.00046842574374750257
train/policy_gradient_loss(策略梯度損失),13500416,1767852165.774252,-0.0005819960497319698
train/policy_gradient_loss(策略梯度損失),13533184,1767852169.5406895,-0.0006513803382404149
train/policy_gradient_loss(策略梯度損失),13565952,1767852173.3529642,-0.0005500652478076518
train/policy_gradient_loss(策略梯度損失),13598720,1767852177.1586583,-0.00046333420323207974
train/policy_gradient_loss(策略梯度損失),13631488,1767852180.9323645,-0.0004361495084594935
train/policy_gradient_loss(策略梯度損失),13664256,1767852184.7696428,-0.0004021722706966102
train/policy_gradient_loss(策略梯度損失),13697024,1767852188.5371807,-0.0005301182391121984
train/policy_gradient_loss(策略梯度損失),13729792,1767852192.3270588,-0.00043822062434628606
train/policy_gradient_loss(策略梯度損失),13762560,1767852196.1565945,-0.0006028848583810031
train/policy_gradient_loss(策略梯度損失),13795328,1767852199.9402995,-0.0006105349166318774
train/policy_gradient_loss(策略梯度損失),13828096,1767852203.746766,-0.0005134852253831923
train/policy_gradient_loss(策略梯度損失),13860864,1767852207.5613794,-0.00044596969382837415
train/policy_gradient_loss(策略梯度損失),13893632,1767852211.3232698,-0.000640269776340574
train/policy_gradient_loss(策略梯度損失),13926400,1767852215.1182077,-0.0006078950245864689
train/policy_gradient_loss(策略梯度損失),13959168,1767852218.9593084,-0.0007031611748971045
train/policy_gradient_loss(策略梯度損失),13991936,1767852222.7497587,-0.0006603110814467072
train/policy_gradient_loss(策略梯度損失),14024704,1767852226.5376217,-0.0006015800172463059
train/policy_gradient_loss(策略梯度損失),14057472,1767852230.341306,-0.0005303971702232957
train/policy_gradient_loss(策略梯度損失),14090240,1767852234.1542726,-0.000588432711083442
train/policy_gradient_loss(策略梯度損失),14123008,1767852237.9555166,-0.0008091209456324577
train/policy_gradient_loss(策略梯度損失),14155776,1767852241.7709186,-0.0008313032449223101
train/policy_gradient_loss(策略梯度損失),14188544,1767852245.580831,-0.0007836509612388909
train/policy_gradient_loss(策略梯度損失),14221312,1767852249.4112377,-0.0004286100738681853
train/policy_gradient_loss(策略梯度損失),14254080,1767852253.1772535,-0.000515229010488838
train/policy_gradient_loss(策略梯度損失),14286848,1767852256.9687953,-0.0005419300869107246
train/policy_gradient_loss(策略梯度損失),14319616,1767852260.8131015,-0.0004175586218480021
train/policy_gradient_loss(策略梯度損失),14352384,1767852264.6120255,-0.0004785586497746408
train/policy_gradient_loss(策略梯度損失),14385152,1767852268.4745007,-0.0005616970011033118
train/policy_gradient_loss(策略梯度損失),14400000,1767852276.521322,-0.0006754207424819469
train/policy_gradient_loss(策略梯度損失),14450688,1767852282.5750442,-0.0005573495873250067
train/policy_gradient_loss(策略梯度損失),14483456,1767852286.392631,-0.0006758664967492223
train/policy_gradient_loss(策略梯度損失),14516224,1767852290.2720983,-0.0004924432141706347
train/policy_gradient_loss(策略梯度損失),14548992,1767852294.1244688,-0.0005389426951296628
train/policy_gradient_loss(策略梯度損失),14581760,1767852297.9144642,-0.00042456082883290946
train/policy_gradient_loss(策略梯度損失),14614528,1767852301.783318,-0.000373196933651343
train/policy_gradient_loss(策略梯度損失),14647296,1767852305.5912447,-0.000716024951543659
train/policy_gradient_loss(策略梯度損失),14680064,1767852309.4423165,-0.0006456185365095735
train/policy_gradient_loss(策略梯度損失),14712832,1767852313.3264575,-0.0003466757480055094
train/policy_gradient_loss(策略梯度損失),14745600,1767852317.128722,-0.0008040085667744279
train/policy_gradient_loss(策略梯度損失),14778368,1767852320.953251,-0.0003585909435059875
train/policy_gradient_loss(策略梯度損失),14811136,1767852324.7883346,-0.0006429182831197977
train/policy_gradient_loss(策略梯度損失),14843904,1767852328.6576471,-0.0006418511038646102
train/policy_gradient_loss(策略梯度損失),14876672,1767852332.5206673,-0.0008324302034452558
train/policy_gradient_loss(策略梯度損失),14909440,1767852336.2910788,-0.0005585168255493045
train/policy_gradient_loss(策略梯度損失),14942208,1767852340.1513834,-0.0003720487584359944
train/policy_gradient_loss(策略梯度損失),14974976,1767852343.9663556,-0.0006767145241610706
train/policy_gradient_loss(策略梯度損失),15007744,1767852347.8206189,-0.0005547903710976243
train/value_loss(價值損失),65536,1767850559.2295241,0.5667725801467896
train/value_loss(價值損失),98304,1767850562.9971344,0.52774578332901
train/value_loss(價值損失),131072,1767850566.7199862,0.5656174421310425
train/value_loss(價值損失),163840,1767850570.4483514,0.5780351161956787
train/value_loss(價值損失),196608,1767850574.154448,0.5594838261604309
train/value_loss(價值損失),229376,1767850577.891555,0.4588222801685333
train/value_loss(價值損失),262144,1767850581.5840447,0.36146917939186096
train/value_loss(價值損失),294912,1767850585.2045236,0.22659388184547424
train/value_loss(價值損失),327680,1767850588.9230797,0.1393047571182251
train/value_loss(價值損失),360448,1767850592.6430264,0.09659772366285324
train/value_loss(價值損失),393216,1767850596.5343516,0.07643131911754608
train/value_loss(價值損失),425984,1767850600.2572355,0.060088083148002625
train/value_loss(價值損失),458752,1767850604.004208,0.046893566846847534
train/value_loss(價值損失),491520,1767850607.7777953,0.03774907439947128
train/value_loss(價值損失),524288,1767850611.575584,0.030592257156968117
train/value_loss(價值損失),557056,1767850615.2056925,0.02612306922674179
train/value_loss(價值損失),589824,1767850618.933322,0.02450556866824627
train/value_loss(價值損失),622592,1767850622.620369,0.019567007198929787
train/value_loss(價值損失),655360,1767850626.317546,0.017155537381768227
train/value_loss(價值損失),688128,1767850629.9229238,0.016525130718946457
train/value_loss(價值損失),720896,1767850633.6171932,0.014558763243258
train/value_loss(價值損失),753664,1767850637.1993759,0.013076850213110447
train/value_loss(價值損失),786432,1767850640.8727472,0.012498131953179836
train/value_loss(價值損失),819200,1767850644.4664817,0.011482054367661476
train/value_loss(價值損失),851968,1767850648.1062481,0.010958008468151093
train/value_loss(價值損失),884736,1767850651.7045784,0.010030110366642475
train/value_loss(價值損失),917504,1767850655.3435278,0.009877093136310577
train/value_loss(價值損失),950272,1767850659.0720494,0.008118980564177036
train/value_loss(價值損失),983040,1767850662.7465475,0.008548812940716743
train/value_loss(價值損失),1015808,1767850666.481074,0.008023593574762344
train/value_loss(價值損失),1048576,1767850670.1074698,0.007689810823649168
train/value_loss(價值損失),1081344,1767850673.8078308,0.0076569439843297005
train/value_loss(價值損失),1114112,1767850677.3998,0.006387610919773579
train/value_loss(價值損失),1146880,1767850681.0852022,0.0060115354135632515
train/value_loss(價值損失),1179648,1767850684.685882,0.007083654869347811
train/value_loss(價值損失),1212416,1767850688.3471098,0.005982955452054739
train/value_loss(價值損失),1245184,1767850692.0412767,0.00549297546967864
train/value_loss(價值損失),1277952,1767850695.7110772,0.00588737428188324
train/value_loss(價值損失),1310720,1767850699.3806767,0.005371978040784597
train/value_loss(價值損失),1343488,1767850703.107059,0.00529200304299593
train/value_loss(價值損失),1376256,1767850706.7285848,0.005059072282165289
train/value_loss(價值損失),1409024,1767850710.4058769,0.019703181460499763
train/value_loss(價值損失),1441792,1767850713.9971812,0.005113657563924789
train/value_loss(價值損失),1474560,1767850717.6608357,0.004248483572155237
train/value_loss(價值損失),1507328,1767850721.2696497,0.03372790664434433
train/value_loss(價值損失),1540096,1767850724.9062245,0.0038044594693928957
train/value_loss(價值損失),1572864,1767850728.5162637,0.04606953263282776
train/value_loss(價值損失),1600000,1767850737.0012846,0.018008200451731682
train/value_loss(價值損失),1638400,1767850741.4428859,0.03151673078536987
train/value_loss(價值損失),1671168,1767850745.0722322,0.05767178162932396
train/value_loss(價值損失),1703936,1767850748.7022338,0.030702147632837296
train/value_loss(價值損失),1736704,1767850752.3870256,0.04407261312007904
train/value_loss(價值損失),1769472,1767850755.9532557,0.0305743757635355
train/value_loss(價值損失),1802240,1767850759.6138678,0.016374265775084496
train/value_loss(價值損失),1835008,1767850763.1796484,0.04291590675711632
train/value_loss(價值損失),1867776,1767850766.815694,0.029897553846240044
train/value_loss(價值損失),1900544,1767850770.3727283,0.0688578337430954
train/value_loss(價值損失),1933312,1767850774.0577557,0.04184979945421219
train/value_loss(價值損失),1966080,1767850777.6614745,0.05507451295852661
train/value_loss(價值損失),1998848,1767850781.2771404,0.02955552004277706
train/value_loss(價值損失),2031616,1767850784.884306,0.06783589720726013
train/value_loss(價值損失),2064384,1767850788.4943774,0.04225139692425728
train/value_loss(價值損失),2097152,1767850792.2042367,0.029101671651005745
train/value_loss(價值損失),2129920,1767850795.866282,0.029898038133978844
train/value_loss(價值損失),2162688,1767850799.5272243,0.04272891953587532
train/value_loss(價值損失),2195456,1767850803.2312806,0.0163585152477026
train/value_loss(價值損失),2228224,1767850806.8444574,0.042539168149232864
train/value_loss(價值損失),2260992,1767850810.4568942,0.02960958331823349
train/value_loss(價值損失),2293760,1767850814.0776038,0.0419556088745594
train/value_loss(價值損失),2326528,1767850817.7324646,0.06755325198173523
train/value_loss(價值損失),2359296,1767850821.3082688,0.02942669205367565
train/value_loss(價值損失),2392064,1767850824.97536,0.042217954993247986
train/value_loss(價值損失),2424832,1767850828.5569177,0.05539903789758682
train/value_loss(價值損失),2457600,1767850832.2089677,0.041203029453754425
train/value_loss(價值損失),2490368,1767850835.7897875,0.055586930364370346
train/value_loss(價值損失),2523136,1767850839.410689,0.029662005603313446
train/value_loss(價值損失),2555904,1767850842.9698803,0.05539484694600105
train/value_loss(價值損失),2588672,1767850846.6125402,0.0554688386619091
train/value_loss(價值損失),2621440,1767850850.1929612,0.0428972989320755
train/value_loss(價值損失),2654208,1767850853.8273733,0.043141163885593414
train/value_loss(價值損失),2686976,1767850857.4195008,0.055880460888147354
train/value_loss(價值損失),2719744,1767850861.3300643,0.06874863803386688
train/value_loss(價值損失),2752512,1767850865.0918067,0.069337397813797
train/value_loss(價值損失),2785280,1767850869.031745,0.01623225025832653
train/value_loss(價值損失),2818048,1767850872.8499599,0.08193948864936829
train/value_loss(價值損失),2850816,1767850876.711256,0.06870916485786438
train/value_loss(價值損失),2883584,1767850880.490425,0.09474451094865799
train/value_loss(價值損失),2916352,1767850884.397116,0.0680694580078125
train/value_loss(價值損失),2949120,1767850888.1792123,0.06907611340284348
train/value_loss(價值損失),2981888,1767850891.9776053,0.05630188062787056
train/value_loss(價值損失),3014656,1767850895.7587442,0.09583733230829239
train/value_loss(價值損失),3047424,1767850899.581668,0.04304075613617897
train/value_loss(價值損失),3080192,1767850903.3671603,0.09657537192106247
train/value_loss(價值損失),3112960,1767850907.1842234,0.06984106451272964
train/value_loss(價值損失),3145728,1767850911.2443433,0.05650187283754349
train/value_loss(價值損失),3178496,1767850915.1832602,0.10734239220619202
train/value_loss(價值損失),3200000,1767850924.5240698,0.017020363360643387
train/value_loss(價值損失),3244032,1767850929.709888,0.08401106297969818
train/value_loss(價值損失),3276800,1767850933.5482094,0.04331997036933899
train/value_loss(價值損失),3309568,1767850937.4689844,0.12481652945280075
train/value_loss(價值損失),3342336,1767850941.3097546,0.04353105649352074
train/value_loss(價值損失),3375104,1767850945.2972867,0.1512729674577713
train/value_loss(價值損失),3407872,1767850949.2090595,0.05720764398574829
train/value_loss(價值損失),3440640,1767850952.9483771,0.0981658473610878
train/value_loss(價值損失),3473408,1767850957.3185942,0.09891333431005478
train/value_loss(價值損失),3506176,1767850961.4277205,0.05761748552322388
train/value_loss(價值損失),3538944,1767850965.3084548,0.11263471096754074
train/value_loss(價值損失),3571712,1767850969.296191,0.08492791652679443
train/value_loss(價值損失),3604480,1767850972.9710395,0.09912050515413284
train/value_loss(價值損失),3637248,1767850976.7383764,0.08627510070800781
train/value_loss(價值損失),3670016,1767850980.5699189,0.05859525501728058
train/value_loss(價值損失),3702784,1767850984.6186466,0.1412128508090973
train/value_loss(價值損失),3735552,1767850988.6594048,0.07283061742782593
train/value_loss(價值損失),3768320,1767850992.555819,0.11489912122488022
train/value_loss(價值損失),3801088,1767850996.51568,0.05960085988044739
train/value_loss(價值損失),3833856,1767851000.422122,0.08804064989089966
train/value_loss(價值損失),3866624,1767851004.6852853,0.04542448744177818
train/value_loss(價值損失),3899392,1767851008.561874,0.11495447903871536
train/value_loss(價值損失),3932160,1767851012.599403,0.07368306815624237
train/value_loss(價值損失),3964928,1767851016.6966462,0.1019657552242279
train/value_loss(價值損失),3997696,1767851020.5575488,0.07415346801280975
train/value_loss(價值損失),4030464,1767851024.2745268,0.11603915691375732
train/value_loss(價值損失),4063232,1767851027.9327044,0.046217456459999084
train/value_loss(價值損失),4096000,1767851031.691269,0.08910807222127914
train/value_loss(價值損失),4128768,1767851035.552128,0.10413967818021774
train/value_loss(價值損失),4161536,1767851039.362606,0.0750843808054924
train/value_loss(價值損失),4194304,1767851043.200196,0.08942560851573944
train/value_loss(價值損失),4227072,1767851047.1013942,0.03272150456905365
train/value_loss(價值損失),4259840,1767851050.849227,0.09002988785505295
train/value_loss(價值損失),4292608,1767851054.8415062,0.07599909603595734
train/value_loss(價值損失),4325376,1767851058.8255458,0.06105092540383339
train/value_loss(價值損失),4358144,1767851062.6418846,0.10551771521568298
train/value_loss(價值損失),4390912,1767851066.511372,0.07609480619430542
train/value_loss(價值損失),4423680,1767851070.3161058,0.10614745318889618
train/value_loss(價值損失),4456448,1767851074.102386,0.06182726100087166
train/value_loss(價值損失),4489216,1767851077.8746214,0.06258991360664368
train/value_loss(價值損失),4521984,1767851081.7253869,0.0921485424041748
train/value_loss(價值損失),4554752,1767851085.5352962,0.09194624423980713
train/value_loss(價值損失),4587520,1767851089.4037945,0.12254640460014343
train/value_loss(價值損失),4620288,1767851093.227601,0.06334899365901947
train/value_loss(價值損失),4653056,1767851097.0151076,0.10753657668828964
train/value_loss(價值損失),4685824,1767851100.8662007,0.06273463368415833
train/value_loss(價值損失),4718592,1767851104.6115327,0.15229269862174988
train/value_loss(價值損失),4751360,1767851108.32668,0.06371122598648071
train/value_loss(價值損失),4784128,1767851112.1232119,0.09353549033403397
train/value_loss(價值損失),4800000,1767851120.069484,0.09363032877445221
train/value_loss(價值損失),4849664,1767851125.9418159,0.10901790857315063
train/value_loss(價值損失),4882432,1767851129.6968298,0.08006461709737778
train/value_loss(價值損失),4915200,1767851133.48323,0.05007263273000717
train/value_loss(價值損失),4947968,1767851137.2527626,0.04838361218571663
train/value_loss(價值損失),4980736,1767851141.0994492,0.0958813801407814
train/value_loss(價值損失),5013504,1767851144.8320682,0.06547538191080093
train/value_loss(價值損失),5046272,1767851148.5426276,0.08025850355625153
train/value_loss(價值損失),5079040,1767851152.4145024,0.09582305699586868
train/value_loss(價值損失),5111808,1767851156.206934,0.1410199999809265
train/value_loss(價值損失),5144576,1767851159.8990655,0.06551186740398407
train/value_loss(價值損失),5177344,1767851163.7191901,0.08053689450025558
train/value_loss(價值損失),5210112,1767851167.4530969,0.04985484108328819
train/value_loss(價值損失),5242880,1767851171.2078493,0.0807105079293251
train/value_loss(價值損失),5275648,1767851174.9225078,0.11324749886989594
train/value_loss(價值損失),5308416,1767851178.7845979,0.08159904181957245
train/value_loss(價值損失),5341184,1767851182.6305401,0.06591363251209259
train/value_loss(價值損失),5373952,1767851186.3842208,0.051510829478502274
train/value_loss(價值損失),5406720,1767851190.256159,0.004268366377800703
train/value_loss(價值損失),5439488,1767851194.0669353,0.06708276271820068
train/value_loss(價值損失),5472256,1767851197.8270295,0.08324230462312698
train/value_loss(價值損失),5505024,1767851201.6639018,0.06774209439754486
train/value_loss(價值損失),5537792,1767851205.410516,0.08279424905776978
train/value_loss(價值損失),5570560,1767851209.1652818,0.1306845098733902
train/value_loss(價值損失),5603328,1767851212.9941003,0.08326924592256546
train/value_loss(價值損失),5636096,1767851216.780533,0.051070235669612885
train/value_loss(價值損失),5668864,1767851220.50399,0.11525357514619827
train/value_loss(價值損失),5701632,1767851224.349205,0.08340509980916977
train/value_loss(價值損失),5734400,1767851228.1825051,0.11495033651590347
train/value_loss(價值損失),5767168,1767851231.9415665,0.08389278501272202
train/value_loss(價值損失),5799936,1767851235.8245368,0.08375632762908936
train/value_loss(價值損失),5832704,1767851239.6419158,0.09921729564666748
train/value_loss(價值損失),5865472,1767851243.3877335,0.10044986754655838
train/value_loss(價值損失),5898240,1767851247.2597299,0.10060809552669525
train/value_loss(價值損失),5931008,1767851251.027742,0.08483254909515381
train/value_loss(價值損失),5963776,1767851254.8088129,0.06858834624290466
train/value_loss(價值損失),5996544,1767851258.8198528,0.10080067813396454
train/value_loss(價值損失),6029312,1767851262.7803826,0.05310424789786339
train/value_loss(價值損失),6062080,1767851266.7055051,0.08532197773456573
train/value_loss(價值損失),6094848,1767851270.5552242,0.13404777646064758
train/value_loss(價值損失),6127616,1767851274.4994256,0.0839778482913971
train/value_loss(價值損失),6160384,1767851278.5363,0.134404718875885
train/value_loss(價值損失),6193152,1767851282.497792,0.05312929302453995
train/value_loss(價值損失),6225920,1767851286.371077,0.1177692636847496
train/value_loss(價值損失),6258688,1767851290.3003335,0.0692504271864891
train/value_loss(價值損失),6291456,1767851294.1221151,0.16763511300086975
train/value_loss(價值損失),6324224,1767851298.056818,0.08505291491746902
train/value_loss(價值損失),6356992,1767851301.9332805,0.11940844357013702
train/value_loss(價值損失),6389760,1767851305.9020336,0.08615436404943466
train/value_loss(價值損失),6400000,1767851311.4639254,0.05399328097701073
train/value_loss(價值損失),6455296,1767851318.2936277,0.1194467693567276
train/value_loss(價值損失),6488064,1767851322.189184,0.08626457303762436
train/value_loss(價值損失),6520832,1767851326.0826638,0.12006830424070358
train/value_loss(價值損失),6553600,1767851329.9729526,0.08733576536178589
train/value_loss(價值損失),6586368,1767851333.9150825,0.12084989249706268
train/value_loss(價值損失),6619136,1767851337.7638006,0.10342974215745926
train/value_loss(價值損失),6651904,1767851341.7025018,0.08793953061103821
train/value_loss(價值損失),6684672,1767851345.674163,0.08752010762691498
train/value_loss(價值損失),6717440,1767851349.561387,0.15459220111370087
train/value_loss(價值損失),6750208,1767851353.5049803,0.08850783854722977
train/value_loss(價值損失),6782976,1767851357.4353492,0.10595563054084778
train/value_loss(價值損失),6815744,1767851361.282602,0.10532505065202713
train/value_loss(價值損失),6848512,1767851365.126538,0.10522966831922531
train/value_loss(價值損失),6881280,1767851369.1308281,0.0893455296754837
train/value_loss(價值損失),6914048,1767851373.0831103,0.08915283530950546
train/value_loss(價值損失),6946816,1767851376.9341528,0.1233735904097557
train/value_loss(價值損失),6979584,1767851380.8898056,0.07163380086421967
train/value_loss(價值損失),7012352,1767851384.8053615,0.1409788876771927
train/value_loss(價值損失),7045120,1767851388.6268508,0.07224239408969879
train/value_loss(價值損失),7077888,1767851392.43745,0.14038389921188354
train/value_loss(價值損失),7110656,1767851396.2063391,0.10647153854370117
train/value_loss(價值損失),7143424,1767851400.0019038,0.15755486488342285
train/value_loss(價值損失),7176192,1767851403.8101492,0.07210732996463776
train/value_loss(價值損失),7208960,1767851407.5575747,0.17527741193771362
train/value_loss(價值損失),7241728,1767851411.3102684,0.07338215410709381
train/value_loss(價值損失),7274496,1767851415.177134,0.13775673508644104
train/value_loss(價值損失),7307264,1767851418.9848976,0.14077763259410858
train/value_loss(價值損失),7340032,1767851422.7513814,0.10658229887485504
train/value_loss(價值損失),7372800,1767851426.6543834,0.15964455902576447
train/value_loss(價值損失),7405568,1767851430.4099774,0.10791443288326263
train/value_loss(價值損失),7438336,1767851434.2532735,0.09053750336170197
train/value_loss(價值損失),7471104,1767851438.027645,0.10863958299160004
train/value_loss(價值損失),7503872,1767851441.8613071,0.1242276281118393
train/value_loss(價值損失),7536640,1767851445.6970434,0.1441916525363922
train/value_loss(價值損失),7569408,1767851449.6046464,0.09105411916971207
train/value_loss(價值損失),7602176,1767851453.3839374,0.14380541443824768
train/value_loss(價值損失),7634944,1767851457.2030041,0.12616001069545746
train/value_loss(價值損失),7667712,1767851461.0323594,0.09191249310970306
train/value_loss(價值損失),7700480,1767851464.8357837,0.12614889442920685
train/value_loss(價值損失),7733248,1767851468.663515,0.05646082013845444
train/value_loss(價值損失),7766016,1767851472.5628033,0.19613711535930634
train/value_loss(價值損失),7798784,1767851476.44101,0.07473012804985046
train/value_loss(價值損失),7831552,1767851480.2209823,0.1624891459941864
train/value_loss(價值損失),7864320,1767851484.0791864,0.05653882026672363
train/value_loss(價值損失),7897088,1767851487.9261947,0.19890788197517395
train/value_loss(價值損失),7929856,1767851491.7186759,0.021178903058171272
train/value_loss(價值損失),7962624,1767851495.5774553,0.16453181207180023
train/value_loss(價值損失),7995392,1767851499.3429677,0.03977005556225777
train/value_loss(價值損失),8000000,1767851506.12033,0.14679968357086182
train/value_loss(價值損失),8060928,1767851513.3896632,0.09371578693389893
train/value_loss(價值損失),8093696,1767851517.217103,0.07500624656677246
train/value_loss(價值損失),8126464,1767851521.007543,0.14765579998493195
train/value_loss(價值損失),8159232,1767851524.8328652,0.09344770759344101
train/value_loss(價值損失),8192000,1767851528.6117404,0.14747294783592224
train/value_loss(價值損失),8224768,1767851532.4558406,0.057897768914699554
train/value_loss(價值損失),8257536,1767851536.3614888,0.16457603871822357
train/value_loss(價值損失),8290304,1767851540.1405644,0.05814015492796898
train/value_loss(價值損失),8323072,1767851543.976219,0.16482190787792206
train/value_loss(價值損失),8355840,1767851547.7974606,0.07671187818050385
train/value_loss(價值損失),8388608,1767851551.589234,0.07655767351388931
train/value_loss(價值損失),8421376,1767851555.4259474,0.11270205676555634
train/value_loss(價值損失),8454144,1767851559.1645546,0.1126183569431305
train/value_loss(價值損失),8486912,1767851562.9102757,0.1478491574525833
train/value_loss(價值損失),8519680,1767851566.6515493,0.09405072033405304
train/value_loss(價值損失),8552448,1767851570.5102527,0.09536760300397873
train/value_loss(價值損失),8585216,1767851574.3190894,0.07654089480638504
train/value_loss(價值損失),8617984,1767851578.1054616,0.11655376851558685
train/value_loss(價值損失),8650752,1767851581.9335651,0.07646138966083527
train/value_loss(價值損失),8683520,1767851585.6849768,0.13061322271823883
train/value_loss(價值損失),8716288,1767851589.453579,0.07609870284795761
train/value_loss(價值損失),8749056,1767851593.3209686,0.1137176901102066
train/value_loss(價值損失),8781824,1767851597.1184623,0.03923572972416878
train/value_loss(價值損失),8814592,1767851600.8884895,0.18412214517593384
train/value_loss(價值損失),8847360,1767851604.7932854,0.04154210537672043
train/value_loss(價值損失),8880128,1767851608.6254165,0.040514733642339706
train/value_loss(價值損失),8912896,1767851612.527798,0.11359279602766037
train/value_loss(價值損失),8945664,1767851616.315878,0.09451202303171158
train/value_loss(價值損失),8978432,1767851620.060589,0.1484833061695099
train/value_loss(價值損失),9011200,1767851623.9160254,0.0944889709353447
train/value_loss(價值損失),9043968,1767851627.6871045,0.09427457302808762
train/value_loss(價值損失),9076736,1767851631.4564013,0.11315880715847015
train/value_loss(價值損失),9109504,1767851635.3087697,0.09420567750930786
train/value_loss(價值損失),9142272,1767851639.1065817,0.11194557696580887
train/value_loss(價值損失),9175040,1767851642.8536239,0.11207141727209091
train/value_loss(價值損失),9207808,1767851646.7252815,0.1299038529396057
train/value_loss(價值損失),9240576,1767851650.524385,0.11232337355613708
train/value_loss(價值損失),9273344,1767851654.3276289,0.06644521653652191
train/value_loss(價值損失),9306112,1767851658.130435,0.13031034171581268
train/value_loss(價值損失),9338880,1767851661.901342,0.11265962570905685
train/value_loss(價值損失),9371648,1767851665.6797972,0.09492895752191544
train/value_loss(價值損失),9404416,1767851669.5437174,0.13034532964229584
train/value_loss(價值損失),9437184,1767851673.3665462,0.07641389220952988
train/value_loss(價值損失),9469952,1767851677.1810167,0.09494748711585999
train/value_loss(價值損失),9502720,1767851680.9703443,0.07651862502098083
train/value_loss(價值損失),9535488,1767851684.7552023,0.11285776644945145
train/value_loss(價值損失),9568256,1767851688.5880558,0.09418022632598877
train/value_loss(價值損失),9600000,1767851698.600738,0.14838334918022156
train/value_loss(價值損失),9633792,1767851702.5447552,0.09418561309576035
train/value_loss(價值損失),9666560,1767851706.3297298,0.1655932515859604
train/value_loss(價值損失),9699328,1767851710.178134,0.11184889823198318
train/value_loss(價值損失),9732096,1767851713.911464,0.11295066028833389
train/value_loss(價值損失),9764864,1767851717.676499,0.05771014466881752
train/value_loss(價值損失),9797632,1767851721.4707024,0.16593614220619202
train/value_loss(價值損失),9830400,1767851725.2923722,0.09536083787679672
train/value_loss(價值損失),9863168,1767851729.1073449,0.07590008527040482
train/value_loss(價值損失),9895936,1767851732.8964748,0.13106335699558258
train/value_loss(價值損失),9928704,1767851736.7245336,0.07540231943130493
train/value_loss(價值損失),9961472,1767851740.5208952,0.16549578309059143
train/value_loss(價值損失),9994240,1767851744.2781618,0.058213796466588974
train/value_loss(價值損失),10027008,1767851748.0849175,0.13130611181259155
train/value_loss(價值損失),10059776,1767851751.8735495,0.075709767639637
train/value_loss(價值損失),10092544,1767851755.6674166,0.14843273162841797
train/value_loss(價值損失),10125312,1767851759.5029423,0.09328991919755936
train/value_loss(價值損失),10158080,1767851763.2669768,0.16554124653339386
train/value_loss(價值損失),10190848,1767851767.0469668,0.07617319375276566
train/value_loss(價值損失),10223616,1767851770.87706,0.1305418163537979
train/value_loss(價值損失),10256384,1767851774.7015347,0.09407158195972443
train/value_loss(價值損失),10289152,1767851778.5006182,0.14638280868530273
train/value_loss(價值損失),10321920,1767851782.3119752,0.05860699713230133
train/value_loss(價值損失),10354688,1767851786.103872,0.11396903544664383
train/value_loss(價值損失),10387456,1767851789.8902838,0.04032573476433754
train/value_loss(價值損失),10420224,1767851793.662539,0.13117220997810364
train/value_loss(價值損失),10452992,1767851797.5060177,0.05865111202001572
train/value_loss(價值損失),10485760,1767851801.2513824,0.14844390749931335
train/value_loss(價值損失),10518528,1767851805.0712113,0.11230315268039703
train/value_loss(價值損失),10551296,1767851808.8693852,0.07722707837820053
train/value_loss(價值損失),10584064,1767851812.6389425,0.05854199454188347
train/value_loss(價值損失),10616832,1767851816.491222,0.11330920457839966
train/value_loss(價值損失),10649600,1767851820.2522118,0.021498261019587517
train/value_loss(價值損失),10682368,1767851824.0040731,0.20171624422073364
train/value_loss(價值損失),10715136,1767851827.861113,0.04140930995345116
train/value_loss(價值損失),10747904,1767851831.6718204,0.1128346398472786
train/value_loss(價值損失),10780672,1767851835.4792118,0.11347560584545135
train/value_loss(價值損失),10813440,1767851839.2813346,0.07653675228357315
train/value_loss(價值損失),10846208,1767851843.0669723,0.07618900388479233
train/value_loss(價值損失),10878976,1767851846.8648553,0.12992660701274872
train/value_loss(價值損失),10911744,1767851850.6492507,0.09510964155197144
train/value_loss(價值損失),10944512,1767851854.434947,0.1127057895064354
train/value_loss(價值損失),10977280,1767851858.2320924,0.09459894150495529
train/value_loss(價值損失),11010048,1767851862.1134384,0.11287646740674973
train/value_loss(價值損失),11042816,1767851865.9574835,0.11194848269224167
train/value_loss(價值損失),11075584,1767851869.8980806,0.09445775300264359
train/value_loss(價值損失),11108352,1767851873.7402625,0.0950249433517456
train/value_loss(價值損失),11141120,1767851877.6550186,0.07686254382133484
train/value_loss(價值損失),11173888,1767851881.506524,0.11210961639881134
train/value_loss(價值損失),11200000,1767851890.8609545,0.11444120109081268
train/value_loss(價值損失),11239424,1767851895.6584544,0.02267478033900261
train/value_loss(價值損失),11272192,1767851899.4383652,0.11228295415639877
train/value_loss(價值損失),11304960,1767851903.2367744,0.09435207396745682
train/value_loss(價值損失),11337728,1767851907.0466642,0.11384555697441101
train/value_loss(價值損失),11370496,1767851910.8155873,0.0950079932808876
train/value_loss(價值損失),11403264,1767851914.5975258,0.09122944623231888
train/value_loss(價值損失),11436032,1767851918.4351337,0.11201489716768265
train/value_loss(價值損失),11468800,1767851922.2353313,0.09508353471755981
train/value_loss(價值損失),11501568,1767851926.0057366,0.041223060339689255
train/value_loss(價值損失),11534336,1767851929.8347263,0.023544244468212128
train/value_loss(價值損失),11567104,1767851933.6304746,0.09481528401374817
train/value_loss(價值損失),11599872,1767851937.410437,0.11308708041906357
train/value_loss(價值損失),11632640,1767851941.254964,0.13097168505191803
train/value_loss(價值損失),11665408,1767851945.045703,0.023069897666573524
train/value_loss(價值損失),11698176,1767851948.8288078,0.09566617757081985
train/value_loss(價值損失),11730944,1767851952.675069,0.059074752032756805
train/value_loss(價值損失),11763712,1767851956.4674273,0.0780644342303276
train/value_loss(價值損失),11796480,1767851960.358683,0.07598717510700226
train/value_loss(價值損失),11829248,1767851964.2488096,0.14737093448638916
train/value_loss(價值損失),11862016,1767851968.0738328,0.040135424584150314
train/value_loss(價值損失),11894784,1767851971.9503706,0.18353040516376495
train/value_loss(價值損失),11927552,1767851975.8439918,0.022677885368466377
train/value_loss(價值損失),11960320,1767851979.655874,0.11972370743751526
train/value_loss(價值損失),11993088,1767851983.4819186,0.059205129742622375
train/value_loss(價值損失),12025856,1767851987.3353593,0.09384622424840927
train/value_loss(價值損失),12058624,1767851991.2070632,0.11376390606164932
train/value_loss(價值損失),12091392,1767851995.0093503,0.059750646352767944
train/value_loss(價值損失),12124160,1767851998.8585718,0.041049640625715256
train/value_loss(價值損失),12156928,1767852002.723118,0.11227373033761978
train/value_loss(價值損失),12189696,1767852006.6192544,0.09481097757816315
train/value_loss(價值損失),12222464,1767852010.4443982,0.09379877895116806
train/value_loss(價值損失),12255232,1767852014.2425733,0.11218824982643127
train/value_loss(價值損失),12288000,1767852018.079374,0.10954177379608154
train/value_loss(價值損失),12320768,1767852021.9418716,0.04081021621823311
train/value_loss(價值損失),12353536,1767852025.84965,0.09415289014577866
train/value_loss(價值損失),12386304,1767852029.716671,0.13015879690647125
train/value_loss(價值損失),12419072,1767852033.6132348,0.05931837856769562
train/value_loss(價值損失),12451840,1767852037.4127305,0.1120573952794075
train/value_loss(價值損失),12484608,1767852041.2458806,0.07521335780620575
train/value_loss(價值損失),12517376,1767852045.0353427,0.14767591655254364
train/value_loss(價值損失),12550144,1767852048.8770835,0.07645387947559357
train/value_loss(價值損失),12582912,1767852052.738572,0.06151477247476578
train/value_loss(價值損失),12615680,1767852056.6020916,0.04084506258368492
train/value_loss(價值損失),12648448,1767852060.4723964,0.09455116838216782
train/value_loss(價值損失),12681216,1767852064.3374374,0.07748907804489136
train/value_loss(價值損失),12713984,1767852068.303477,0.09539880603551865
train/value_loss(價值損失),12746752,1767852072.147686,0.05969933420419693
train/value_loss(價值損失),12779520,1767852076.0877922,0.058880142867565155
train/value_loss(價值損失),12800000,1767852083.8443215,0.09641468524932861
train/value_loss(價值損失),12845056,1767852089.3516994,0.060038357973098755
train/value_loss(價值損失),12877824,1767852093.2415376,0.04175359755754471
train/value_loss(價值損失),12910592,1767852097.0481791,0.09494276344776154
train/value_loss(價值損失),12943360,1767852100.8524952,0.058688946068286896
train/value_loss(價值損失),12976128,1767852104.6656787,0.094965361058712
train/value_loss(價值損失),13008896,1767852108.5625186,0.05841599777340889
train/value_loss(價值損失),13041664,1767852112.3828123,0.07815366983413696
train/value_loss(價值損失),13074432,1767852116.1452997,0.0046960124745965
train/value_loss(價值損失),13107200,1767852119.9857202,0.11416435241699219
train/value_loss(價值損失),13139968,1767852123.7683256,0.022641295567154884
train/value_loss(價值損失),13172736,1767852127.556609,0.09470253437757492
train/value_loss(價值損失),13205504,1767852131.4304585,0.05851345881819725
train/value_loss(價值損失),13238272,1767852135.2620735,0.14850246906280518
train/value_loss(價值損失),13271040,1767852139.1306732,0.04017041251063347
train/value_loss(價值損失),13303808,1767852142.939284,0.13016901910305023
train/value_loss(價值損失),13336576,1767852146.6933453,0.07638832926750183
train/value_loss(價值損失),13369344,1767852150.5665677,0.12984119355678558
train/value_loss(價值損失),13402112,1767852154.3380415,0.09373889863491058
train/value_loss(價值損失),13434880,1767852158.1100445,0.11222415417432785
train/value_loss(價值損失),13467648,1767852161.9538155,0.09655601531267166
train/value_loss(價值損失),13500416,1767852165.774252,0.07643959671258926
train/value_loss(價值損失),13533184,1767852169.5406895,0.12866079807281494
train/value_loss(價值損失),13565952,1767852173.3529642,0.12925593554973602
train/value_loss(價值損失),13598720,1767852177.1586583,0.11161866784095764
train/value_loss(價值損失),13631488,1767852180.9323645,0.12817515432834625
train/value_loss(價值損失),13664256,1767852184.7696428,0.09437811374664307
train/value_loss(價值損失),13697024,1767852188.5371807,0.1121448278427124
train/value_loss(價值損失),13729792,1767852192.3270588,0.0757594034075737
train/value_loss(價值損失),13762560,1767852196.157594,0.16482600569725037
train/value_loss(價值損失),13795328,1767852199.9402995,0.039749108254909515
train/value_loss(價值損失),13828096,1767852203.746766,0.14844918251037598
train/value_loss(價值損失),13860864,1767852207.5613794,0.09498877823352814
train/value_loss(價值損失),13893632,1767852211.3232698,0.09448474645614624
train/value_loss(價值損失),13926400,1767852215.1182077,0.11217816174030304
train/value_loss(價值損失),13959168,1767852218.9593084,0.09402381628751755
train/value_loss(價值損失),13991936,1767852222.7497587,0.07646172493696213
train/value_loss(價值損失),14024704,1767852226.53862,0.0926896408200264
train/value_loss(價值損失),14057472,1767852230.341306,0.09535940736532211
train/value_loss(價值損失),14090240,1767852234.1542726,0.07588109374046326
train/value_loss(價值損失),14123008,1767852237.9555166,0.1476503312587738
train/value_loss(價值損失),14155776,1767852241.7709186,0.09426426887512207
train/value_loss(價值損失),14188544,1767852245.5818322,0.058755069971084595
train/value_loss(價值損失),14221312,1767852249.4112377,0.11075592786073685
train/value_loss(價值損失),14254080,1767852253.1772535,0.12950308620929718
train/value_loss(價值損失),14286848,1767852256.9687953,0.09378603845834732
train/value_loss(價值損失),14319616,1767852260.8141005,0.07563349604606628
train/value_loss(價值損失),14352384,1767852264.6120255,0.13029152154922485
train/value_loss(價值損失),14385152,1767852268.4745007,0.04018856957554817
train/value_loss(價值損失),14400000,1767852276.521322,0.1473577618598938
train/value_loss(價值損失),14450688,1767852282.5750442,0.09320270270109177
train/value_loss(價值損失),14483456,1767852286.392631,0.11224881559610367
train/value_loss(價值損失),14516224,1767852290.2720983,0.09416543692350388
train/value_loss(價值損失),14548992,1767852294.1254685,0.07546092569828033
train/value_loss(價值損失),14581760,1767852297.9154642,0.1646423190832138
train/value_loss(價值損失),14614528,1767852301.783318,0.09375197440385818
train/value_loss(價值損失),14647296,1767852305.5912447,0.09414473176002502
train/value_loss(價值損失),14680064,1767852309.4423165,0.09510601311922073
train/value_loss(價值損失),14712832,1767852313.3264575,0.07591980695724487
train/value_loss(價值損失),14745600,1767852317.128722,0.1304275095462799
train/value_loss(價值損失),14778368,1767852320.9537618,0.05764724686741829
train/value_loss(價值損失),14811136,1767852324.7883346,0.18241403996944427
train/value_loss(價值損失),14843904,1767852328.658647,0.07617853581905365
train/value_loss(價值損失),14876672,1767852332.5206673,0.11145974695682526
train/value_loss(價值損失),14909440,1767852336.2910788,0.09424663335084915
train/value_loss(價值損失),14942208,1767852340.1513834,0.12906323373317719
train/value_loss(價值損失),14974976,1767852343.9663556,0.11240264773368835
train/value_loss(價值損失),15007744,1767852347.8206189,0.09364891797304153
