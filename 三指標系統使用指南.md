# 📊 三指標追蹤系統 - 快速使用指南

## 🎯 核心概念

訓練 AI 不只要看「平均表現」，更要看：
- 🌟 **最高分**：AI 的潛力上限（正面教材）
- ⬇️ **最低分**：AI 的穩定下限（反面教材）
- 📊 **平均分**：整體表現水準

## 📈 訓練輸出解讀

### 理想情況 ✅
```
迭代 500:
  平均獎勵: 150.00
  最高獎勵: 180.00
  最低獎勵: 120.00
  完成回合數: 8

分析：
✅ 平均分高
✅ 最高分突出
✅ 最低分也很高
✅ 分數範圍窄（180-120=60）
→ 策略穩定且優秀，繼續訓練
```

### 需要注意 ⚠️
```
迭代 500:
  平均獎勵: 80.00
  最高獎勵: 200.00  ← 很高！
  最低獎勵: -50.00  ← 災難！
  完成回合數: 10

分析：
⚠️ 平均分中等
✅ 最高分非常高（有潛力）
❌ 最低分災難性（-50）
❌ 分數範圍極大（200-(-50)=250）
→ 策略不穩定，有潛力但需要穩定
→ 系統會自動調整學習率
```

### 需要調整 🔧
```
迭代 500:
  平均獎勵: 60.00
  最高獎勵: 70.00
  最低獎勵: 50.00
  完成回合數: 12

分析：
❌ 平均分低
❌ 最高分不突出
✅ 但很穩定（70-50=20）
→ 卡在局部最優
→ 建議：增加 entropy_coef 鼓勵探索
```

## 🤖 自動調整機制

系統會根據三個指標自動調整學習率：

### 信號類型

| 信號 | 含義 | 系統響應 |
|------|------|----------|
| 📈 平均分 +1% | 整體進步 | 重置 patience，繼續當前策略 |
| 🌟 最高分 +0.5% | 發現潛力 | patience -5，鼓勵探索 |
| ⬆️ 最低分 +0.5% | 下限提升 | patience -3，穩定性改善 |
| ⚠️ 最低分 -5% | 策略退化 | patience +2，加速降低 LR |

### 實際案例

```
迭代 100: 平均 50, 最高 80, 最低 10
  → 初始狀態

迭代 200: 平均 70, 最高 150, 最低 -20
  📈 平均分提升！patience = 0
  🌟 最高分突破！patience -= 5
  ⚠️ 但最低分惡化！patience += 2
  → 最終 patience = 0 + 2 = 2
  → 訊息："有進步但出現災難性失敗"

迭代 300: 平均 85, 最高 160, 最低 20
  📈 平均分提升！patience = 0
  ⬆️ 最低分大幅改善！patience -= 3
  → 訊息："整體進步且穩定性提升"

迭代 400: 平均 86, 最高 155, 最低 15
  ⚠️ 最低分惡化！patience += 2
  → 訊息："策略可能不穩定"

迭代 430: patience 達到 30
  📉 學習率降低：0.00025 → 0.000125
  → 訊息："30次無顯著改善，降低學習率"
```

## 🎛️ TensorBoard 觀察重點

啟動 TensorBoard：
```bash
tensorboard --logdir=checkpoints/tb --port=6006
```

### 觀察三條曲線

1. **reward/mean**（藍色）
   - 應該持續上升
   - 波動範圍逐漸縮小

2. **reward/max**（綠色）
   - 應該不斷突破新高
   - 如果停滯 → 可能需要增加探索

3. **reward/min**（紅色）⭐ 最重要！
   - 應該持續上升
   - 如果下降 → 策略退化警告
   - 理想：逐漸接近 reward/mean

### 健康的訓練曲線

```
分數
200 ┤     ╭────max
    │    ╱
150 ┤   ╱  ╭──mean
    │  ╱  ╱
100 ┤ ╱  ╱ ╭─min
    │╱  ╱ ╱
 50 ┤  ╱ ╱
    │ ╱ ╱
  0 ┤╱ ╱
    └────────────────
     迭代次數 →

觀察：
✅ 三條線都上升
✅ min 逐漸接近 mean（穩定性提升）
✅ max 持續突破（潛力增長）
```

### 不健康的訓練曲線

```
分數
200 ┤  ╱╲ ╱╲ ╱──max（波動大）
    │ ╱  ╳  ╳
100 ┤╱   ╱╲╱─mean
    │   ╱
  0 ┤──╱─────────min（停滯或下降）
    │
-50 ┤
    └────────────────
     迭代次數 →

問題：
❌ max 波動劇烈（不穩定）
❌ min 不上升或下降（退化）
❌ 三條線距離太大（不一致）

建議：
→ 降低學習率
→ 增加 batch_size
→ 減少 entropy_coef
```

## 🔧 常見問題與解決

### Q1: 最高分很高，但平均分很低
```
最高: 200, 平均: 60, 最低: -50
```
**分析**：策略不穩定，偶爾打出好成績但經常失敗

**解決**：
1. 系統會自動檢測到最低分惡化
2. patience 會增加，學習率會更快降低
3. 等待穩定性提升

**手動調整**（可選）：
```json
{
    "learning_rate": 0.0001,  // 降低學習率
    "batch_size": 512,        // 增加批量
    "ent_coef": 0.005         // 減少探索
}
```

### Q2: 三個指標都停滯不前
```
平均: 50 → 50 → 50
最高: 60 → 60 → 60
最低: 40 → 40 → 40
```
**分析**：卡在局部最優

**解決**：
```json
{
    "learning_rate": 0.0003,  // 提高學習率
    "ent_coef": 0.02,         // 增加探索
    "clip_range": 0.3         // 放寬裁剪範圍
}
```

### Q3: 最低分持續惡化
```
迭代 100: 最低 20
迭代 200: 最低 10
迭代 300: 最低 -10  ⚠️
迭代 400: 最低 -30  ❌
```
**分析**：策略退化，過度探索或學習率太高

**系統響應**：
- 每次惡化 patience +2
- 更快觸發學習率降低
- 自動穩定訓練

**額外建議**：
- 檢查是否改動了環境參數
- 查看是否有異常檢查點
- 考慮回退到之前的檢查點

### Q4: 最低分提升但最高分不動
```
迭代 100: 最低 -20, 最高 150
迭代 200: 最低 10,  最高 150
迭代 300: 最低 40,  最高 150
```
**分析**：穩定性改善但缺乏突破

**系統響應**：
- 最低分改善 → patience -3
- 鼓勵繼續當前策略

**建議**：
- 這是好事！穩定性提升
- 等待更多迭代，最高分可能後續突破
- 或適度增加探索

## 📝 配置建議

### 保守訓練（穩定優先）
```json
{
    "lr_scheduler": {
        "type": "adaptive",
        "patience": 20,              // 較短 patience
        "factor": 0.5,
        "improvement_threshold": 0.01
    },
    "ent_coef": 0.01                // 低探索
}
```

### 激進訓練（突破優先）
```json
{
    "lr_scheduler": {
        "type": "adaptive",
        "patience": 50,              // 較長 patience
        "factor": 0.7,               // 較溫和的衰減
        "improvement_threshold": 0.005  // 更寬鬆的閾值
    },
    "ent_coef": 0.02                // 高探索
}
```

### 平衡訓練（推薦）
```json
{
    "lr_scheduler": {
        "type": "adaptive",
        "patience": 30,
        "factor": 0.5,
        "improvement_threshold": 0.01
    },
    "ent_coef": 0.01
}
```

## 🎯 成功指標

訓練成功的標誌：

1. ✅ **平均分持續上升**
2. ✅ **最高分不斷突破**
3. ✅ **最低分穩步提升**
4. ✅ **三條線逐漸收攏**（範圍縮小）
5. ✅ **很少或沒有「最低分惡化」警告**

**目標範例**（迭代 1000+）：
```
平均獎勵: 165.00
最高獎勵: 185.00
最低獎勵: 145.00

分析：
✅ 平均分高
✅ 範圍小（185-145=40）
✅ 最低分也很高（145）
→ 訓練成功！策略穩定且優秀
```

## 📞 尋求幫助

如果遇到問題，提供以下信息：

1. 最近 10 次迭代的三指標數據
2. TensorBoard 截圖
3. `training_config.json` 內容
4. 控制台輸出的最後 50 行

---

**記住**：好的 AI 不只是「偶爾很厲害」，而是「穩定地厲害」！

三指標系統幫助你：
- 🎯 追求卓越（最高分）
- 🛡️ 避免災難（最低分）
- ⚖️ 保持穩定（平均分）
