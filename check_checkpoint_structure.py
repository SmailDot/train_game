"""
æª¢æŸ¥æª¢æŸ¥é»æª”æ¡ˆçš„å¯¦éš›çµæ§‹
"""

import os

import torch

checkpoint_file = "checkpoints/checkpoint_5940.pt"

print("=" * 80)
print(f"ğŸ” æª¢æŸ¥æª¢æŸ¥é»çµæ§‹: {checkpoint_file}")
print("=" * 80)

try:
    checkpoint = torch.load(checkpoint_file, map_location="cpu")

    print(f"\næª¢æŸ¥é»çš„ keys:")
    for key in checkpoint.keys():
        print(f"   - {key}: {type(checkpoint[key])}")

    # å¦‚æœæœ‰ model_state_dictï¼Œé¡¯ç¤ºåƒæ•¸åç¨±
    if "model_state_dict" in checkpoint:
        print(f"\nmodel_state_dict çš„åƒæ•¸:")
        for i, (param_name, param_tensor) in enumerate(
            checkpoint["model_state_dict"].items()
        ):
            if i < 20:  # åªé¡¯ç¤ºå‰ 20 å€‹
                print(f"   {param_name}: {param_tensor.shape} ({param_tensor.dtype})")
        print(f"   ... å…± {len(checkpoint['model_state_dict'])} å€‹åƒæ•¸")

    # å¦‚æœæœ‰ optimizer_state_dictï¼Œé¡¯ç¤ºçµæ§‹
    if "optimizer_state_dict" in checkpoint:
        print(f"\noptimizer_state_dict çš„çµæ§‹:")
        opt_state = checkpoint["optimizer_state_dict"]
        for key in opt_state.keys():
            if key != "state":
                print(f"   {key}: {opt_state[key]}")

    # å¦‚æœæœ‰ iteration
    if "iteration" in checkpoint:
        print(f"\niteration: {checkpoint['iteration']}")

    # å¦‚æœæœ‰å…¶ä»–å…ƒæ•¸æ“š
    for key in ["episode", "best_score", "avg_score"]:
        if key in checkpoint:
            print(f"{key}: {checkpoint[key]}")

except Exception as e:
    print(f"âŒ ç„¡æ³•è¼‰å…¥: {e}")
    import traceback

    traceback.print_exc()
